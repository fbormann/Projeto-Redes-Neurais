{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ftFvfpxnf7U7"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas\n",
    "import sklearn\n",
    "import scipy\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier, BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "gKy3cQvwf7VL"
   },
   "outputs": [],
   "source": [
    "# use this code to transfer between csv to parquet\n",
    "df.to_parquet(\"train_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RK7tQhKHf7VN"
   },
   "outputs": [],
   "source": [
    "original_training_data = pandas.read_csv(\"train_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "o07Q4SALf7VQ"
   },
   "outputs": [],
   "source": [
    "training_sample = original_training_data.sample(frac=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-ekcnVOGf7VT",
    "outputId": "01aac98a-f4dd-4f17-ddc3-dd6a443bafa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38920, 247)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import pandas\n",
    "import sklearn\n",
    "import scipy\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "TIx6bw-af7VX"
   },
   "outputs": [],
   "source": [
    "training_sample.to_csv(\"train_data_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Training and Test samples from the training data we have available, so all models access the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389196, 246)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.350979e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.735041e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.819095e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.257406e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.804034e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.193229e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.734882e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.343982e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.474494e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.506237e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7         IDADE  SEXO_1  \\\n",
       "0   0     1     1     1     0     0     0     0  1.350979e-01       1   \n",
       "1   1     1     0     1     0     0     1     0  2.735041e-01       1   \n",
       "2   2     1     0     1     0     0     1     0  2.819095e-01       0   \n",
       "3   3     1     1     1     0     0     0     0  2.257406e-01       0   \n",
       "4   4     1     1     0     0     0     1     0  4.804034e-01       0   \n",
       "5   5     0     1     1     0     0     0     1  2.193229e-01       0   \n",
       "6   6     1     1     1     0     0     0     0  5.734882e-01       0   \n",
       "7   7     0     1     0     0     1     0     1  8.343982e-01       1   \n",
       "8   8     1     1     0     1     0     0     0  3.474494e-01       1   \n",
       "9   9     1     1     1     0     0     0     0  5.506237e-16       1   \n",
       "\n",
       "      ...       CEP4_7  CEP4_8  CEP4_9  CEP4_10  CEP4_11  CEP4_12  CEP4_13  \\\n",
       "0     ...            0       0       1        1        0        1        1   \n",
       "1     ...            0       1       0        1        1        0        0   \n",
       "2     ...            1       1       0        0        0        0        1   \n",
       "3     ...            1       1       0        1        1        0        1   \n",
       "4     ...            1       1       1        0        0        1        0   \n",
       "5     ...            0       1       1        0        1        0        0   \n",
       "6     ...            0       0       0        1        1        0        0   \n",
       "7     ...            0       1       0        0        0        1        1   \n",
       "8     ...            1       0       0        0        1        0        1   \n",
       "9     ...            1       1       0        0        0        1        0   \n",
       "\n",
       "   CEP4_14  IND_BOM_1_1  IND_BOM_1_2  \n",
       "0        1            0            1  \n",
       "1        0            1            0  \n",
       "2        0            1            0  \n",
       "3        0            1            0  \n",
       "4        1            1            0  \n",
       "5        1            1            0  \n",
       "6        0            1            0  \n",
       "7        1            1            0  \n",
       "8        1            1            0  \n",
       "9        0            1            0  \n",
       "\n",
       "[10 rows x 246 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_training_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop one of the the label columns\n",
    "original_training_data.drop([\"IND_BOM_1_2\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(original_training_data.drop(\"IND_BOM_1_1\", axis=1), original_training_data[\"IND_BOM_1_1\"],test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pandas.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260761, 245)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.drop(\"id\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260761, 244)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write common training sample to dataset\n",
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.to_csv(\"training_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pandas.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_6</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80781</th>\n",
       "      <td>80781</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.453938</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96217</th>\n",
       "      <td>96217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.322631</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145553</th>\n",
       "      <td>145553</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.733192</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246883</th>\n",
       "      <td>246883</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388795</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192908</th>\n",
       "      <td>192908</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.711497</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70399</th>\n",
       "      <td>70399</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561959</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148944</th>\n",
       "      <td>148944</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375278</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68658</th>\n",
       "      <td>68658</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259987</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187123</th>\n",
       "      <td>187123</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013503</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235113</th>\n",
       "      <td>235113</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661348</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "80781    80781     1     0     1     1     0     0     0  0.453938       1   \n",
       "96217    96217     0     0     1     1     1     0     0  0.322631       1   \n",
       "145553  145553     1     1     1     0     0     0     0  0.733192       1   \n",
       "246883  246883     1     0     0     1     1     0     0  0.388795       1   \n",
       "192908  192908     1     1     0     0     1     0     0  0.711497       1   \n",
       "70399    70399     1     0     0     0     1     1     0  0.561959       1   \n",
       "148944  148944     1     0     1     0     1     0     0  0.375278       1   \n",
       "68658    68658     1     0     1     0     0     1     0  0.259987       1   \n",
       "187123  187123     1     1     1     0     0     0     0  0.013503       1   \n",
       "235113  235113     1     0     1     0     1     0     0  0.661348       1   \n",
       "\n",
       "           ...       CEP4_6  CEP4_7  CEP4_8  CEP4_9  CEP4_10  CEP4_11  \\\n",
       "80781      ...            0       1       0       0        1        1   \n",
       "96217      ...            0       0       0       0        1        0   \n",
       "145553     ...            0       1       1       0        0        0   \n",
       "246883     ...            1       1       0       1        0        0   \n",
       "192908     ...            0       1       1       0        0        1   \n",
       "70399      ...            1       0       1       1        0        0   \n",
       "148944     ...            0       1       1       1        1        1   \n",
       "68658      ...            0       0       0       1        0        1   \n",
       "187123     ...            1       0       0       1        0        1   \n",
       "235113     ...            0       1       0       0        0        1   \n",
       "\n",
       "        CEP4_12  CEP4_13  CEP4_14  IND_BOM_1_1  \n",
       "80781         1        0        1            1  \n",
       "96217         1        0        1            1  \n",
       "145553        0        1        0            1  \n",
       "246883        1        1        0            0  \n",
       "192908        0        1        1            0  \n",
       "70399         0        1        1            1  \n",
       "148944        0        0        0            1  \n",
       "68658         1        0        0            1  \n",
       "187123        0        0        0            1  \n",
       "235113        0        0        0            1  \n",
       "\n",
       "[10 rows x 245 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop id column because the index has the same values\n",
    "test.drop(\"id\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128435, 244)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"test_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FdcCmdK2f7Va"
   },
   "source": [
    "# read sample if already available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "IjI9B-quf7Va"
   },
   "outputs": [],
   "source": [
    "training_data = pandas.read_csv(\"train_data_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38920, 246)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2Ly7xloIf7Ve",
    "outputId": "7a5edec3-61ed-406f-f2a5-a7372d380aa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'UF_1', 'UF_2', 'UF_3', 'UF_4', 'UF_5', 'UF_6', 'UF_7', 'IDADE',\n",
       "       'SEXO_1',\n",
       "       ...\n",
       "       'CEP4_7', 'CEP4_8', 'CEP4_9', 'CEP4_10', 'CEP4_11', 'CEP4_12',\n",
       "       'CEP4_13', 'CEP4_14', 'IND_BOM_1_1', 'IND_BOM_1_2'],\n",
       "      dtype='object', length=246)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "rzfd9dg1f7Vh"
   },
   "outputs": [],
   "source": [
    "# keep ids and their index on database for further reference\n",
    "ids = training_data[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "6C0sx7Tif7Vj"
   },
   "outputs": [],
   "source": [
    "features = training_data.drop([\"IND_BOM_1_1\", \"IND_BOM_1_2\", \"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4udGl4tKf7Vm",
    "outputId": "b929b576-1e63-4a12-df67-d74fb554f238"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_5</th>\n",
       "      <th>CEP4_6</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533846</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604895</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571103</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625795</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107837</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.566673</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174853</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394475</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310590</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "0     1     0     1     1     0     0     0  0.533846       0   \n",
       "1     1     1     0     0     0     1     0  0.604895       1   \n",
       "2     1     0     1     1     0     0     0  0.571103       1   \n",
       "3     1     0     1     0     0     0     1  0.625795       0   \n",
       "4     0     1     1     0     0     1     0  0.272198       0   \n",
       "5     1     1     0     0     0     0     1  0.107837       1   \n",
       "6     1     0     0     1     1     0     0  0.566673       1   \n",
       "7     1     1     0     1     0     0     0  0.174853       1   \n",
       "8     1     1     0     0     0     1     0  0.394475       0   \n",
       "9     0     1     1     0     1     0     0  0.310590       0   \n",
       "\n",
       "   NIVEL_RELACIONAMENTO_CREDITO01   ...     CEP4_5  CEP4_6  CEP4_7  CEP4_8  \\\n",
       "0                        0.111111   ...          1       0       0       0   \n",
       "1                        0.000000   ...          1       0       0       1   \n",
       "2                        0.111111   ...          1       1       0       1   \n",
       "3                        0.111111   ...          0       1       0       1   \n",
       "4                        0.111111   ...          0       0       0       0   \n",
       "5                        0.111111   ...          1       0       0       0   \n",
       "6                        0.111111   ...          1       1       1       1   \n",
       "7                        0.111111   ...          1       1       1       1   \n",
       "8                        0.111111   ...          1       0       1       1   \n",
       "9                        0.111111   ...          1       0       1       0   \n",
       "\n",
       "   CEP4_9  CEP4_10  CEP4_11  CEP4_12  CEP4_13  CEP4_14  \n",
       "0       0        1        1        0        1        0  \n",
       "1       1        1        1        0        0        0  \n",
       "2       0        0        1        0        1        0  \n",
       "3       0        1        0        0        1        0  \n",
       "4       0        1        1        0        0        1  \n",
       "5       0        0        0        1        0        1  \n",
       "6       1        1        0        0        0        0  \n",
       "7       1        0        0        0        0        0  \n",
       "8       0        1        0        0        1        0  \n",
       "9       0        0        0        0        0        1  \n",
       "\n",
       "[10 rows x 243 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "z-XYnde-f7Vs"
   },
   "outputs": [],
   "source": [
    "labels = training_data[\"IND_BOM_1_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PUAV5GkMf7Vv"
   },
   "source": [
    "Vou tentar reduzir a dimensionalidade do dataframe utilizando LDA para poder analisar \n",
    "melhor um subconjunto de variáveis e mensurar a acurácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYDQV9idf7V8"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "c1WYqc8Gf7V-",
    "outputId": "34c86b31-11e0-43b6-d51d-1add48cb3406"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    144\n",
       "int64      102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQM5hPKMf7WB"
   },
   "source": [
    "Pandas leu muito dos valores de forma errada, gerando até problemas para o uso de memória, existem formas\n",
    "melhores de representar estas variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sfF7azoAf7WC",
    "outputId": "44ffb9d7-50ce-4293-97eb-391a90ad70b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'UF_1', 'UF_2', 'UF_3', 'UF_4', 'UF_5', 'UF_6', 'UF_7', 'IDADE',\n",
       "       'SEXO_1',\n",
       "       ...\n",
       "       'CEP4_7', 'CEP4_8', 'CEP4_9', 'CEP4_10', 'CEP4_11', 'CEP4_12',\n",
       "       'CEP4_13', 'CEP4_14', 'IND_BOM_1_1', 'IND_BOM_1_2'],\n",
       "      dtype='object', length=246)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "olJ6I1COf7WG",
    "outputId": "bbe2d096-e03a-4d5e-ec29-1baa6d0fc532"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                  int64\n",
       "UF_1                                int64\n",
       "UF_2                                int64\n",
       "UF_3                                int64\n",
       "UF_4                                int64\n",
       "UF_5                                int64\n",
       "UF_6                                int64\n",
       "UF_7                                int64\n",
       "IDADE                             float64\n",
       "SEXO_1                              int64\n",
       "NIVEL_RELACIONAMENTO_CREDITO01    float64\n",
       "NIVEL_RELACIONAMENTO_CREDITO02    float64\n",
       "BANCO_REST_IRPF_ULTIMA_1            int64\n",
       "BANCO_REST_IRPF_ULTIMA_2            int64\n",
       "BANCO_REST_IRPF_ULTIMA_3            int64\n",
       "BANCO_REST_IRPF_ULTIMA_4            int64\n",
       "BANCO_REST_IRPF_ULTIMA_5            int64\n",
       "BANCO_REST_IRPF_ULTIMA_6            int64\n",
       "BANCO_REST_IRPF_ULTIMA_7            int64\n",
       "ATIVIDADE_EMAIL                   float64\n",
       "EXPOSICAO_ENDERECO                float64\n",
       "EXPOSICAO_EMAIL                   float64\n",
       "EXPOSICAO_TELEFONE                float64\n",
       "ATIVIDADE_ENDERECO                float64\n",
       "ATUALIZACAO_ENDERECO              float64\n",
       "ATUALIZACAO_EMAIL                 float64\n",
       "EXPOSICAO_CONSUMIDOR_EMAILS       float64\n",
       "EXPOSICAO_CONSUMIDOR_TELEFONES    float64\n",
       "ATIVIDADE_TELEFONE                float64\n",
       "VALOR_PARCELA_BOLSA_FAMILIA       float64\n",
       "                                   ...   \n",
       "CEP2_8                              int64\n",
       "CEP2_9                              int64\n",
       "CEP3_1                              int64\n",
       "CEP3_2                              int64\n",
       "CEP3_3                              int64\n",
       "CEP3_4                              int64\n",
       "CEP3_5                              int64\n",
       "CEP3_6                              int64\n",
       "CEP3_7                              int64\n",
       "CEP3_8                              int64\n",
       "CEP3_9                              int64\n",
       "CEP3_10                             int64\n",
       "CEP3_11                             int64\n",
       "CEP3_12                             int64\n",
       "CEP4_1                              int64\n",
       "CEP4_2                              int64\n",
       "CEP4_3                              int64\n",
       "CEP4_4                              int64\n",
       "CEP4_5                              int64\n",
       "CEP4_6                              int64\n",
       "CEP4_7                              int64\n",
       "CEP4_8                              int64\n",
       "CEP4_9                              int64\n",
       "CEP4_10                             int64\n",
       "CEP4_11                             int64\n",
       "CEP4_12                             int64\n",
       "CEP4_13                             int64\n",
       "CEP4_14                             int64\n",
       "IND_BOM_1_1                         int64\n",
       "IND_BOM_1_2                         int64\n",
       "Length: 246, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "VOz6CYXCf7WJ"
   },
   "outputs": [],
   "source": [
    "category_columns = [\"UF_1\", \"UF_2\", \"UF_3\", \"UF_4\", \"UF_5\", \"UF_6\", \"UF_7\",\n",
    "                   \"BANCO_REST_IRPF_ULTIMA_1\", \"BANCO_REST_IRPF_ULTIMA_2\", \"BANCO_REST_IRPF_ULTIMA_3\",\n",
    "                   \"BANCO_REST_IRPF_ULTIMA_4\", \"BANCO_REST_IRPF_ULTIMA_5\", \"BANCO_REST_IRPF_ULTIMA_6\",\n",
    "                   \"BANCO_REST_IRPF_ULTIMA_7\", \"FLAG_BOLSA_FAMILIA_1\", \"SIGLA_PARTIDO_FILIADO_1\",\n",
    "                   \"SIGLA_PARTIDO_FILIADO_2\", \"SIGLA_PARTIDO_FILIADO_3\", \"SIGLA_PARTIDO_FILIADO_4\",\n",
    "                   \"SIGLA_PARTIDO_FILIADO_5\", \"SIGLA_PARTIDO_FILIADO_6\", \"SIGLA_PARTIDO_FILIADO_7\",\n",
    "                   \"FLAG_FILIADO_PARTIDO_POLITICO_1\", \"FLAG_PROUNI_1\", \"RENDA_VIZINHANCA_1\", \n",
    "                   \"RENDA_VIZINHANCA_2\", \"RENDA_VIZINHANCA_3\", \"RENDA_VIZINHANCA_4\", \n",
    "                    \"COMPARATIVO_RENDA_CEP_1\", \"COMPARATIVO_RENDA_CEP_2\", \"COMPARATIVO_RENDA_CEP_3\",\n",
    "                   \"COMPARATIVO_RENDA_CEP_4\", \"COMPARATIVO_RENDA_CEP_5\", \"CLASSE_SOCIAL_CONSUMIDOR_1\",\n",
    "                   \"CLASSE_SOCIAL_CONSUMIDOR_2\", \"CLASSE_SOCIAL_CONSUMIDOR_3\", \"CLASSE_SOCIAL_CONSUMIDOR_4\",\n",
    "                   \"FLAG_REDE_SOCIAL_1\", \"FLAG_REDE_SOCIAL_2\", \"FLAG_REDE_SOCIAL_3\",\n",
    "                   \"CEP1_1\", \"CEP1_2\", \"CEP1_3\", \"CEP1_4\", \"CEP1_5\", \"CEP2_1\", \"CEP2_2\", \"CEP2_3\", \"CEP2_4\",\n",
    "                   \"CEP2_5\", \"CEP2_6\", \"CEP2_7\", \"CEP2_8\", \"CEP2_9\", \"CEP3_1\", \"CEP3_2\", \"CEP3_3\", \"CEP3_4\",\n",
    "                   \"CEP3_5\", \"CEP3_6\", \"CEP3_7\", \"CEP3_8\", \"CEP3_9\", \"CEP3_10\", \"CEP3_11\", \"CEP3_12\",\n",
    "                   \"CEP4_1\", \"CEP4_2\", \"CEP4_3\", \"CEP4_4\", \"CEP4_5\", \"CEP4_6\", \"CEP4_7\", \"CEP4_8\", \"CEP4_9\",\n",
    "                   \"CEP4_10\", \"CEP4_11\", \"CEP4_12\", \"CEP4_13\", \"CEP4_14\"]\n",
    "\n",
    "ordered_category_columns = [\"NIVEL_RELACIONAMENTO_CREDITO02\", \"EXPOSICAO_CONSUMIDOR_EMAILS\", \n",
    "                            \"EXPOSICAO_CONSUMIDOR_TELEFONES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Rne2Z-82f7WL",
    "outputId": "221c332b-b531-4c10-e309-23245f2fcf3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "2047      1\n",
      "66954     1\n",
      "340615    1\n",
      "118163    1\n",
      "116114    1\n",
      "384401    1\n",
      "284684    1\n",
      "337294    1\n",
      "81293     1\n",
      "341388    1\n",
      "Name: Unnamed: 0, dtype: int64\n",
      "194598\n",
      "id\n",
      "2047      1\n",
      "66954     1\n",
      "340615    1\n",
      "118163    1\n",
      "116114    1\n",
      "384401    1\n",
      "284684    1\n",
      "337294    1\n",
      "81293     1\n",
      "341388    1\n",
      "Name: id, dtype: int64\n",
      "194598\n",
      "UF_1\n",
      "1    173076\n",
      "0     21522\n",
      "Name: UF_1, dtype: int64\n",
      "2\n",
      "UF_2\n",
      "1    134541\n",
      "0     60057\n",
      "Name: UF_2, dtype: int64\n",
      "2\n",
      "UF_3\n",
      "0    101940\n",
      "1     92658\n",
      "Name: UF_3, dtype: int64\n",
      "2\n",
      "UF_4\n",
      "0    136851\n",
      "1     57747\n",
      "Name: UF_4, dtype: int64\n",
      "2\n",
      "UF_5\n",
      "0    147454\n",
      "1     47144\n",
      "Name: UF_5, dtype: int64\n",
      "2\n",
      "UF_6\n",
      "0    152286\n",
      "1     42312\n",
      "Name: UF_6, dtype: int64\n",
      "2\n",
      "UF_7\n",
      "0    158282\n",
      "1     36316\n",
      "Name: UF_7, dtype: int64\n",
      "2\n",
      "IDADE\n",
      "5.506237e-16    2054\n",
      "1.000000e+00    1909\n",
      "3.078642e-01      50\n",
      "3.008786e-01      46\n",
      "2.940066e-01      46\n",
      "3.130324e-01      40\n",
      "5.574156e-01      37\n",
      "3.833430e-01      30\n",
      "3.026960e-01      30\n",
      "3.440986e-01      30\n",
      "Name: IDADE, dtype: int64\n",
      "17157\n",
      "SEXO_1\n",
      "1    101673\n",
      "0     92925\n",
      "Name: SEXO_1, dtype: int64\n",
      "2\n",
      "NIVEL_RELACIONAMENTO_CREDITO01\n",
      "0.111111    184016\n",
      "1.000000      2515\n",
      "0.000000      2194\n",
      "0.222222      1189\n",
      "0.888889      1095\n",
      "0.777778       986\n",
      "0.666667       768\n",
      "0.333333       663\n",
      "0.444444       601\n",
      "0.555556       571\n",
      "Name: NIVEL_RELACIONAMENTO_CREDITO01, dtype: int64\n",
      "10\n",
      "NIVEL_RELACIONAMENTO_CREDITO02\n",
      "0.0    194134\n",
      "1.0       348\n",
      "0.5       116\n",
      "Name: NIVEL_RELACIONAMENTO_CREDITO02, dtype: int64\n",
      "3\n",
      "BANCO_REST_IRPF_ULTIMA_1\n",
      "0    179674\n",
      "1     14924\n",
      "Name: BANCO_REST_IRPF_ULTIMA_1, dtype: int64\n",
      "2\n",
      "BANCO_REST_IRPF_ULTIMA_2\n",
      "0    188163\n",
      "1      6435\n",
      "Name: BANCO_REST_IRPF_ULTIMA_2, dtype: int64\n",
      "2\n",
      "BANCO_REST_IRPF_ULTIMA_3\n",
      "0    191280\n",
      "1      3318\n",
      "Name: BANCO_REST_IRPF_ULTIMA_3, dtype: int64\n",
      "2\n",
      "BANCO_REST_IRPF_ULTIMA_4\n",
      "0    191595\n",
      "1      3003\n",
      "Name: BANCO_REST_IRPF_ULTIMA_4, dtype: int64\n",
      "2\n",
      "BANCO_REST_IRPF_ULTIMA_5\n",
      "0    192282\n",
      "1      2316\n",
      "Name: BANCO_REST_IRPF_ULTIMA_5, dtype: int64\n",
      "2\n",
      "BANCO_REST_IRPF_ULTIMA_6\n",
      "1    180256\n",
      "0     14342\n",
      "Name: BANCO_REST_IRPF_ULTIMA_6, dtype: int64\n",
      "2\n",
      "BANCO_REST_IRPF_ULTIMA_7\n",
      "1    178944\n",
      "0     15654\n",
      "Name: BANCO_REST_IRPF_ULTIMA_7, dtype: int64\n",
      "2\n",
      "ATIVIDADE_EMAIL\n",
      "5.881235e-18    139155\n",
      "5.694352e-02      3805\n",
      "9.102106e-02      1396\n",
      "7.695731e-02      1369\n",
      "9.129151e-02      1360\n",
      "3.720255e-01       658\n",
      "1.000000e+00       577\n",
      "3.493072e-01       260\n",
      "3.717551e-01       209\n",
      "3.514709e-01       190\n",
      "Name: ATIVIDADE_EMAIL, dtype: int64\n",
      "2984\n",
      "EXPOSICAO_ENDERECO\n",
      "0.000000    53081\n",
      "0.013889    22093\n",
      "0.041667    20216\n",
      "0.027778    14601\n",
      "0.055556    13266\n",
      "0.111111     9110\n",
      "0.069444     8825\n",
      "0.083333     5844\n",
      "0.097222     5524\n",
      "0.125000     4877\n",
      "Name: EXPOSICAO_ENDERECO, dtype: int64\n",
      "73\n",
      "EXPOSICAO_EMAIL\n",
      "0.000000    141260\n",
      "0.031579      8956\n",
      "0.010526      7888\n",
      "0.052632      4543\n",
      "0.073684      3139\n",
      "0.094737      3063\n",
      "0.115789      1907\n",
      "0.136842      1638\n",
      "0.063158      1635\n",
      "0.042105      1486\n",
      "Name: EXPOSICAO_EMAIL, dtype: int64\n",
      "96\n",
      "EXPOSICAO_TELEFONE\n",
      "0.000000    116352\n",
      "0.027778     19312\n",
      "0.055556     14792\n",
      "0.083333      8628\n",
      "0.111111      6592\n",
      "0.138889      4856\n",
      "0.166667      3760\n",
      "0.194444      3051\n",
      "0.222222      2374\n",
      "0.250000      1916\n",
      "Name: EXPOSICAO_TELEFONE, dtype: int64\n",
      "37\n",
      "ATIVIDADE_ENDERECO\n",
      "1.473561e-01    114624\n",
      "1.144370e-01     20395\n",
      "1.055877e-01      9248\n",
      "2.044015e-16      3314\n",
      "1.519577e-01      3232\n",
      "1.526657e-01      3077\n",
      "1.516038e-01      2418\n",
      "1.523117e-01      2140\n",
      "1.000000e+00      2003\n",
      "1.919563e-01      1917\n",
      "Name: ATIVIDADE_ENDERECO, dtype: int64\n",
      "1711\n",
      "ATUALIZACAO_ENDERECO\n",
      "0.398645    44202\n",
      "0.979968    41451\n",
      "0.815862    37353\n",
      "0.002289    19386\n",
      "0.850630    16924\n",
      "0.003680     9342\n",
      "0.593347     4449\n",
      "0.084342     2403\n",
      "0.796392     2203\n",
      "1.000000     1856\n",
      "Name: ATUALIZACAO_ENDERECO, dtype: int64\n",
      "362\n",
      "ATUALIZACAO_EMAIL\n",
      "-5.140958e-17    139227\n",
      " 8.325188e-02     10028\n",
      " 1.081891e-01      3186\n",
      " 2.562665e-02      2283\n",
      " 1.257126e-01      2131\n",
      " 1.260496e-01      1930\n",
      " 2.596364e-02      1395\n",
      " 5.070283e-03      1194\n",
      " 1.000000e+00       548\n",
      " 2.528966e-02       457\n",
      "Name: ATUALIZACAO_EMAIL, dtype: int64\n",
      "2258\n",
      "EXPOSICAO_CONSUMIDOR_EMAILS\n",
      "0.0    138671\n",
      "0.2     33038\n",
      "0.4     12526\n",
      "0.6      5354\n",
      "1.0      2600\n",
      "0.8      2409\n",
      "Name: EXPOSICAO_CONSUMIDOR_EMAILS, dtype: int64\n",
      "6\n",
      "EXPOSICAO_CONSUMIDOR_TELEFONES\n",
      "0.1    67386\n",
      "0.0    64586\n",
      "0.2    21907\n",
      "0.3    14226\n",
      "0.4     8567\n",
      "0.5     5586\n",
      "0.6     3853\n",
      "1.0     2685\n",
      "0.7     2672\n",
      "0.8     1803\n",
      "Name: EXPOSICAO_CONSUMIDOR_TELEFONES, dtype: int64\n",
      "11\n",
      "ATIVIDADE_TELEFONE\n",
      "-2.188272e-17    65811\n",
      " 1.388212e-01    46117\n",
      " 6.681370e-02     8763\n",
      " 1.698044e-01     2570\n",
      " 1.692307e-01     2546\n",
      " 8.574793e-02     2461\n",
      " 1.689438e-01     1864\n",
      " 1.695176e-01     1734\n",
      " 2.016484e-01     1410\n",
      " 1.000000e+00     1310\n",
      "Name: ATIVIDADE_TELEFONE, dtype: int64\n",
      "2535\n",
      "VALOR_PARCELA_BOLSA_FAMILIA\n",
      "0.000000    154721\n",
      "0.098958      3443\n",
      "0.182292      2801\n",
      "0.117188      2639\n",
      "0.265625      2635\n",
      "0.208333      2621\n",
      "0.299479      1609\n",
      "0.348958      1159\n",
      "0.122396      1017\n",
      "0.138021       879\n",
      "Name: VALOR_PARCELA_BOLSA_FAMILIA, dtype: int64\n",
      "327\n",
      "FLAG_BOLSA_FAMILIA_1\n",
      "0    153420\n",
      "1     41178\n",
      "Name: FLAG_BOLSA_FAMILIA_1, dtype: int64\n",
      "2\n",
      "SIGLA_PARTIDO_FILIADO_1\n",
      "1    187747\n",
      "0      6851\n",
      "Name: SIGLA_PARTIDO_FILIADO_1, dtype: int64\n",
      "2\n",
      "SIGLA_PARTIDO_FILIADO_2\n",
      "1    173751\n",
      "0     20847\n",
      "Name: SIGLA_PARTIDO_FILIADO_2, dtype: int64\n",
      "2\n",
      "SIGLA_PARTIDO_FILIADO_3\n",
      "1    165988\n",
      "0     28610\n",
      "Name: SIGLA_PARTIDO_FILIADO_3, dtype: int64\n",
      "2\n",
      "SIGLA_PARTIDO_FILIADO_4\n",
      "0    177834\n",
      "1     16764\n",
      "Name: SIGLA_PARTIDO_FILIADO_4, dtype: int64\n",
      "2\n",
      "SIGLA_PARTIDO_FILIADO_5\n",
      "0    180050\n",
      "1     14548\n",
      "Name: SIGLA_PARTIDO_FILIADO_5, dtype: int64\n",
      "2\n",
      "SIGLA_PARTIDO_FILIADO_6\n",
      "0    181095\n",
      "1     13503\n",
      "Name: SIGLA_PARTIDO_FILIADO_6, dtype: int64\n",
      "2\n",
      "SIGLA_PARTIDO_FILIADO_7\n",
      "0    183105\n",
      "1     11493\n",
      "Name: SIGLA_PARTIDO_FILIADO_7, dtype: int64\n",
      "2\n",
      "FLAG_FILIADO_PARTIDO_POLITICO_1\n",
      "0    150125\n",
      "1     44473\n",
      "Name: FLAG_FILIADO_PARTIDO_POLITICO_1, dtype: int64\n",
      "2\n",
      "FLAG_PROUNI_1\n",
      "1    112484\n",
      "0     82114\n",
      "Name: FLAG_PROUNI_1, dtype: int64\n",
      "2\n",
      "RENDA_VIZINHANCA_1\n",
      "0    179113\n",
      "1     15485\n",
      "Name: RENDA_VIZINHANCA_1, dtype: int64\n",
      "2\n",
      "RENDA_VIZINHANCA_2\n",
      "1    188386\n",
      "0      6212\n",
      "Name: RENDA_VIZINHANCA_2, dtype: int64\n",
      "2\n",
      "RENDA_VIZINHANCA_3\n",
      "0    188815\n",
      "1      5783\n",
      "Name: RENDA_VIZINHANCA_3, dtype: int64\n",
      "2\n",
      "RENDA_VIZINHANCA_4\n",
      "1    179542\n",
      "0     15056\n",
      "Name: RENDA_VIZINHANCA_4, dtype: int64\n",
      "2\n",
      "QUANTIDADE_VIZINHANCA\n",
      "1.000000    2834\n",
      "0.000000     941\n",
      "0.991063     371\n",
      "0.901305     319\n",
      "0.397017     267\n",
      "0.000416     264\n",
      "0.000438     263\n",
      "0.000652     259\n",
      "0.000618     257\n",
      "0.000551     254\n",
      "Name: QUANTIDADE_VIZINHANCA, dtype: int64\n",
      "7508\n",
      "COMPARATIVO_RENDA_CEP_1\n",
      "1    187464\n",
      "0      7134\n",
      "Name: COMPARATIVO_RENDA_CEP_1, dtype: int64\n",
      "2\n",
      "COMPARATIVO_RENDA_CEP_2\n",
      "0    98333\n",
      "1    96265\n",
      "Name: COMPARATIVO_RENDA_CEP_2, dtype: int64\n",
      "2\n",
      "COMPARATIVO_RENDA_CEP_3\n",
      "0    128474\n",
      "1     66124\n",
      "Name: COMPARATIVO_RENDA_CEP_3, dtype: int64\n",
      "2\n",
      "COMPARATIVO_RENDA_CEP_4\n",
      "0    167209\n",
      "1     27389\n",
      "Name: COMPARATIVO_RENDA_CEP_4, dtype: int64\n",
      "2\n",
      "COMPARATIVO_RENDA_CEP_5\n",
      "0    182644\n",
      "1     11954\n",
      "Name: COMPARATIVO_RENDA_CEP_5, dtype: int64\n",
      "2\n",
      "CLASSE_SOCIAL_CONSUMIDOR_1\n",
      "0    151855\n",
      "1     42743\n",
      "Name: CLASSE_SOCIAL_CONSUMIDOR_1, dtype: int64\n",
      "2\n",
      "CLASSE_SOCIAL_CONSUMIDOR_2\n",
      "1    178750\n",
      "0     15848\n",
      "Name: CLASSE_SOCIAL_CONSUMIDOR_2, dtype: int64\n",
      "2\n",
      "CLASSE_SOCIAL_CONSUMIDOR_3\n",
      "0    180351\n",
      "1     14247\n",
      "Name: CLASSE_SOCIAL_CONSUMIDOR_3, dtype: int64\n",
      "2\n",
      "CLASSE_SOCIAL_CONSUMIDOR_4\n",
      "1    153456\n",
      "0     41142\n",
      "Name: CLASSE_SOCIAL_CONSUMIDOR_4, dtype: int64\n",
      "2\n",
      "ATIVIDADE_CONSUMIDOR_MERCADO_FINANCEIRO\n",
      "0.000000    144934\n",
      "0.050505      1751\n",
      "0.090909      1608\n",
      "0.010101      1555\n",
      "0.020202      1524\n",
      "0.040404      1515\n",
      "0.262626      1485\n",
      "0.161616      1447\n",
      "0.080808      1391\n",
      "0.303030      1325\n",
      "Name: ATIVIDADE_CONSUMIDOR_MERCADO_FINANCEIRO, dtype: int64\n",
      "100\n",
      "ATUALIZACAO_CONSUMIDOR_MERCADO_FINANCEIRO\n",
      "0.000000    151688\n",
      "0.013158      3239\n",
      "0.039474      2991\n",
      "0.078947      2758\n",
      "0.026316      2743\n",
      "0.065789      2193\n",
      "0.052632      2116\n",
      "0.118421      1627\n",
      "0.131579      1619\n",
      "0.105263      1562\n",
      "Name: ATUALIZACAO_CONSUMIDOR_MERCADO_FINANCEIRO, dtype: int64\n",
      "77\n",
      "FLAG_PROGRAMAS_SOCIAIS_1\n",
      "0    151717\n",
      "1     42881\n",
      "Name: FLAG_PROGRAMAS_SOCIAIS_1, dtype: int64\n",
      "2\n",
      "CAD_DEMOGRAFICO_VAR_0\n",
      "0.000000    25126\n",
      "0.048492      517\n",
      "0.955691      395\n",
      "0.253486      394\n",
      "0.810936      371\n",
      "0.963828      320\n",
      "0.970214      267\n",
      "0.847030      249\n",
      "0.890235      248\n",
      "0.935111      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_0, dtype: int64\n",
      "39935\n",
      "CAD_DEMOGRAFICO_VAR_1\n",
      "0.000000    25126\n",
      "0.040312      517\n",
      "0.396743      395\n",
      "0.209010      394\n",
      "0.873684      371\n",
      "0.818808      320\n",
      "0.906474      268\n",
      "0.608767      249\n",
      "0.701063      248\n",
      "0.863097      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_1, dtype: int64\n",
      "41082\n",
      "CAD_DEMOGRAFICO_VAR_2\n",
      "0.000000    25126\n",
      "0.989493      522\n",
      "0.998899      397\n",
      "0.838472      395\n",
      "0.885520      371\n",
      "0.535248      320\n",
      "0.779409      267\n",
      "0.998439      249\n",
      "0.564296      248\n",
      "0.359907      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_2, dtype: int64\n",
      "40729\n",
      "CAD_DEMOGRAFICO_VAR_3\n",
      "0.000000    25126\n",
      "0.987110      517\n",
      "0.972762      395\n",
      "0.995386      395\n",
      "0.008934      371\n",
      "0.693235      320\n",
      "0.489917      267\n",
      "0.052614      249\n",
      "0.004468      248\n",
      "0.109779      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_3, dtype: int64\n",
      "41294\n",
      "CAD_DEMOGRAFICO_VAR_4\n",
      "0.000000    25126\n",
      "0.022697      517\n",
      "0.045476      395\n",
      "0.043169      394\n",
      "0.963439      371\n",
      "0.968847      320\n",
      "0.976295      267\n",
      "0.999176      250\n",
      "0.789861      249\n",
      "0.998518      248\n",
      "Name: CAD_DEMOGRAFICO_VAR_4, dtype: int64\n",
      "40785\n",
      "CAD_DEMOGRAFICO_VAR_5\n",
      "0.000000    25126\n",
      "0.012063      517\n",
      "0.269885      395\n",
      "0.282468      394\n",
      "0.943856      371\n",
      "0.978815      322\n",
      "0.987182      267\n",
      "0.993987      249\n",
      "0.899048      248\n",
      "0.945438      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_5, dtype: int64\n",
      "39607\n",
      "CAD_DEMOGRAFICO_VAR_6\n",
      "0.000000    25126\n",
      "0.958932      517\n",
      "0.449129      395\n",
      "0.862243      394\n",
      "0.710904      371\n",
      "0.331384      320\n",
      "0.992104      267\n",
      "0.779666      249\n",
      "0.503754      248\n",
      "0.605663      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_6, dtype: int64\n",
      "41065\n",
      "CAD_DEMOGRAFICO_VAR_7\n",
      "0.000000    25126\n",
      "0.985317      517\n",
      "0.995418      396\n",
      "0.882730      395\n",
      "0.008898      371\n",
      "0.065813      322\n",
      "0.017847      267\n",
      "0.031452      249\n",
      "0.335856      249\n",
      "0.002856      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_7, dtype: int64\n",
      "41248\n",
      "CAD_DEMOGRAFICO_VAR_8\n",
      "0.000000    25126\n",
      "0.003971      517\n",
      "0.999475      416\n",
      "0.807542      394\n",
      "0.922812      371\n",
      "0.005801      320\n",
      "0.999546      272\n",
      "0.826861      267\n",
      "0.853727      249\n",
      "0.018307      248\n",
      "Name: CAD_DEMOGRAFICO_VAR_8, dtype: int64\n",
      "19014\n",
      "CAD_DEMOGRAFICO_VAR_10\n",
      "0.000000    25126\n",
      "0.993323      517\n",
      "0.336118      395\n",
      "0.033679      394\n",
      "0.641228      371\n",
      "0.976283      320\n",
      "0.503201      267\n",
      "0.082427      250\n",
      "0.320616      249\n",
      "0.224403      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_10, dtype: int64\n",
      "41278\n",
      "CAD_DEMOGRAFICO_VAR_11\n",
      "0.000000    25126\n",
      "0.007490      517\n",
      "0.039769      395\n",
      "0.555661      394\n",
      "0.887487      371\n",
      "0.096545      320\n",
      "0.992439      270\n",
      "0.627339      267\n",
      "0.489805      248\n",
      "0.954182      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_11, dtype: int64\n",
      "41387\n",
      "CAD_DEMOGRAFICO_VAR_13\n",
      "0.000000    25126\n",
      "0.003422      520\n",
      "0.998974      395\n",
      "0.304410      394\n",
      "0.010760      372\n",
      "0.039413      320\n",
      "0.016907      267\n",
      "0.370168      249\n",
      "0.073925      248\n",
      "0.043512      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_13, dtype: int64\n",
      "37708\n",
      "CAD_DEMOGRAFICO_VAR_14\n",
      "0.000000    25126\n",
      "0.002933      517\n",
      "0.792059      395\n",
      "0.057010      394\n",
      "0.838217      371\n",
      "0.998249      321\n",
      "0.969553      267\n",
      "0.964569      249\n",
      "0.497979      248\n",
      "0.405989      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_14, dtype: int64\n",
      "40866\n",
      "CAD_DEMOGRAFICO_VAR_15\n",
      "0.000000    25126\n",
      "0.976251      517\n",
      "0.959851      395\n",
      "0.947507      394\n",
      "0.799402      373\n",
      "0.944919      320\n",
      "0.929839      267\n",
      "0.441613      249\n",
      "0.792720      248\n",
      "0.637405      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_15, dtype: int64\n",
      "41354\n",
      "CAD_DEMOGRAFICO_VAR_16\n",
      "0.000000    25126\n",
      "0.004232      517\n",
      "0.901381      395\n",
      "0.080766      394\n",
      "0.045935      371\n",
      "0.080150      320\n",
      "0.134445      267\n",
      "0.620366      249\n",
      "0.014748      248\n",
      "0.507049      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_16, dtype: int64\n",
      "41273\n",
      "CAD_DEMOGRAFICO_VAR_17\n",
      "0.000000    25126\n",
      "0.037255      517\n",
      "0.998928      497\n",
      "0.000253      408\n",
      "0.964458      395\n",
      "0.963185      320\n",
      "0.989980      267\n",
      "0.998417      252\n",
      "0.967579      249\n",
      "0.991472      245\n",
      "Name: CAD_DEMOGRAFICO_VAR_17, dtype: int64\n",
      "32218\n",
      "CAD_DEMOGRAFICO_VAR_19\n",
      "0.000000    25126\n",
      "0.000037      629\n",
      "0.999987      569\n",
      "0.000063      560\n",
      "0.999998      556\n",
      "0.999999      548\n",
      "0.002678      518\n",
      "0.999985      446\n",
      "0.000076      435\n",
      "0.999995      431\n",
      "Name: CAD_DEMOGRAFICO_VAR_19, dtype: int64\n",
      "22456\n",
      "CAD_DEMOGRAFICO_VAR_21\n",
      "0.000000    25126\n",
      "0.017351      517\n",
      "0.991670      395\n",
      "0.238135      394\n",
      "0.634559      371\n",
      "0.364606      320\n",
      "0.170363      267\n",
      "0.100960      249\n",
      "0.216848      248\n",
      "0.505530      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_21, dtype: int64\n",
      "41264\n",
      "CAD_DEMOGRAFICO_VAR_22\n",
      "0.000000    25126\n",
      "0.031813      517\n",
      "0.982244      395\n",
      "0.993852      395\n",
      "0.583199      371\n",
      "0.009870      320\n",
      "0.010279      267\n",
      "0.008048      249\n",
      "0.145849      248\n",
      "0.079105      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_22, dtype: int64\n",
      "40432\n",
      "CAD_DEMOGRAFICO_VAR_23\n",
      "0.000000    25126\n",
      "0.992942      517\n",
      "0.136754      395\n",
      "0.994052      394\n",
      "0.673335      371\n",
      "0.024422      320\n",
      "0.527489      267\n",
      "0.397584      249\n",
      "0.067695      248\n",
      "0.209691      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_23, dtype: int64\n",
      "41446\n",
      "CAD_DEMOGRAFICO_VAR_24\n",
      "0.000000    25126\n",
      "0.978205      517\n",
      "0.615352      395\n",
      "0.095653      394\n",
      "0.722526      371\n",
      "0.006292      320\n",
      "0.120610      267\n",
      "0.324291      249\n",
      "0.322618      248\n",
      "0.960056      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_24, dtype: int64\n",
      "41296\n",
      "CAD_DEMOGRAFICO_VAR_25\n",
      "0.000000    25126\n",
      "0.791048      517\n",
      "0.838127      395\n",
      "0.772585      394\n",
      "0.969985      371\n",
      "0.015573      323\n",
      "0.761632      267\n",
      "0.016869      253\n",
      "0.474924      248\n",
      "0.760417      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_25, dtype: int64\n",
      "38323\n",
      "CAD_DEMOGRAFICO_VAR_26\n",
      "0.000000    25126\n",
      "0.025606      517\n",
      "0.994045      395\n",
      "0.989887      394\n",
      "0.991948      371\n",
      "0.992075      320\n",
      "0.990596      267\n",
      "0.973544      249\n",
      "0.987543      248\n",
      "0.963862      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_26, dtype: int64\n",
      "41361\n",
      "CAD_DEMOGRAFICO_VAR_27\n",
      "0.000000    25126\n",
      "0.973584      517\n",
      "0.923571      395\n",
      "0.458836      394\n",
      "0.671476      371\n",
      "0.987169      320\n",
      "0.760318      267\n",
      "0.496887      249\n",
      "0.160566      248\n",
      "0.709441      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_27, dtype: int64\n",
      "40961\n",
      "CAD_DEMOGRAFICO_VAR_28\n",
      "0.000000    25126\n",
      "0.025227      517\n",
      "0.480200      395\n",
      "0.045757      394\n",
      "0.911405      371\n",
      "0.968164      325\n",
      "0.618670      267\n",
      "0.069670      249\n",
      "0.507606      248\n",
      "0.957693      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_28, dtype: int64\n",
      "41438\n",
      "CAD_DEMOGRAFICO_VAR_30\n",
      "0.000000    25126\n",
      "0.013986      517\n",
      "0.424137      395\n",
      "0.999883      394\n",
      "0.156681      371\n",
      "0.315356      320\n",
      "0.794873      267\n",
      "0.693926      250\n",
      "0.982943      248\n",
      "0.760080      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_30, dtype: int64\n",
      "41171\n",
      "CAD_DEMOGRAFICO_VAR_31\n",
      "0.000000    25126\n",
      "0.987138      517\n",
      "0.095134      398\n",
      "0.500496      394\n",
      "0.036774      371\n",
      "0.021727      320\n",
      "0.019823      267\n",
      "0.035938      249\n",
      "0.017232      248\n",
      "0.165333      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_31, dtype: int64\n",
      "40896\n",
      "CAD_DEMOGRAFICO_VAR_33\n",
      "0.000000    25126\n",
      "0.039500      517\n",
      "0.933549      395\n",
      "0.939612      394\n",
      "0.007087      372\n",
      "0.052203      320\n",
      "0.083365      267\n",
      "0.202751      249\n",
      "0.135881      248\n",
      "0.113060      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_33, dtype: int64\n",
      "41078\n",
      "CAD_DEMOGRAFICO_VAR_34\n",
      "0.000000    25126\n",
      "0.996157      517\n",
      "0.958168      395\n",
      "0.965408      394\n",
      "0.149179      371\n",
      "0.001959      320\n",
      "0.036582      267\n",
      "0.012262      249\n",
      "0.003623      248\n",
      "0.995214      245\n",
      "Name: CAD_DEMOGRAFICO_VAR_34, dtype: int64\n",
      "36891\n",
      "CAD_DEMOGRAFICO_VAR_35\n",
      "0.000000    25126\n",
      "0.957224      517\n",
      "0.992920      395\n",
      "0.112137      394\n",
      "0.170196      371\n",
      "0.378482      320\n",
      "0.047683      267\n",
      "0.283356      249\n",
      "0.381318      248\n",
      "0.056517      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_35, dtype: int64\n",
      "41168\n",
      "CAD_DEMOGRAFICO_VAR_36\n",
      "0.000000    25126\n",
      "0.990461      519\n",
      "0.882631      395\n",
      "0.840922      394\n",
      "0.086666      371\n",
      "0.089409      320\n",
      "0.363218      267\n",
      "0.030563      249\n",
      "0.149357      248\n",
      "0.007676      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_36, dtype: int64\n",
      "39885\n",
      "CAD_DEMOGRAFICO_VAR_37\n",
      "0.000000    25126\n",
      "0.007406      519\n",
      "0.489579      395\n",
      "0.985987      394\n",
      "0.977308      372\n",
      "0.643099      320\n",
      "0.963047      267\n",
      "0.920343      249\n",
      "0.974953      248\n",
      "0.979374      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_37, dtype: int64\n",
      "39833\n",
      "CAD_DEMOGRAFICO_VAR_38\n",
      "0.000000    25126\n",
      "0.994157      517\n",
      "0.333299      395\n",
      "0.289495      394\n",
      "0.716329      371\n",
      "0.052726      320\n",
      "0.970953      267\n",
      "0.082572      249\n",
      "0.873123      248\n",
      "0.042640      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_38, dtype: int64\n",
      "40732\n",
      "CAD_DEMOGRAFICO_VAR_39\n",
      "0.000000    25126\n",
      "0.919202      517\n",
      "0.556019      395\n",
      "0.324641      394\n",
      "0.021359      371\n",
      "0.002606      320\n",
      "0.002779      271\n",
      "0.004883      267\n",
      "0.040914      249\n",
      "0.939007      248\n",
      "Name: CAD_DEMOGRAFICO_VAR_39, dtype: int64\n",
      "41186\n",
      "CAD_DEMOGRAFICO_VAR_40\n",
      "0.000000    25126\n",
      "0.989259      518\n",
      "0.181396      395\n",
      "0.220857      394\n",
      "0.981907      372\n",
      "0.995360      320\n",
      "0.941941      267\n",
      "0.985194      249\n",
      "0.962060      248\n",
      "0.981160      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_40, dtype: int64\n",
      "37006\n",
      "CAD_DEMOGRAFICO_VAR_41\n",
      "0.000000    25126\n",
      "0.008433      517\n",
      "0.837825      395\n",
      "0.817987      394\n",
      "0.094442      371\n",
      "0.028057      320\n",
      "0.008620      301\n",
      "0.261219      267\n",
      "0.272123      248\n",
      "0.005525      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_41, dtype: int64\n",
      "41011\n",
      "CAD_DEMOGRAFICO_VAR_42\n",
      "0.000000    25126\n",
      "0.985474      517\n",
      "0.930034      395\n",
      "0.002705      394\n",
      "0.004221      371\n",
      "0.014950      321\n",
      "0.005857      269\n",
      "0.357077      249\n",
      "0.352651      248\n",
      "0.020894      245\n",
      "Name: CAD_DEMOGRAFICO_VAR_42, dtype: int64\n",
      "41337\n",
      "CAD_DEMOGRAFICO_VAR_43\n",
      "0.000000    25126\n",
      "0.018129      517\n",
      "0.962558      395\n",
      "0.951118      394\n",
      "0.856517      371\n",
      "0.751157      320\n",
      "0.112395      267\n",
      "0.291758      250\n",
      "0.997152      250\n",
      "0.930509      248\n",
      "Name: CAD_DEMOGRAFICO_VAR_43, dtype: int64\n",
      "40589\n",
      "CAD_DEMOGRAFICO_VAR_44\n",
      "0.000000    25126\n",
      "0.970443      517\n",
      "0.956441      395\n",
      "0.848736      394\n",
      "0.496023      371\n",
      "0.963518      320\n",
      "0.910697      267\n",
      "0.662755      249\n",
      "0.994678      248\n",
      "0.670155      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_44, dtype: int64\n",
      "41328\n",
      "CAD_DEMOGRAFICO_VAR_45\n",
      "0.000000    25126\n",
      "0.989486      520\n",
      "0.002111      395\n",
      "0.916289      394\n",
      "0.933879      371\n",
      "0.676835      320\n",
      "0.745547      267\n",
      "0.962982      251\n",
      "0.765626      248\n",
      "0.370513      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_45, dtype: int64\n",
      "41089\n",
      "CAD_DEMOGRAFICO_VAR_46\n",
      "0.000000    27657\n",
      "0.000001     1864\n",
      "0.999996     1773\n",
      "0.999992     1305\n",
      "0.999995     1244\n",
      "0.999989     1205\n",
      "0.999997     1202\n",
      "0.999993     1158\n",
      "0.000002     1142\n",
      "0.999994     1118\n",
      "Name: CAD_DEMOGRAFICO_VAR_46, dtype: int64\n",
      "11397\n",
      "CAD_DEMOGRAFICO_VAR_47\n",
      "0.000000    25126\n",
      "0.018602      517\n",
      "0.869920      395\n",
      "0.025413      394\n",
      "0.925734      371\n",
      "0.848635      320\n",
      "0.990051      285\n",
      "0.993679      267\n",
      "0.950776      249\n",
      "0.950815      248\n",
      "Name: CAD_DEMOGRAFICO_VAR_47, dtype: int64\n",
      "40093\n",
      "CAD_DEMOGRAFICO_VAR_50\n",
      "0.000000    25126\n",
      "0.013875      517\n",
      "0.991028      395\n",
      "0.597071      394\n",
      "0.076425      371\n",
      "0.732845      320\n",
      "0.716635      267\n",
      "0.501067      249\n",
      "0.513301      248\n",
      "0.717097      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_50, dtype: int64\n",
      "41413\n",
      "CAD_DEMOGRAFICO_VAR_52\n",
      "0.000000    25126\n",
      "0.975665      518\n",
      "0.774659      395\n",
      "0.501111      394\n",
      "0.583758      371\n",
      "0.994365      320\n",
      "0.264439      267\n",
      "0.607346      249\n",
      "0.990618      248\n",
      "0.785820      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_52, dtype: int64\n",
      "41212\n",
      "CAD_DEMOGRAFICO_VAR_53\n",
      "0.000000    25126\n",
      "0.980588      517\n",
      "0.609061      395\n",
      "0.193659      394\n",
      "0.113343      371\n",
      "0.201542      320\n",
      "0.528319      267\n",
      "0.772696      249\n",
      "0.743176      248\n",
      "0.177074      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_53, dtype: int64\n",
      "41135\n",
      "CAD_DEMOGRAFICO_VAR_54\n",
      "0.000000    25126\n",
      "0.012885      517\n",
      "0.031941      395\n",
      "0.020873      394\n",
      "0.924132      372\n",
      "0.997501      323\n",
      "0.991132      267\n",
      "0.996789      249\n",
      "0.997489      249\n",
      "0.991301      244\n",
      "Name: CAD_DEMOGRAFICO_VAR_54, dtype: int64\n",
      "38944\n",
      "CAD_DEMOGRAFICO_VAR_55\n",
      "0.000000    25126\n",
      "0.992939      522\n",
      "0.999103      396\n",
      "0.041601      394\n",
      "0.990948      371\n",
      "0.962303      320\n",
      "0.986959      267\n",
      "0.999225      249\n",
      "0.981492      248\n",
      "0.970743      245\n",
      "Name: CAD_DEMOGRAFICO_VAR_55, dtype: int64\n",
      "40569\n",
      "CAD_DEMOGRAFICO_VAR_57\n",
      "0.000000    25126\n",
      "0.008421      517\n",
      "0.867802      395\n",
      "0.063863      394\n",
      "0.142247      371\n",
      "0.967660      320\n",
      "0.959987      267\n",
      "0.949456      249\n",
      "0.439697      248\n",
      "0.894450      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_57, dtype: int64\n",
      "40755\n",
      "CAD_DEMOGRAFICO_VAR_58\n",
      "0.000000    25126\n",
      "0.005879      517\n",
      "0.002526      395\n",
      "0.380956      394\n",
      "0.006123      375\n",
      "0.007945      321\n",
      "0.988979      273\n",
      "0.009686      267\n",
      "0.002649      251\n",
      "0.040422      248\n",
      "Name: CAD_DEMOGRAFICO_VAR_58, dtype: int64\n",
      "35735\n",
      "CAD_DEMOGRAFICO_VAR_59\n",
      "0.000000    25126\n",
      "0.011486      517\n",
      "0.255540      395\n",
      "0.450253      394\n",
      "0.979131      371\n",
      "0.913440      320\n",
      "0.991781      267\n",
      "0.992934      249\n",
      "0.997089      248\n",
      "0.984619      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_59, dtype: int64\n",
      "40768\n",
      "CAD_DEMOGRAFICO_VAR_61\n",
      "0.000000    25126\n",
      "0.005768      517\n",
      "0.000835      486\n",
      "0.007768      395\n",
      "0.905352      371\n",
      "0.964857      320\n",
      "0.998470      267\n",
      "0.964221      249\n",
      "0.787865      248\n",
      "0.945109      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_61, dtype: int64\n",
      "40010\n",
      "CAD_DEMOGRAFICO_VAR_62\n",
      "0.000000    25126\n",
      "0.015690      517\n",
      "0.079488      395\n",
      "0.593470      394\n",
      "0.020256      371\n",
      "0.270722      320\n",
      "0.158964      267\n",
      "0.350418      251\n",
      "0.993589      248\n",
      "0.562213      243\n",
      "Name: CAD_DEMOGRAFICO_VAR_62, dtype: int64\n",
      "41360\n",
      "MENOR_DIST_ENDERECO_AEROPORTOS\n",
      "2.539246e-18    3401\n",
      "1.000000e+00    3310\n",
      "4.455518e-02     394\n",
      "2.801763e-02     392\n",
      "5.108797e-02     371\n",
      "6.193273e-02     319\n",
      "1.517788e-01     267\n",
      "1.840941e-01     249\n",
      "2.102735e-01     248\n",
      "1.442375e-01     243\n",
      "Name: MENOR_DIST_ENDERECO_AEROPORTOS, dtype: int64\n",
      "74965\n",
      "MENOR_DIST_ENDERECO_PARQUES_DIVERSAO\n",
      "1.000000e+00    2829\n",
      "2.770096e-18    2400\n",
      "3.754384e-02     394\n",
      "1.617548e-02     392\n",
      "6.777406e-02     371\n",
      "1.664236e-02     319\n",
      "2.750940e-01     267\n",
      "5.358099e-01     249\n",
      "5.035149e-02     248\n",
      "5.404773e-02     243\n",
      "Name: MENOR_DIST_ENDERECO_PARQUES_DIVERSAO, dtype: int64\n",
      "74822\n",
      "MENOR_DIST_ENDERECO_CAIXA_ELETRONICO\n",
      " 1.000000e+00    3416\n",
      "-5.197942e-20    2613\n",
      " 6.894711e-02     394\n",
      " 2.104202e-02     392\n",
      " 1.005299e-01     371\n",
      " 9.658023e-02     319\n",
      " 8.705225e-02     267\n",
      " 3.277823e-01     249\n",
      " 5.982250e-02     248\n",
      " 2.207974e-01     243\n",
      "Name: MENOR_DIST_ENDERECO_CAIXA_ELETRONICO, dtype: int64\n",
      "75689\n",
      "MENOR_DIST_BANCO\n",
      "1.000000    3355\n",
      "0.078665     394\n",
      "0.004037     392\n",
      "0.106025     371\n",
      "0.125061     319\n",
      "0.129556     267\n",
      "0.372201     249\n",
      "0.068398     248\n",
      "0.220930     243\n",
      "0.137108     215\n",
      "Name: MENOR_DIST_BANCO, dtype: int64\n",
      "76091\n",
      "MENOR_DIST_ENDERECO_BARES\n",
      " 1.000000e+00    3193\n",
      "-6.443398e-20    2595\n",
      " 1.046334e-01     394\n",
      " 3.965335e-02     392\n",
      " 6.429643e-02     371\n",
      " 1.319723e-01     319\n",
      " 1.272101e-01     267\n",
      " 3.858556e-01     249\n",
      " 6.198480e-02     248\n",
      " 9.904480e-02     243\n",
      "Name: MENOR_DIST_ENDERECO_BARES, dtype: int64\n",
      "75721\n",
      "MENOR_DIST_ENDERECO_ESTACAO_ONIBUS\n",
      "1.000000e+00    3924\n",
      "4.756433e-19    1586\n",
      "4.017416e-02     394\n",
      "3.269956e-03     392\n",
      "4.104545e-02     371\n",
      "5.345394e-02     319\n",
      "5.854451e-02     267\n",
      "3.996122e-01     249\n",
      "6.132947e-02     248\n",
      "1.257479e-01     243\n",
      "Name: MENOR_DIST_ENDERECO_ESTACAO_ONIBUS, dtype: int64\n",
      "75372\n",
      "MENOR_DIST_CONCESSIONARIA\n",
      "1.000000    3601\n",
      "0.036628     394\n",
      "0.020744     392\n",
      "0.030935     371\n",
      "0.064224     319\n",
      "0.058108     267\n",
      "0.162539     249\n",
      "0.032951     248\n",
      "0.135526     243\n",
      "0.037986     215\n",
      "Name: MENOR_DIST_CONCESSIONARIA, dtype: int64\n",
      "75956\n",
      "MENOR_DIST_ALUGUEL_CARROS\n",
      "1.000000e+00    3700\n",
      "7.599871e-20    2375\n",
      "2.777880e-02     394\n",
      "2.781320e-03     392\n",
      "4.249618e-02     371\n",
      "4.939028e-02     319\n",
      "6.607459e-01     267\n",
      "1.269857e-01     249\n",
      "2.987231e-02     248\n",
      "2.622454e-01     243\n",
      "Name: MENOR_DIST_ALUGUEL_CARROS, dtype: int64\n",
      "75214\n",
      "MENOR_DIST_ENDERECO_OFICINAS\n",
      "1.000000    3392\n",
      "0.000153     394\n",
      "0.014348     392\n",
      "0.020555     371\n",
      "0.058305     319\n",
      "0.056720     267\n",
      "0.310845     249\n",
      "0.043373     248\n",
      "0.195154     243\n",
      "0.057830     215\n",
      "Name: MENOR_DIST_ENDERECO_OFICINAS, dtype: int64\n",
      "76056\n",
      "MENOR_DIST_ENDERECO_LAVA_RAPIDO\n",
      " 1.000000e+00    3518\n",
      "-4.379933e-19    2049\n",
      " 5.140202e-02     394\n",
      " 1.823984e-02     392\n",
      " 3.700059e-02     371\n",
      " 6.619197e-02     319\n",
      " 7.993909e-01     267\n",
      " 1.973262e-01     249\n",
      " 3.820978e-02     248\n",
      " 1.362536e-01     243\n",
      "Name: MENOR_DIST_ENDERECO_LAVA_RAPIDO, dtype: int64\n",
      "75198\n",
      "MENOR_DIST_ENDERECO_CEMITERIO\n",
      " 1.000000e+00    3342\n",
      "-1.371173e-18    2655\n",
      " 5.523813e-02     394\n",
      " 3.017856e-02     392\n",
      " 5.487558e-02     371\n",
      " 7.888535e-02     319\n",
      " 5.301598e-02     267\n",
      " 2.372356e-01     249\n",
      " 3.655255e-02     248\n",
      " 1.359753e-01     243\n",
      "Name: MENOR_DIST_ENDERECO_CEMITERIO, dtype: int64\n",
      "74877\n",
      "MENOR_DIST_ENDERECO_IGREJA\n",
      " 1.000000e+00    3053\n",
      "-6.595748e-20    2878\n",
      " 7.560011e-02     394\n",
      " 2.059771e-02     392\n",
      " 6.125039e-02     371\n",
      " 4.109651e-02     319\n",
      " 1.043120e-01     267\n",
      " 3.744941e-01     249\n",
      " 2.283397e-02     248\n",
      " 2.039378e-01     243\n",
      "Name: MENOR_DIST_ENDERECO_IGREJA, dtype: int64\n",
      "75737\n",
      "MENOR_DIST_ENDERECO_PREFEITURA\n",
      "1.000000    3225\n",
      "0.000141     394\n",
      "0.020789     392\n",
      "0.058389     371\n",
      "0.104612     319\n",
      "0.089304     267\n",
      "0.337165     249\n",
      "0.078639     248\n",
      "0.248626     243\n",
      "0.134827     215\n",
      "Name: MENOR_DIST_ENDERECO_PREFEITURA, dtype: int64\n",
      "76121\n",
      "MENOR_DIST_ENDERECO_BOMBEIRO\n",
      " 1.000000e+00    3350\n",
      "-1.708888e-18    2635\n",
      " 2.597031e-02     394\n",
      " 1.335011e-02     392\n",
      " 2.200075e-02     371\n",
      " 4.877819e-02     319\n",
      " 3.260193e-02     267\n",
      " 1.436401e-01     249\n",
      " 3.060983e-02     248\n",
      " 7.800987e-02     243\n",
      "Name: MENOR_DIST_ENDERECO_BOMBEIRO, dtype: int64\n",
      "75050\n",
      "MENOR_DIST_ENDERECO_FAVELA\n",
      " 1.000000e+00    4903\n",
      "-6.974137e-21    2073\n",
      " 2.562051e-03     394\n",
      " 3.539302e-02     392\n",
      " 1.836316e-01     371\n",
      " 4.694967e-01     319\n",
      " 8.060681e-01     267\n",
      " 3.888943e-02     248\n",
      " 3.518173e-01     243\n",
      " 1.501282e-01     215\n",
      "Name: MENOR_DIST_ENDERECO_FAVELA, dtype: int64\n",
      "74184\n",
      "MENOR_DIST_ENDERECO_FUNERARIA\n",
      "1.000000e+00    3325\n",
      "2.116851e-19    2928\n",
      "4.224142e-02     394\n",
      "2.341346e-02     392\n",
      "3.733457e-02     371\n",
      "7.444900e-02     319\n",
      "7.714812e-02     267\n",
      "2.006598e-01     249\n",
      "4.316056e-02     248\n",
      "1.248303e-01     243\n",
      "Name: MENOR_DIST_ENDERECO_FUNERARIA, dtype: int64\n",
      "75036\n",
      "MENOR_DIST_ENDERECO_POSTO_GASOLINA\n",
      "1.000000    3439\n",
      "0.039122     394\n",
      "0.057674     392\n",
      "0.055989     371\n",
      "0.106645     319\n",
      "0.053665     267\n",
      "0.407753     249\n",
      "0.055373     248\n",
      "0.000043     243\n",
      "0.065250     215\n",
      "Name: MENOR_DIST_ENDERECO_POSTO_GASOLINA, dtype: int64\n",
      "76068\n",
      "MENOR_DIST_ENDERECO_SUPERMERCADO\n",
      "1.000000    3193\n",
      "0.103830     394\n",
      "0.058541     392\n",
      "0.015525     371\n",
      "0.127366     319\n",
      "0.000214     267\n",
      "0.397360     249\n",
      "0.033640     248\n",
      "0.212808     243\n",
      "0.139259     215\n",
      "Name: MENOR_DIST_ENDERECO_SUPERMERCADO, dtype: int64\n",
      "76116\n",
      "MENOR_DIST_ENDERECO_ACADEMIAS\n",
      " 1.000000e+00    3436\n",
      "-4.548199e-20    1952\n",
      " 2.607871e-02     394\n",
      " 2.147866e-02     392\n",
      " 6.985113e-02     371\n",
      " 1.099460e-01     319\n",
      " 8.679613e-02     267\n",
      " 2.810976e-01     249\n",
      " 4.403385e-02     248\n",
      " 1.768822e-01     243\n",
      "Name: MENOR_DIST_ENDERECO_ACADEMIAS, dtype: int64\n",
      "75811\n",
      "MENOR_DIST_ENDERECO_HOSPITAL\n",
      " 1.000000e+00    3962\n",
      "-3.140927e-20    2761\n",
      " 3.613646e-02     394\n",
      " 3.232807e-03     392\n",
      " 2.482019e-02     371\n",
      " 7.247690e-02     319\n",
      " 5.346287e-02     267\n",
      " 1.930042e-01     249\n",
      " 4.224334e-02     248\n",
      " 9.586353e-02     243\n",
      "Name: MENOR_DIST_ENDERECO_HOSPITAL, dtype: int64\n",
      "75551\n",
      "MENOR_DIST_CORRETOR_SEGUROS\n",
      " 1.000000e+00    4717\n",
      "-9.457537e-20    3346\n",
      " 1.124008e-02     394\n",
      " 2.808479e-03     392\n",
      " 1.635467e-01     371\n",
      " 1.822354e-02     319\n",
      " 1.164961e-01     267\n",
      " 4.508174e-01     249\n",
      " 9.318787e-02     248\n",
      " 2.929726e-02     243\n",
      "Name: MENOR_DIST_CORRETOR_SEGUROS, dtype: int64\n",
      "74538\n",
      "MENOR_DIST_ENDERECO_BEBIDAS\n",
      " 1.000000e+00    2861\n",
      "-8.305931e-20    2328\n",
      " 1.154678e-02     394\n",
      " 6.295477e-03     392\n",
      " 1.283328e-02     371\n",
      " 1.874329e-02     319\n",
      " 2.268720e-01     267\n",
      " 9.102872e-02     249\n",
      " 1.076419e-02     248\n",
      " 1.521498e-01     243\n",
      "Name: MENOR_DIST_ENDERECO_BEBIDAS, dtype: int64\n",
      "75191\n",
      "MENOR_DIST_ENDERECO_HOTEL\n",
      "1.000000    3428\n",
      "0.133270     394\n",
      "0.059226     392\n",
      "0.084463     371\n",
      "0.105030     319\n",
      "0.044143     267\n",
      "0.334819     249\n",
      "0.045229     248\n",
      "0.279692     243\n",
      "0.089196     215\n",
      "Name: MENOR_DIST_ENDERECO_HOTEL, dtype: int64\n",
      "76057\n",
      "MENOR_DIST_ENDERECO_CINEMAS\n",
      " 1.000000e+00    3223\n",
      "-3.831494e-18    3167\n",
      " 3.378340e-02     394\n",
      " 9.285169e-03     392\n",
      " 3.364686e-02     371\n",
      " 3.133821e-01     319\n",
      " 3.993402e-02     267\n",
      " 6.313191e-01     249\n",
      " 2.513264e-02     248\n",
      " 7.765493e-02     243\n",
      "Name: MENOR_DIST_ENDERECO_CINEMAS, dtype: int64\n",
      "74981\n",
      "MENOR_DIST_ENDERECO_CASA_NOTURNA\n",
      "1.000000e+00    3404\n",
      "7.983483e-19    2355\n",
      "5.519930e-02     394\n",
      "2.953183e-02     392\n",
      "2.816648e-02     371\n",
      "8.993286e-02     319\n",
      "4.871137e-01     267\n",
      "2.467815e-01     249\n",
      "4.671487e-02     248\n",
      "1.567958e-01     243\n",
      "Name: MENOR_DIST_ENDERECO_CASA_NOTURNA, dtype: int64\n",
      "75203\n",
      "MENOR_DIST_ENDERECO_PARQUE\n",
      " 1.000000e+00    3470\n",
      "-6.554914e-19    2067\n",
      " 8.212750e-02     394\n",
      " 4.694045e-03     392\n",
      " 4.064626e-02     371\n",
      " 1.008627e-01     319\n",
      " 5.541076e-02     267\n",
      " 3.177421e-01     249\n",
      " 8.412781e-02     248\n",
      " 2.072835e-01     243\n",
      "Name: MENOR_DIST_ENDERECO_PARQUE, dtype: int64\n",
      "75210\n",
      "MENOR_DIST_ESTACIONAMENTOS\n",
      "1.000000e+00    3160\n",
      "3.079579e-19    2969\n",
      "1.444275e-02     394\n",
      "2.397857e-03     392\n",
      "2.881845e-02     371\n",
      "4.130666e-02     319\n",
      "2.865836e-01     267\n",
      "9.983412e-02     249\n",
      "2.492172e-02     248\n",
      "8.886379e-02     243\n",
      "Name: MENOR_DIST_ESTACIONAMENTOS, dtype: int64\n",
      "74963\n",
      "MENOR_DIST_ENDERECO_POLICIA\n",
      "3.907195e-20    2726\n",
      "1.000000e+00    2332\n",
      "1.449352e-02     394\n",
      "5.063025e-03     392\n",
      "2.539737e-01     371\n",
      "5.475057e-01     319\n",
      "1.378220e-02     248\n",
      "1.733407e-01     243\n",
      "2.094781e-01     215\n",
      "3.741287e-01     208\n",
      "Name: MENOR_DIST_ENDERECO_POLICIA, dtype: int64\n",
      "75378\n",
      "MENOR_DIST_ENDERECO_CORREIOS\n",
      "1.493065e-18    3294\n",
      "1.000000e+00    2527\n",
      "9.893134e-03     394\n",
      "1.031300e-03     392\n",
      "2.365512e-02     371\n",
      "1.565873e-01     319\n",
      "3.231401e-01     267\n",
      "6.368483e-01     249\n",
      "6.950849e-03     248\n",
      "1.455266e-01     243\n",
      "Name: MENOR_DIST_ENDERECO_CORREIOS, dtype: int64\n",
      "74893\n",
      "MENOR_DIST_ENDERECO_ESCOLAS\n",
      "1.000000    2948\n",
      "0.098199     394\n",
      "0.056414     392\n",
      "0.032847     371\n",
      "0.096906     319\n",
      "0.145523     267\n",
      "0.190153     249\n",
      "0.052551     248\n",
      "0.000058     243\n",
      "0.158964     215\n",
      "Name: MENOR_DIST_ENDERECO_ESCOLAS, dtype: int64\n",
      "76121\n",
      "MENOR_DIST_ENDERECO_SHOPPING\n",
      "1.000000e+00    3468\n",
      "1.186602e-19    3036\n",
      "4.777771e-02     394\n",
      "2.008229e-02     392\n",
      "3.498853e-02     371\n",
      "8.726322e-02     319\n",
      "4.929834e-02     267\n",
      "1.991860e-01     249\n",
      "3.704925e-02     248\n",
      "1.438467e-01     243\n",
      "Name: MENOR_DIST_ENDERECO_SHOPPING, dtype: int64\n",
      "74910\n",
      "MENOR_DIST_ENDERECO_METRO\n",
      "1.000000e+00    46327\n",
      "8.473269e-19     3560\n",
      "2.678521e-02      394\n",
      "4.446790e-03      392\n",
      "2.991055e-01      371\n",
      "2.129273e-01      248\n",
      "2.628248e-01      215\n",
      "3.517178e-01      208\n",
      "2.562833e-01      194\n",
      "1.488942e-01      169\n",
      "Name: MENOR_DIST_ENDERECO_METRO, dtype: int64\n",
      "60709\n",
      "MENOR_DIST_PONTO_TAXI\n",
      "1.000000e+00    3015\n",
      "8.534396e-20    2625\n",
      "2.895084e-02     394\n",
      "1.175790e-02     392\n",
      "1.899704e-02     371\n",
      "3.435091e-02     319\n",
      "3.735749e-01     267\n",
      "7.522638e-02     249\n",
      "1.729237e-02     248\n",
      "4.046433e-01     243\n",
      "Name: MENOR_DIST_PONTO_TAXI, dtype: int64\n",
      "74745\n",
      "MENOR_DIST_ENDERECO_TREM\n",
      " 1.000000e+00    15367\n",
      "-1.245274e-18     2256\n",
      " 4.693475e-02      394\n",
      " 8.683823e-01      392\n",
      " 2.244713e-02      371\n",
      " 4.717132e-01      319\n",
      " 6.682426e-01      267\n",
      " 8.030674e-01      249\n",
      " 5.832251e-02      248\n",
      " 9.339127e-01      243\n",
      "Name: MENOR_DIST_ENDERECO_TREM, dtype: int64\n",
      "70937\n",
      "MENOR_DIST_UNIVERSIDADE\n",
      " 1.000000e+00    3428\n",
      "-3.924331e-19    2968\n",
      " 1.782199e-02     394\n",
      " 2.025158e-02     392\n",
      " 5.279241e-02     371\n",
      " 9.525572e-02     319\n",
      " 3.943389e-02     267\n",
      " 1.967114e-01     249\n",
      " 2.614324e-02     248\n",
      " 1.708475e-01     243\n",
      "Name: MENOR_DIST_UNIVERSIDADE, dtype: int64\n",
      "75079\n",
      "MENOR_DIST_ENDERECO_FRONTEIRA_ESTADUAL\n",
      "8.425253e-19    2338\n",
      "1.000000e+00    2254\n",
      "2.178323e-02     394\n",
      "1.477244e-01     392\n",
      "3.687333e-01     371\n",
      "4.277294e-01     319\n",
      "2.491539e-01     267\n",
      "7.180600e-02     249\n",
      "3.551824e-01     248\n",
      "6.602487e-02     243\n",
      "Name: MENOR_DIST_ENDERECO_FRONTEIRA_ESTADUAL, dtype: int64\n",
      "74899\n",
      "MENOR_DIST_ENDERECO_FRONTEIRA_MARITIMA\n",
      " 1.000000e+00    59152\n",
      "-1.109648e-17     2226\n",
      " 7.181341e-02      394\n",
      " 3.028137e-01      371\n",
      " 2.892596e-01      248\n",
      " 2.652864e-01      215\n",
      " 3.329858e-01      208\n",
      " 3.214180e-01      194\n",
      " 2.449441e-01      169\n",
      " 1.361561e-01      160\n",
      "Name: MENOR_DIST_ENDERECO_FRONTEIRA_MARITIMA, dtype: int64\n",
      "55215\n",
      "MENOR_DIST_ENDERECO_FRONTEIRA_INTERNACIONAL\n",
      "1.000000e+00    171202\n",
      "1.312635e-16      2012\n",
      "3.702257e-01       319\n",
      "1.826407e-01       267\n",
      "9.079855e-02       249\n",
      "6.578699e-01       159\n",
      "4.683321e-01       151\n",
      "4.929721e-01       151\n",
      "9.092993e-01       140\n",
      "2.641283e-01       136\n",
      "Name: MENOR_DIST_ENDERECO_FRONTEIRA_INTERNACIONAL, dtype: int64\n",
      "5417\n",
      "EXPOSICAO_ENDERECO_AEROPORTOS\n",
      "0.000000    107731\n",
      "0.015385     28570\n",
      "0.030769     16640\n",
      "0.046154      7120\n",
      "0.076923      5286\n",
      "0.061538      5099\n",
      "0.107692      3930\n",
      "1.000000      3798\n",
      "0.092308      3652\n",
      "0.123077      2550\n",
      "Name: EXPOSICAO_ENDERECO_AEROPORTOS, dtype: int64\n",
      "66\n",
      "EXPOSICAO_ENDERECO_PARQUES_DIVERSAO\n",
      "0.0    103591\n",
      "0.1     29140\n",
      "0.2     17219\n",
      "0.3     13824\n",
      "0.4      9273\n",
      "0.6      5070\n",
      "0.5      4708\n",
      "1.0      4422\n",
      "0.7      3495\n",
      "0.8      2022\n",
      "Name: EXPOSICAO_ENDERECO_PARQUES_DIVERSAO, dtype: int64\n",
      "11\n",
      "EXPOSICAO_ENDERECO_AREA_RISCO\n",
      "0.000000    78533\n",
      "0.013825     9107\n",
      "0.023041     6160\n",
      "0.018433     6093\n",
      "0.027650     4183\n",
      "0.032258     3776\n",
      "0.046083     3404\n",
      "0.036866     3046\n",
      "0.050691     2641\n",
      "0.041475     2625\n",
      "Name: EXPOSICAO_ENDERECO_AREA_RISCO, dtype: int64\n",
      "218\n",
      "EXPOSICAO_ENDERECO_CAIXA_ELETRONICO\n",
      "0.000000    45307\n",
      "0.003704     7776\n",
      "0.007407     4586\n",
      "0.011111     3941\n",
      "0.014815     3364\n",
      "0.033333     3321\n",
      "0.018519     3203\n",
      "0.029630     3058\n",
      "0.022222     2973\n",
      "1.000000     2867\n",
      "Name: EXPOSICAO_ENDERECO_CAIXA_ELETRONICO, dtype: int64\n",
      "271\n",
      "EXPOSICAO_ENDERECO_BANCOS\n",
      "0.000000    41498\n",
      "0.004425     7745\n",
      "0.008850     5019\n",
      "0.013274     3556\n",
      "0.017699     3185\n",
      "0.035398     3018\n",
      "0.022124     2844\n",
      "0.030973     2797\n",
      "0.026549     2742\n",
      "1.000000     2718\n",
      "Name: EXPOSICAO_ENDERECO_BANCOS, dtype: int64\n",
      "227\n",
      "EXPOSICAO_ENDERECO_BARES\n",
      "0.000000    34755\n",
      "0.002041     9714\n",
      "0.004082     5591\n",
      "0.006122     4542\n",
      "0.008163     3450\n",
      "0.010204     3369\n",
      "0.018367     3107\n",
      "0.012245     2776\n",
      "0.014286     2603\n",
      "1.000000     2569\n",
      "Name: EXPOSICAO_ENDERECO_BARES, dtype: int64\n",
      "491\n",
      "EXPOSICAO_ENDERECO_ESTACAO_ONIBUS\n",
      "0.000000    64764\n",
      "0.000585    21753\n",
      "0.001170    11464\n",
      "0.001754     7027\n",
      "0.002339     3584\n",
      "1.000000     2598\n",
      "0.003509     2425\n",
      "0.002924     1948\n",
      "0.004094     1255\n",
      "0.004678     1192\n",
      "Name: EXPOSICAO_ENDERECO_ESTACAO_ONIBUS, dtype: int64\n",
      "1626\n",
      "EXPOSICAO_ENDERECO_CONCESSIONARIA\n",
      "0.000000    53199\n",
      "0.004219     6888\n",
      "0.008439     3739\n",
      "0.012658     3694\n",
      "1.000000     2609\n",
      "0.016878     2409\n",
      "0.113924     1978\n",
      "0.025316     1934\n",
      "0.054852     1927\n",
      "0.126582     1900\n",
      "Name: EXPOSICAO_ENDERECO_CONCESSIONARIA, dtype: int64\n",
      "238\n",
      "EXPOSICAO_ENDERECO_ALUGUEL_CARROS\n",
      "0.000000    69296\n",
      "0.007092     9036\n",
      "0.014184     6753\n",
      "0.021277     6200\n",
      "0.028369     5455\n",
      "0.035461     4181\n",
      "0.049645     4003\n",
      "0.042553     3558\n",
      "1.000000     3061\n",
      "0.070922     2941\n",
      "Name: EXPOSICAO_ENDERECO_ALUGUEL_CARROS, dtype: int64\n",
      "142\n",
      "EXPOSICAO_ENDERECO_OFICINAS\n",
      "0.000000    35706\n",
      "0.001730     7400\n",
      "0.003460     4006\n",
      "0.005190     3790\n",
      "0.006920     3073\n",
      "0.008651     2456\n",
      "1.000000     2143\n",
      "0.010381     2140\n",
      "0.019031     2066\n",
      "0.013841     1809\n",
      "Name: EXPOSICAO_ENDERECO_OFICINAS, dtype: int64\n",
      "579\n",
      "EXPOSICAO_ENDERECO_LAVA_RAPIDO\n",
      "0.000000    57760\n",
      "0.004762     9373\n",
      "0.009524     5582\n",
      "0.014286     3501\n",
      "0.028571     3341\n",
      "0.019048     3166\n",
      "0.023810     3028\n",
      "1.000000     3012\n",
      "0.038095     2403\n",
      "0.057143     2302\n",
      "Name: EXPOSICAO_ENDERECO_LAVA_RAPIDO, dtype: int64\n",
      "211\n",
      "EXPOSICAO_ENDERECO_CEMITERIO\n",
      "0.000000    56283\n",
      "0.030303    24726\n",
      "0.060606    20853\n",
      "0.090909    15315\n",
      "0.121212    12375\n",
      "0.151515     9124\n",
      "0.181818     7119\n",
      "0.212121     5591\n",
      "0.272727     4842\n",
      "0.242424     4486\n",
      "Name: EXPOSICAO_ENDERECO_CEMITERIO, dtype: int64\n",
      "34\n",
      "EXPOSICAO_ENDERECO_IGREJA\n",
      "0.000000    30846\n",
      "0.003367     8332\n",
      "0.006734     4666\n",
      "0.010101     4377\n",
      "0.013468     3720\n",
      "0.020202     2745\n",
      "0.087542     2582\n",
      "0.016835     2418\n",
      "0.023569     2239\n",
      "0.090909     2230\n",
      "Name: EXPOSICAO_ENDERECO_IGREJA, dtype: int64\n",
      "298\n",
      "EXPOSICAO_ENDERECO_PREFEITURA\n",
      "0.000000    42361\n",
      "0.014493    14972\n",
      "0.028986    12951\n",
      "0.043478    10721\n",
      "0.057971     8387\n",
      "0.086957     7321\n",
      "0.072464     7096\n",
      "0.115942     6032\n",
      "0.101449     5528\n",
      "0.130435     5262\n",
      "Name: EXPOSICAO_ENDERECO_PREFEITURA, dtype: int64\n",
      "70\n",
      "EXPOSICAO_ENDERECO_BOMBEIRO\n",
      "0.00    72107\n",
      "0.04    24132\n",
      "0.08    18857\n",
      "0.12    14011\n",
      "0.16    10377\n",
      "0.20     8691\n",
      "0.24     8564\n",
      "0.28     5916\n",
      "0.32     4919\n",
      "0.36     3945\n",
      "Name: EXPOSICAO_ENDERECO_BOMBEIRO, dtype: int64\n",
      "26\n",
      "EXPOSICAO_ENDERECO_FAVELAS\n",
      "0.000000    97760\n",
      "1.000000     1553\n",
      "0.032330      423\n",
      "0.003369      352\n",
      "0.001720      350\n",
      "0.001792      324\n",
      "0.002867      318\n",
      "0.003297      311\n",
      "0.001290      306\n",
      "0.000932      303\n",
      "Name: EXPOSICAO_ENDERECO_FAVELAS, dtype: int64\n",
      "7933\n",
      "EXPOSICAO_ENDERECO_FUNERARIA\n",
      "0.000000    58802\n",
      "0.015873    13727\n",
      "0.031746    11950\n",
      "0.047619     9228\n",
      "0.063492     8480\n",
      "0.079365     7937\n",
      "0.095238     6709\n",
      "0.111111     5182\n",
      "0.126984     5157\n",
      "0.142857     4885\n",
      "Name: EXPOSICAO_ENDERECO_FUNERARIA, dtype: int64\n",
      "64\n",
      "EXPOSICAO_ENDERECO_POSTO_GASOLINA\n",
      "0.000000    32861\n",
      "0.004237     8398\n",
      "0.008475     5764\n",
      "0.012712     4198\n",
      "0.016949     3184\n",
      "0.021186     2893\n",
      "0.063559     2682\n",
      "0.025424     2653\n",
      "0.033898     2461\n",
      "0.029661     2434\n",
      "Name: EXPOSICAO_ENDERECO_POSTO_GASOLINA, dtype: int64\n",
      "237\n",
      "EXPOSICAO_ENDERECO_SUPERMERCADO\n",
      "0.000000    33011\n",
      "0.003155     7584\n",
      "0.006309     4850\n",
      "0.009464     3214\n",
      "0.028391     3016\n",
      "0.015773     2960\n",
      "0.012618     2754\n",
      "0.044164     2401\n",
      "0.018927     2359\n",
      "0.066246     2222\n",
      "Name: EXPOSICAO_ENDERECO_SUPERMERCADO, dtype: int64\n",
      "318\n",
      "EXPOSICAO_ENDERECO_ACADEMIAS\n",
      "0.000000    46412\n",
      "0.003571     6473\n",
      "0.007143     5379\n",
      "0.010714     3800\n",
      "0.014286     2653\n",
      "1.000000     2635\n",
      "0.017857     2372\n",
      "0.046429     2184\n",
      "0.039286     2112\n",
      "0.021429     1893\n",
      "Name: EXPOSICAO_ENDERECO_ACADEMIAS, dtype: int64\n",
      "281\n",
      "EXPOSICAO_ENDERECO_HOSPITAL\n",
      "0.000000    47183\n",
      "0.003413     9661\n",
      "0.006826     6397\n",
      "0.010239     4767\n",
      "0.013652     3542\n",
      "1.000000     3165\n",
      "0.017065     3104\n",
      "0.020478     2527\n",
      "0.030717     2410\n",
      "0.040956     2404\n",
      "Name: EXPOSICAO_ENDERECO_HOSPITAL, dtype: int64\n",
      "294\n",
      "EXPOSICAO_ENDERECO_CORRETOR_SEGUROS\n",
      "0.000000    77957\n",
      "0.004673     5695\n",
      "0.009346     4658\n",
      "0.014019     3384\n",
      "0.023364     3333\n",
      "0.060748     2808\n",
      "0.018692     2752\n",
      "0.070093     2597\n",
      "0.065421     2546\n",
      "1.000000     2382\n",
      "Name: EXPOSICAO_ENDERECO_CORRETOR_SEGUROS, dtype: int64\n",
      "215\n",
      "EXPOSICAO_ENDERECO_BEBIDAS\n",
      "0.000000    73639\n",
      "0.010638     9591\n",
      "0.021277     6208\n",
      "0.053191     5188\n",
      "0.031915     5142\n",
      "0.042553     4637\n",
      "0.085106     3809\n",
      "0.074468     3806\n",
      "1.000000     3255\n",
      "0.095745     3239\n",
      "Name: EXPOSICAO_ENDERECO_BEBIDAS, dtype: int64\n",
      "95\n",
      "EXPOSICAO_ENDERECO_HOTEL\n",
      "0.000000    36398\n",
      "0.004016    10366\n",
      "0.008032     7995\n",
      "0.012048     6452\n",
      "0.016064     5546\n",
      "0.020080     3998\n",
      "0.024096     3675\n",
      "0.028112     3518\n",
      "0.032129     3048\n",
      "0.052209     3046\n",
      "Name: EXPOSICAO_ENDERECO_HOTEL, dtype: int64\n",
      "250\n",
      "EXPOSICAO_ENDERECO_CINEMAS\n",
      "0.000000    77873\n",
      "0.008621    19433\n",
      "0.017241    14819\n",
      "0.025862    11653\n",
      "0.034483     8860\n",
      "0.043103     6849\n",
      "0.051724     6083\n",
      "0.060345     4949\n",
      "0.077586     4090\n",
      "0.068966     3626\n",
      "Name: EXPOSICAO_ENDERECO_CINEMAS, dtype: int64\n",
      "117\n",
      "EXPOSICAO_ENDERECO_CASA_NOTURNA\n",
      "0.000000    50354\n",
      "0.007042     9328\n",
      "0.014085     6380\n",
      "0.035211     4331\n",
      "0.021127     4134\n",
      "0.028169     4101\n",
      "1.000000     3359\n",
      "0.056338     2959\n",
      "0.098592     2896\n",
      "0.070423     2784\n",
      "Name: EXPOSICAO_ENDERECO_CASA_NOTURNA, dtype: int64\n",
      "143\n",
      "EXPOSICAO_ENDERECO_PARQUE\n",
      "0.000000    45426\n",
      "0.010870    10106\n",
      "0.021739     6757\n",
      "0.032609     6028\n",
      "0.076087     5916\n",
      "0.054348     5058\n",
      "0.086957     5049\n",
      "0.065217     4776\n",
      "0.108696     4736\n",
      "0.043478     4726\n",
      "Name: EXPOSICAO_ENDERECO_PARQUE, dtype: int64\n",
      "93\n",
      "EXPOSICAO_ENDERECO_ESTACIONAMENTOS\n",
      "0.000000    68810\n",
      "0.003460     9489\n",
      "0.006920     5773\n",
      "0.010381     4502\n",
      "0.013841     4497\n",
      "0.017301     3707\n",
      "0.020761     3576\n",
      "0.027682     3072\n",
      "1.000000     2755\n",
      "0.024221     2641\n",
      "Name: EXPOSICAO_ENDERECO_ESTACIONAMENTOS, dtype: int64\n",
      "290\n",
      "EXPOSICAO_ENDERECO_POLICIA\n",
      "0.000000    71856\n",
      "0.012658     7544\n",
      "0.025316     7139\n",
      "0.037975     5433\n",
      "0.050633     4789\n",
      "0.088608     4501\n",
      "0.075949     3849\n",
      "0.063291     3488\n",
      "0.101266     3343\n",
      "0.202532     3147\n",
      "Name: EXPOSICAO_ENDERECO_POLICIA, dtype: int64\n",
      "80\n",
      "EXPOSICAO_ENDERECO_CORREIOS\n",
      "0.000000    78482\n",
      "0.015385    11128\n",
      "0.030769     7895\n",
      "0.046154     6129\n",
      "0.061538     6036\n",
      "0.092308     4273\n",
      "0.107692     4030\n",
      "0.153846     4005\n",
      "0.076923     3975\n",
      "0.123077     3953\n",
      "Name: EXPOSICAO_ENDERECO_CORREIOS, dtype: int64\n",
      "66\n",
      "EXPOSICAO_ENDERECO_ESCOLAS\n",
      "0.000000    21763\n",
      "0.002899    11305\n",
      "0.005797     5695\n",
      "0.008696     4191\n",
      "0.011594     2898\n",
      "0.014493     2530\n",
      "0.017391     2325\n",
      "1.000000     2308\n",
      "0.086957     2255\n",
      "0.104348     2084\n",
      "Name: EXPOSICAO_ENDERECO_ESCOLAS, dtype: int64\n",
      "346\n",
      "EXPOSICAO_ENDERECO_SHOPPING\n",
      "0.000000    56990\n",
      "0.004310     9340\n",
      "0.008621     5450\n",
      "0.017241     5204\n",
      "0.012931     5063\n",
      "0.021552     4491\n",
      "0.030172     3601\n",
      "0.025862     3521\n",
      "0.060345     2967\n",
      "0.056034     2709\n",
      "Name: EXPOSICAO_ENDERECO_SHOPPING, dtype: int64\n",
      "233\n",
      "EXPOSICAO_ENDERECO_METRO\n",
      "0.000000    156558\n",
      "0.045455      4425\n",
      "0.318182      3694\n",
      "1.000000      3470\n",
      "0.227273      3374\n",
      "0.272727      3233\n",
      "0.181818      3074\n",
      "0.136364      2948\n",
      "0.090909      2672\n",
      "0.363636      2400\n",
      "Name: EXPOSICAO_ENDERECO_METRO, dtype: int64\n",
      "23\n",
      "EXPOSICAO_ENDERECO_PONTO_TAXI\n",
      "0.000000    85397\n",
      "0.008929    17706\n",
      "0.017857    11326\n",
      "0.026786     6660\n",
      "0.035714     6615\n",
      "0.044643     6511\n",
      "0.062500     5369\n",
      "0.053571     5335\n",
      "0.071429     4642\n",
      "1.000000     3351\n",
      "Name: EXPOSICAO_ENDERECO_PONTO_TAXI, dtype: int64\n",
      "113\n",
      "EXPOSICAO_ENDERECO_TREM\n",
      "0.000000    146725\n",
      "0.076923     14972\n",
      "0.153846      5693\n",
      "0.230769      5159\n",
      "0.307692      4456\n",
      "0.384615      3190\n",
      "0.461538      2727\n",
      "0.692308      2486\n",
      "0.538462      2424\n",
      "1.000000      2377\n",
      "Name: EXPOSICAO_ENDERECO_TREM, dtype: int64\n",
      "14\n",
      "EXPOSICAO_ENDERECO_UNIVERSIDADE\n",
      "0.000000    62339\n",
      "0.004587     7655\n",
      "0.009174     4995\n",
      "0.013761     4752\n",
      "0.022936     4459\n",
      "0.018349     3945\n",
      "0.027523     3474\n",
      "0.050459     3288\n",
      "0.055046     3280\n",
      "0.032110     3154\n",
      "Name: EXPOSICAO_ENDERECO_UNIVERSIDADE, dtype: int64\n",
      "219\n",
      "FLAG_REDE_SOCIAL_1\n",
      "1    157516\n",
      "0     37082\n",
      "Name: FLAG_REDE_SOCIAL_1, dtype: int64\n",
      "2\n",
      "FLAG_REDE_SOCIAL_2\n",
      "0    175707\n",
      "1     18891\n",
      "Name: FLAG_REDE_SOCIAL_2, dtype: int64\n",
      "2\n",
      "FLAG_REDE_SOCIAL_3\n",
      "0    176407\n",
      "1     18191\n",
      "Name: FLAG_REDE_SOCIAL_3, dtype: int64\n",
      "2\n",
      "FLAG_WEB_ARTES_1\n",
      "0    131238\n",
      "1     63360\n",
      "Name: FLAG_WEB_ARTES_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_MUSICA_1\n",
      "0    171529\n",
      "1     23069\n",
      "Name: FLAG_WEB_MUSICA_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_TV_1\n",
      "0    151012\n",
      "1     43586\n",
      "Name: FLAG_WEB_TV_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_LIVROS_1\n",
      "0    175801\n",
      "1     18797\n",
      "Name: FLAG_WEB_LIVROS_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_NEGOCIOS_1\n",
      "0    146467\n",
      "1     48131\n",
      "Name: FLAG_WEB_NEGOCIOS_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_NEGOCIOS_SERVICOS_1\n",
      "0    179735\n",
      "1     14863\n",
      "Name: FLAG_WEB_NEGOCIOS_SERVICOS_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_NEGOCIOS_MARKETING_1\n",
      "0    176163\n",
      "1     18435\n",
      "Name: FLAG_WEB_NEGOCIOS_MARKETING_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_NEGOCIOS_SERVICOS_UNIVERSIDADES_1\n",
      "0    169345\n",
      "1     25253\n",
      "Name: FLAG_WEB_NEGOCIOS_SERVICOS_UNIVERSIDADES_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_NEGOCIOS_SERVICOS_COMPUTACAO_1\n",
      "0    175048\n",
      "1     19550\n",
      "Name: FLAG_WEB_NEGOCIOS_SERVICOS_COMPUTACAO_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_SAUDE_1\n",
      "0    173322\n",
      "1     21276\n",
      "Name: FLAG_WEB_SAUDE_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_NOTICIAS_1\n",
      "0    153663\n",
      "1     40935\n",
      "Name: FLAG_WEB_NOTICIAS_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_SOCIEDADE_1\n",
      "0    164324\n",
      "1     30274\n",
      "Name: FLAG_WEB_SOCIEDADE_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_SOCIEDADE_GENEALOGIA_1\n",
      "0    172638\n",
      "1     21960\n",
      "Name: FLAG_WEB_SOCIEDADE_GENEALOGIA_1, dtype: int64\n",
      "2\n",
      "EXPOSICAO_WEB\n",
      "1.0000    38915\n",
      "0.0000    19105\n",
      "0.0003     6651\n",
      "0.0004     6563\n",
      "0.0001     6475\n",
      "0.0002     6383\n",
      "0.0005     6007\n",
      "0.0007     5830\n",
      "0.0006     5706\n",
      "0.0008     5462\n",
      "Name: EXPOSICAO_WEB, dtype: int64\n",
      "1900\n",
      "FLAG_WEB_CIENCIA_1\n",
      "0    175733\n",
      "1     18865\n",
      "Name: FLAG_WEB_CIENCIA_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_COMPRAS_1\n",
      "0    165865\n",
      "1     28733\n",
      "Name: FLAG_WEB_COMPRAS_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_ESPORTES_FUTEBOL_1\n",
      "0    177693\n",
      "1     16905\n",
      "Name: FLAG_WEB_ESPORTES_FUTEBOL_1, dtype: int64\n",
      "2\n",
      "FLAG_WEB_1\n",
      "0    181723\n",
      "1     12875\n",
      "Name: FLAG_WEB_1, dtype: int64\n",
      "2\n",
      "CEP1_1\n",
      "0    103873\n",
      "1     90725\n",
      "Name: CEP1_1, dtype: int64\n",
      "2\n",
      "CEP1_2\n",
      "0    112060\n",
      "1     82538\n",
      "Name: CEP1_2, dtype: int64\n",
      "2\n",
      "CEP1_3\n",
      "0    119021\n",
      "1     75577\n",
      "Name: CEP1_3, dtype: int64\n",
      "2\n",
      "CEP1_4\n",
      "0    122977\n",
      "1     71621\n",
      "Name: CEP1_4, dtype: int64\n",
      "2\n",
      "CEP1_5\n",
      "0    125863\n",
      "1     68735\n",
      "Name: CEP1_5, dtype: int64\n",
      "2\n",
      "CEP2_1\n",
      "1    154293\n",
      "0     40305\n",
      "Name: CEP2_1, dtype: int64\n",
      "2\n",
      "CEP2_2\n",
      "1    114336\n",
      "0     80262\n",
      "Name: CEP2_2, dtype: int64\n",
      "2\n",
      "CEP2_3\n",
      "0    103213\n",
      "1     91385\n",
      "Name: CEP2_3, dtype: int64\n",
      "2\n",
      "CEP2_4\n",
      "0    114038\n",
      "1     80560\n",
      "Name: CEP2_4, dtype: int64\n",
      "2\n",
      "CEP2_5\n",
      "0    122336\n",
      "1     72262\n",
      "Name: CEP2_5, dtype: int64\n",
      "2\n",
      "CEP2_6\n",
      "0    125407\n",
      "1     69191\n",
      "Name: CEP2_6, dtype: int64\n",
      "2\n",
      "CEP2_7\n",
      "0    128175\n",
      "1     66423\n",
      "Name: CEP2_7, dtype: int64\n",
      "2\n",
      "CEP2_8\n",
      "0    128894\n",
      "1     65704\n",
      "Name: CEP2_8, dtype: int64\n",
      "2\n",
      "CEP2_9\n",
      "0    130360\n",
      "1     64238\n",
      "Name: CEP2_9, dtype: int64\n",
      "2\n",
      "CEP3_1\n",
      "1    146448\n",
      "0     48150\n",
      "Name: CEP3_1, dtype: int64\n",
      "2\n",
      "CEP3_2\n",
      "1    118072\n",
      "0     76526\n",
      "Name: CEP3_2, dtype: int64\n",
      "2\n",
      "CEP3_3\n",
      "0    106953\n",
      "1     87645\n",
      "Name: CEP3_3, dtype: int64\n",
      "2\n",
      "CEP3_4\n",
      "0    117507\n",
      "1     77091\n",
      "Name: CEP3_4, dtype: int64\n",
      "2\n",
      "CEP3_5\n",
      "0    120861\n",
      "1     73737\n",
      "Name: CEP3_5, dtype: int64\n",
      "2\n",
      "CEP3_6\n",
      "0    129660\n",
      "1     64938\n",
      "Name: CEP3_6, dtype: int64\n",
      "2\n",
      "CEP3_7\n",
      "0    130609\n",
      "1     63989\n",
      "Name: CEP3_7, dtype: int64\n",
      "2\n",
      "CEP3_8\n",
      "0    132360\n",
      "1     62238\n",
      "Name: CEP3_8, dtype: int64\n",
      "2\n",
      "CEP3_9\n",
      "0    127163\n",
      "1     67435\n",
      "Name: CEP3_9, dtype: int64\n",
      "2\n",
      "CEP3_10\n",
      "0    130120\n",
      "1     64478\n",
      "Name: CEP3_10, dtype: int64\n",
      "2\n",
      "CEP3_11\n",
      "0    121487\n",
      "1     73111\n",
      "Name: CEP3_11, dtype: int64\n",
      "2\n",
      "CEP3_12\n",
      "0    120790\n",
      "1     73808\n",
      "Name: CEP3_12, dtype: int64\n",
      "2\n",
      "CEP4_1\n",
      "1    156872\n",
      "0     37726\n",
      "Name: CEP4_1, dtype: int64\n",
      "2\n",
      "CEP4_2\n",
      "1    134629\n",
      "0     59969\n",
      "Name: CEP4_2, dtype: int64\n",
      "2\n",
      "CEP4_3\n",
      "1    116577\n",
      "0     78021\n",
      "Name: CEP4_3, dtype: int64\n",
      "2\n",
      "CEP4_4\n",
      "1    99975\n",
      "0    94623\n",
      "Name: CEP4_4, dtype: int64\n",
      "2\n",
      "CEP4_5\n",
      "0    102015\n",
      "1     92583\n",
      "Name: CEP4_5, dtype: int64\n",
      "2\n",
      "CEP4_6\n",
      "0    109659\n",
      "1     84939\n",
      "Name: CEP4_6, dtype: int64\n",
      "2\n",
      "CEP4_7\n",
      "0    112266\n",
      "1     82332\n",
      "Name: CEP4_7, dtype: int64\n",
      "2\n",
      "CEP4_8\n",
      "0    113342\n",
      "1     81256\n",
      "Name: CEP4_8, dtype: int64\n",
      "2\n",
      "CEP4_9\n",
      "0    111784\n",
      "1     82814\n",
      "Name: CEP4_9, dtype: int64\n",
      "2\n",
      "CEP4_10\n",
      "0    104975\n",
      "1     89623\n",
      "Name: CEP4_10, dtype: int64\n",
      "2\n",
      "CEP4_11\n",
      "0    108809\n",
      "1     85789\n",
      "Name: CEP4_11, dtype: int64\n",
      "2\n",
      "CEP4_12\n",
      "0    109746\n",
      "1     84852\n",
      "Name: CEP4_12, dtype: int64\n",
      "2\n",
      "CEP4_13\n",
      "0    110289\n",
      "1     84309\n",
      "Name: CEP4_13, dtype: int64\n",
      "2\n",
      "CEP4_14\n",
      "0    108962\n",
      "1     85636\n",
      "Name: CEP4_14, dtype: int64\n",
      "2\n",
      "IND_BOM_1_1\n",
      "1    127647\n",
      "0     66951\n",
      "Name: IND_BOM_1_1, dtype: int64\n",
      "2\n",
      "IND_BOM_1_2\n",
      "0    127647\n",
      "1     66951\n",
      "Name: IND_BOM_1_2, dtype: int64\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for column in training_data.columns:\n",
    "    print(column)\n",
    "    values = training_data[column].value_counts()\n",
    "    if type(values) == list:\n",
    "        print(values[:10])\n",
    "    else:\n",
    "        print(values.head(10))\n",
    "    print(len(values))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "M1Eay13Kf7WN"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'category_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e0e0b166e4a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategory_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'category_columns' is not defined"
     ]
    }
   ],
   "source": [
    "for column in category_columns:\n",
    "    training_data[column] = training_data[column].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "o6KVdoYNf7WR",
    "outputId": "0e997d3b-17f3-498a-f057-32538b7434b4"
   },
   "outputs": [],
   "source": [
    "training_data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dPNgFMCRf7WU",
    "outputId": "80579775-f6b3-4a70-a140-25b6be1f267c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEXO_1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19330</td>\n",
       "      <td>36823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20837</td>\n",
       "      <td>39769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "IND_BOM_1_1      0      1\n",
       "SEXO_1                   \n",
       "0            19330  36823\n",
       "1            20837  39769"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confunsion_matrix = pandas.crosstab(training_data[\"SEXO_1\"], training_data[\"IND_BOM_1_1\"])\n",
    "confunsion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "F_wc44luf7WX",
    "outputId": "8f948f8f-ea80-42ea-923e-f5a79ea8e8c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=array([  56.54016979,  113.31360978]), pvalue=array([  5.50619646e-14,   1.84208521e-26]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "chisquare(confunsion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HE8lepFEf7Wa"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tvOkSKebf7Wb",
    "outputId": "c70f39c8-fe00-49f1-ef67-235eea0792e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_5</th>\n",
       "      <th>CEP4_6</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UF_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209093</td>\n",
       "      <td>0.048255</td>\n",
       "      <td>0.146628</td>\n",
       "      <td>0.118488</td>\n",
       "      <td>0.100570</td>\n",
       "      <td>0.087990</td>\n",
       "      <td>0.019386</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.017901</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.041249</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>0.022239</td>\n",
       "      <td>0.035315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UF_2</th>\n",
       "      <td>0.209093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>0.247423</td>\n",
       "      <td>0.187327</td>\n",
       "      <td>0.171868</td>\n",
       "      <td>0.180898</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>0.014506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040997</td>\n",
       "      <td>0.006801</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.035769</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0.021424</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>0.029016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UF_3</th>\n",
       "      <td>0.048255</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.275167</td>\n",
       "      <td>0.269899</td>\n",
       "      <td>0.246315</td>\n",
       "      <td>0.216494</td>\n",
       "      <td>0.031256</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011452</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>0.062716</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>0.038354</td>\n",
       "      <td>0.017366</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>0.011395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UF_4</th>\n",
       "      <td>0.146628</td>\n",
       "      <td>0.247423</td>\n",
       "      <td>0.275167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.126074</td>\n",
       "      <td>0.126333</td>\n",
       "      <td>0.135131</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.041647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.021085</td>\n",
       "      <td>0.012738</td>\n",
       "      <td>0.019959</td>\n",
       "      <td>0.028406</td>\n",
       "      <td>0.010240</td>\n",
       "      <td>0.023383</td>\n",
       "      <td>0.047764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UF_5</th>\n",
       "      <td>0.118488</td>\n",
       "      <td>0.187327</td>\n",
       "      <td>0.269899</td>\n",
       "      <td>0.126074</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.156790</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.018759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.060533</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.026264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UF_6</th>\n",
       "      <td>0.100570</td>\n",
       "      <td>0.171868</td>\n",
       "      <td>0.246315</td>\n",
       "      <td>0.126333</td>\n",
       "      <td>0.156790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.137971</td>\n",
       "      <td>0.026368</td>\n",
       "      <td>0.017433</td>\n",
       "      <td>0.028672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.023013</td>\n",
       "      <td>0.067999</td>\n",
       "      <td>0.022139</td>\n",
       "      <td>0.029033</td>\n",
       "      <td>0.065947</td>\n",
       "      <td>0.025372</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.015740</td>\n",
       "      <td>0.003706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UF_7</th>\n",
       "      <td>0.087990</td>\n",
       "      <td>0.180898</td>\n",
       "      <td>0.216494</td>\n",
       "      <td>0.135131</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.137971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.022839</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044504</td>\n",
       "      <td>0.024435</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.017101</td>\n",
       "      <td>0.034493</td>\n",
       "      <td>0.003431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDADE</th>\n",
       "      <td>0.019386</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.031256</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>0.026368</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>0.029988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.008037</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.006353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEXO_1</th>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.017433</td>\n",
       "      <td>0.022839</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.003675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.014506</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.041647</td>\n",
       "      <td>0.018759</td>\n",
       "      <td>0.028672</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.029988</td>\n",
       "      <td>0.020646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.005085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO02</th>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.239705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.001580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANCO_REST_IRPF_ULTIMA_1</th>\n",
       "      <td>0.007550</td>\n",
       "      <td>0.048365</td>\n",
       "      <td>0.042261</td>\n",
       "      <td>0.036186</td>\n",
       "      <td>0.006520</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.028865</td>\n",
       "      <td>0.011831</td>\n",
       "      <td>0.041594</td>\n",
       "      <td>0.014328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012245</td>\n",
       "      <td>0.016455</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.011306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANCO_REST_IRPF_ULTIMA_2</th>\n",
       "      <td>0.027318</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.015587</td>\n",
       "      <td>0.012387</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.035525</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.012884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.009435</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.007759</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.012610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANCO_REST_IRPF_ULTIMA_3</th>\n",
       "      <td>0.031309</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.035204</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.009251</td>\n",
       "      <td>0.039252</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.022476</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011136</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.004504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANCO_REST_IRPF_ULTIMA_4</th>\n",
       "      <td>0.009614</td>\n",
       "      <td>0.011060</td>\n",
       "      <td>0.029721</td>\n",
       "      <td>0.024070</td>\n",
       "      <td>0.004330</td>\n",
       "      <td>0.012961</td>\n",
       "      <td>0.021763</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>0.031053</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.008856</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANCO_REST_IRPF_ULTIMA_5</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.009894</td>\n",
       "      <td>0.020938</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.013540</td>\n",
       "      <td>0.019192</td>\n",
       "      <td>0.009553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.004460</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.006276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANCO_REST_IRPF_ULTIMA_6</th>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.024210</td>\n",
       "      <td>0.031489</td>\n",
       "      <td>0.008058</td>\n",
       "      <td>0.008847</td>\n",
       "      <td>0.023075</td>\n",
       "      <td>0.017595</td>\n",
       "      <td>0.041111</td>\n",
       "      <td>0.015834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012357</td>\n",
       "      <td>0.015106</td>\n",
       "      <td>0.006938</td>\n",
       "      <td>0.006781</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.004426</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.012221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANCO_REST_IRPF_ULTIMA_7</th>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.048489</td>\n",
       "      <td>0.038199</td>\n",
       "      <td>0.031314</td>\n",
       "      <td>0.012052</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.017687</td>\n",
       "      <td>0.040374</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.014959</td>\n",
       "      <td>0.007677</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.011833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATIVIDADE_EMAIL</th>\n",
       "      <td>0.029827</td>\n",
       "      <td>0.102135</td>\n",
       "      <td>0.053917</td>\n",
       "      <td>0.079640</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.067921</td>\n",
       "      <td>0.058710</td>\n",
       "      <td>0.022313</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.015398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>0.017565</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXPOSICAO_ENDERECO</th>\n",
       "      <td>0.050144</td>\n",
       "      <td>0.068285</td>\n",
       "      <td>0.010087</td>\n",
       "      <td>0.071787</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.025830</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>0.037784</td>\n",
       "      <td>0.029683</td>\n",
       "      <td>0.043574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.019879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXPOSICAO_EMAIL</th>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.076136</td>\n",
       "      <td>0.038393</td>\n",
       "      <td>0.065260</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.041351</td>\n",
       "      <td>0.038661</td>\n",
       "      <td>0.036607</td>\n",
       "      <td>0.010047</td>\n",
       "      <td>0.013042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.016051</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.006326</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.007416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXPOSICAO_TELEFONE</th>\n",
       "      <td>0.036865</td>\n",
       "      <td>0.089696</td>\n",
       "      <td>0.040969</td>\n",
       "      <td>0.067006</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.053896</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>0.008596</td>\n",
       "      <td>0.029972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008441</td>\n",
       "      <td>0.012044</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.008774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATIVIDADE_ENDERECO</th>\n",
       "      <td>0.022894</td>\n",
       "      <td>0.053707</td>\n",
       "      <td>0.036434</td>\n",
       "      <td>0.033969</td>\n",
       "      <td>0.043457</td>\n",
       "      <td>0.020355</td>\n",
       "      <td>0.021810</td>\n",
       "      <td>0.053765</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.010995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.017025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATUALIZACAO_ENDERECO</th>\n",
       "      <td>0.079764</td>\n",
       "      <td>0.133604</td>\n",
       "      <td>0.085711</td>\n",
       "      <td>0.128637</td>\n",
       "      <td>0.028621</td>\n",
       "      <td>0.081709</td>\n",
       "      <td>0.063768</td>\n",
       "      <td>0.028367</td>\n",
       "      <td>0.009754</td>\n",
       "      <td>0.055744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.004754</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.011011</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>0.021115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATUALIZACAO_EMAIL</th>\n",
       "      <td>0.022480</td>\n",
       "      <td>0.064821</td>\n",
       "      <td>0.029610</td>\n",
       "      <td>0.043340</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.048778</td>\n",
       "      <td>0.039065</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.026544</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.009938</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.011939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXPOSICAO_CONSUMIDOR_EMAILS</th>\n",
       "      <td>0.028191</td>\n",
       "      <td>0.100637</td>\n",
       "      <td>0.066333</td>\n",
       "      <td>0.092479</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.056396</td>\n",
       "      <td>0.055250</td>\n",
       "      <td>0.029127</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.026866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011044</td>\n",
       "      <td>0.017121</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.007219</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.014085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXPOSICAO_CONSUMIDOR_TELEFONES</th>\n",
       "      <td>0.043818</td>\n",
       "      <td>0.123445</td>\n",
       "      <td>0.046967</td>\n",
       "      <td>0.100710</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.038440</td>\n",
       "      <td>0.076835</td>\n",
       "      <td>0.015251</td>\n",
       "      <td>0.009026</td>\n",
       "      <td>0.042013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016380</td>\n",
       "      <td>0.012466</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.007509</td>\n",
       "      <td>0.007721</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.015405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATIVIDADE_TELEFONE</th>\n",
       "      <td>0.048842</td>\n",
       "      <td>0.123535</td>\n",
       "      <td>0.054476</td>\n",
       "      <td>0.097383</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.060096</td>\n",
       "      <td>0.082791</td>\n",
       "      <td>0.013744</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.029384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.015946</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.004522</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.018880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VALOR_PARCELA_BOLSA_FAMILIA</th>\n",
       "      <td>0.029549</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>0.030546</td>\n",
       "      <td>0.075914</td>\n",
       "      <td>0.007226</td>\n",
       "      <td>0.034562</td>\n",
       "      <td>0.033717</td>\n",
       "      <td>0.019411</td>\n",
       "      <td>0.224650</td>\n",
       "      <td>0.015068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.014631</td>\n",
       "      <td>0.009022</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.016280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_BOLSA_FAMILIA_1</th>\n",
       "      <td>0.017125</td>\n",
       "      <td>0.076686</td>\n",
       "      <td>0.048595</td>\n",
       "      <td>0.073702</td>\n",
       "      <td>0.011201</td>\n",
       "      <td>0.057516</td>\n",
       "      <td>0.029261</td>\n",
       "      <td>0.056231</td>\n",
       "      <td>0.246700</td>\n",
       "      <td>0.018757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.018833</td>\n",
       "      <td>0.008540</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.007389</td>\n",
       "      <td>0.018539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP2_6</th>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.049254</td>\n",
       "      <td>0.227824</td>\n",
       "      <td>0.151508</td>\n",
       "      <td>0.067630</td>\n",
       "      <td>0.118541</td>\n",
       "      <td>0.018354</td>\n",
       "      <td>0.017671</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028036</td>\n",
       "      <td>0.012740</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.033257</td>\n",
       "      <td>0.041206</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.022095</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.033753</td>\n",
       "      <td>0.008207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP2_7</th>\n",
       "      <td>0.035253</td>\n",
       "      <td>0.036345</td>\n",
       "      <td>0.092329</td>\n",
       "      <td>0.042431</td>\n",
       "      <td>0.019542</td>\n",
       "      <td>0.107576</td>\n",
       "      <td>0.132370</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.015988</td>\n",
       "      <td>0.013299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.021336</td>\n",
       "      <td>0.014143</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.003459</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>0.025808</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.016561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP2_8</th>\n",
       "      <td>0.127231</td>\n",
       "      <td>0.064413</td>\n",
       "      <td>0.153344</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.231533</td>\n",
       "      <td>0.110188</td>\n",
       "      <td>0.080085</td>\n",
       "      <td>0.011028</td>\n",
       "      <td>0.013940</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026070</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.023503</td>\n",
       "      <td>0.024130</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.015350</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.018287</td>\n",
       "      <td>0.027417</td>\n",
       "      <td>0.024925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP2_9</th>\n",
       "      <td>0.035706</td>\n",
       "      <td>0.160233</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.157641</td>\n",
       "      <td>0.044606</td>\n",
       "      <td>0.021549</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049948</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.013246</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.026293</td>\n",
       "      <td>0.039538</td>\n",
       "      <td>0.031095</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>0.058079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_1</th>\n",
       "      <td>0.079478</td>\n",
       "      <td>0.013082</td>\n",
       "      <td>0.024672</td>\n",
       "      <td>0.115169</td>\n",
       "      <td>0.019630</td>\n",
       "      <td>0.076478</td>\n",
       "      <td>0.047759</td>\n",
       "      <td>0.030490</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011758</td>\n",
       "      <td>0.026038</td>\n",
       "      <td>0.048094</td>\n",
       "      <td>0.033452</td>\n",
       "      <td>0.058999</td>\n",
       "      <td>0.035789</td>\n",
       "      <td>0.047201</td>\n",
       "      <td>0.033384</td>\n",
       "      <td>0.017597</td>\n",
       "      <td>0.019042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_2</th>\n",
       "      <td>0.095808</td>\n",
       "      <td>0.012289</td>\n",
       "      <td>0.032843</td>\n",
       "      <td>0.019285</td>\n",
       "      <td>0.013063</td>\n",
       "      <td>0.086146</td>\n",
       "      <td>0.050879</td>\n",
       "      <td>0.022153</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.010664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027264</td>\n",
       "      <td>0.054886</td>\n",
       "      <td>0.053113</td>\n",
       "      <td>0.054921</td>\n",
       "      <td>0.079345</td>\n",
       "      <td>0.059479</td>\n",
       "      <td>0.034065</td>\n",
       "      <td>0.006475</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.059274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_3</th>\n",
       "      <td>0.005244</td>\n",
       "      <td>0.044583</td>\n",
       "      <td>0.021466</td>\n",
       "      <td>0.047603</td>\n",
       "      <td>0.044638</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.033995</td>\n",
       "      <td>0.009803</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011289</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>0.021250</td>\n",
       "      <td>0.004511</td>\n",
       "      <td>0.018212</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>0.061374</td>\n",
       "      <td>0.019429</td>\n",
       "      <td>0.040716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_4</th>\n",
       "      <td>0.036935</td>\n",
       "      <td>0.068332</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.006970</td>\n",
       "      <td>0.018711</td>\n",
       "      <td>0.067506</td>\n",
       "      <td>0.046090</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015391</td>\n",
       "      <td>0.025864</td>\n",
       "      <td>0.056434</td>\n",
       "      <td>0.021252</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>0.034971</td>\n",
       "      <td>0.021035</td>\n",
       "      <td>0.015093</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.003043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_5</th>\n",
       "      <td>0.018686</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.044004</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>0.035649</td>\n",
       "      <td>0.034387</td>\n",
       "      <td>0.055902</td>\n",
       "      <td>0.020135</td>\n",
       "      <td>0.005227</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026954</td>\n",
       "      <td>0.014938</td>\n",
       "      <td>0.021426</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.051028</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.011449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_6</th>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.033136</td>\n",
       "      <td>0.100501</td>\n",
       "      <td>0.026748</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>0.010951</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>0.008376</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013941</td>\n",
       "      <td>0.033553</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.013424</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.068129</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.058430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_7</th>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.070140</td>\n",
       "      <td>0.066772</td>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.111133</td>\n",
       "      <td>0.078501</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.006493</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037716</td>\n",
       "      <td>0.032734</td>\n",
       "      <td>0.042090</td>\n",
       "      <td>0.028335</td>\n",
       "      <td>0.022631</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>0.043659</td>\n",
       "      <td>0.022275</td>\n",
       "      <td>0.006181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_8</th>\n",
       "      <td>0.007747</td>\n",
       "      <td>0.038914</td>\n",
       "      <td>0.014766</td>\n",
       "      <td>0.155868</td>\n",
       "      <td>0.078621</td>\n",
       "      <td>0.040540</td>\n",
       "      <td>0.019838</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>0.009370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013239</td>\n",
       "      <td>0.020391</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.021430</td>\n",
       "      <td>0.030134</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>0.036293</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_9</th>\n",
       "      <td>0.007316</td>\n",
       "      <td>0.051206</td>\n",
       "      <td>0.018560</td>\n",
       "      <td>0.050332</td>\n",
       "      <td>0.065487</td>\n",
       "      <td>0.088553</td>\n",
       "      <td>0.028149</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.058565</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.048102</td>\n",
       "      <td>0.039036</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.009801</td>\n",
       "      <td>0.007158</td>\n",
       "      <td>0.023076</td>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_10</th>\n",
       "      <td>0.037401</td>\n",
       "      <td>0.122573</td>\n",
       "      <td>0.032248</td>\n",
       "      <td>0.009712</td>\n",
       "      <td>0.040417</td>\n",
       "      <td>0.054517</td>\n",
       "      <td>0.020581</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.021077</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.038610</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>0.034739</td>\n",
       "      <td>0.034160</td>\n",
       "      <td>0.015346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_11</th>\n",
       "      <td>0.038761</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.032516</td>\n",
       "      <td>0.032584</td>\n",
       "      <td>0.059035</td>\n",
       "      <td>0.029763</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.019295</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.016885</td>\n",
       "      <td>0.016830</td>\n",
       "      <td>0.016259</td>\n",
       "      <td>0.008468</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.007912</td>\n",
       "      <td>0.012464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_12</th>\n",
       "      <td>0.009115</td>\n",
       "      <td>0.089565</td>\n",
       "      <td>0.044717</td>\n",
       "      <td>0.027196</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.009442</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>0.038325</td>\n",
       "      <td>0.030986</td>\n",
       "      <td>0.021511</td>\n",
       "      <td>0.011453</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>0.014722</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>0.009819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_1</th>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.023137</td>\n",
       "      <td>0.010847</td>\n",
       "      <td>0.042641</td>\n",
       "      <td>0.007986</td>\n",
       "      <td>0.053411</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.026147</td>\n",
       "      <td>0.002971</td>\n",
       "      <td>0.012223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050156</td>\n",
       "      <td>0.066598</td>\n",
       "      <td>0.062154</td>\n",
       "      <td>0.069148</td>\n",
       "      <td>0.057546</td>\n",
       "      <td>0.034671</td>\n",
       "      <td>0.079745</td>\n",
       "      <td>0.080468</td>\n",
       "      <td>0.042412</td>\n",
       "      <td>0.056045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_2</th>\n",
       "      <td>0.041778</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>0.045959</td>\n",
       "      <td>0.016462</td>\n",
       "      <td>0.072975</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>0.014857</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077276</td>\n",
       "      <td>0.079951</td>\n",
       "      <td>0.108763</td>\n",
       "      <td>0.099927</td>\n",
       "      <td>0.064027</td>\n",
       "      <td>0.066742</td>\n",
       "      <td>0.060307</td>\n",
       "      <td>0.064826</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.079220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_3</th>\n",
       "      <td>0.023338</td>\n",
       "      <td>0.015772</td>\n",
       "      <td>0.025754</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.050612</td>\n",
       "      <td>0.092219</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>0.009344</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055127</td>\n",
       "      <td>0.100593</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>0.068514</td>\n",
       "      <td>0.091356</td>\n",
       "      <td>0.126188</td>\n",
       "      <td>0.057642</td>\n",
       "      <td>0.055201</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.092043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_4</th>\n",
       "      <td>0.012945</td>\n",
       "      <td>0.051797</td>\n",
       "      <td>0.016761</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.018837</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>0.018447</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110578</td>\n",
       "      <td>0.082239</td>\n",
       "      <td>0.059399</td>\n",
       "      <td>0.102702</td>\n",
       "      <td>0.086201</td>\n",
       "      <td>0.092063</td>\n",
       "      <td>0.089606</td>\n",
       "      <td>0.091386</td>\n",
       "      <td>0.093666</td>\n",
       "      <td>0.076223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_5</th>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.040997</td>\n",
       "      <td>0.011452</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.044504</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.081452</td>\n",
       "      <td>0.084146</td>\n",
       "      <td>0.068273</td>\n",
       "      <td>0.074884</td>\n",
       "      <td>0.114886</td>\n",
       "      <td>0.076358</td>\n",
       "      <td>0.081288</td>\n",
       "      <td>0.077429</td>\n",
       "      <td>0.070549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_6</th>\n",
       "      <td>0.017901</td>\n",
       "      <td>0.006801</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.023013</td>\n",
       "      <td>0.024435</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061243</td>\n",
       "      <td>0.055286</td>\n",
       "      <td>0.057445</td>\n",
       "      <td>0.067454</td>\n",
       "      <td>0.093325</td>\n",
       "      <td>0.109380</td>\n",
       "      <td>0.059392</td>\n",
       "      <td>0.105031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_7</th>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.060533</td>\n",
       "      <td>0.067999</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084146</td>\n",
       "      <td>0.061243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076438</td>\n",
       "      <td>0.065009</td>\n",
       "      <td>0.079427</td>\n",
       "      <td>0.053802</td>\n",
       "      <td>0.095205</td>\n",
       "      <td>0.093120</td>\n",
       "      <td>0.079717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_8</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.035769</td>\n",
       "      <td>0.062716</td>\n",
       "      <td>0.021085</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>0.022139</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068273</td>\n",
       "      <td>0.055286</td>\n",
       "      <td>0.076438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070476</td>\n",
       "      <td>0.081482</td>\n",
       "      <td>0.094420</td>\n",
       "      <td>0.037541</td>\n",
       "      <td>0.100988</td>\n",
       "      <td>0.089647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_9</th>\n",
       "      <td>0.041249</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>0.012738</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.029033</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.008037</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074884</td>\n",
       "      <td>0.057445</td>\n",
       "      <td>0.065009</td>\n",
       "      <td>0.070476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.056205</td>\n",
       "      <td>0.107209</td>\n",
       "      <td>0.104018</td>\n",
       "      <td>0.096174</td>\n",
       "      <td>0.081960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_10</th>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.038354</td>\n",
       "      <td>0.019959</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.065947</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114886</td>\n",
       "      <td>0.067454</td>\n",
       "      <td>0.079427</td>\n",
       "      <td>0.081482</td>\n",
       "      <td>0.056205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077964</td>\n",
       "      <td>0.093005</td>\n",
       "      <td>0.059894</td>\n",
       "      <td>0.067307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_11</th>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0.017366</td>\n",
       "      <td>0.028406</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.025372</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076358</td>\n",
       "      <td>0.093325</td>\n",
       "      <td>0.053802</td>\n",
       "      <td>0.094420</td>\n",
       "      <td>0.107209</td>\n",
       "      <td>0.077964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065892</td>\n",
       "      <td>0.077590</td>\n",
       "      <td>0.087774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_12</th>\n",
       "      <td>0.009868</td>\n",
       "      <td>0.021424</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.010240</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.017101</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081288</td>\n",
       "      <td>0.109380</td>\n",
       "      <td>0.095205</td>\n",
       "      <td>0.037541</td>\n",
       "      <td>0.104018</td>\n",
       "      <td>0.093005</td>\n",
       "      <td>0.065892</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078021</td>\n",
       "      <td>0.064582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_13</th>\n",
       "      <td>0.022239</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>0.023383</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.015740</td>\n",
       "      <td>0.034493</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077429</td>\n",
       "      <td>0.059392</td>\n",
       "      <td>0.093120</td>\n",
       "      <td>0.100988</td>\n",
       "      <td>0.096174</td>\n",
       "      <td>0.059894</td>\n",
       "      <td>0.077590</td>\n",
       "      <td>0.078021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_14</th>\n",
       "      <td>0.035315</td>\n",
       "      <td>0.029016</td>\n",
       "      <td>0.011395</td>\n",
       "      <td>0.047764</td>\n",
       "      <td>0.026264</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070549</td>\n",
       "      <td>0.105031</td>\n",
       "      <td>0.079717</td>\n",
       "      <td>0.089647</td>\n",
       "      <td>0.081960</td>\n",
       "      <td>0.067307</td>\n",
       "      <td>0.087774</td>\n",
       "      <td>0.064582</td>\n",
       "      <td>0.068267</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    UF_1      UF_2      UF_3      UF_4  \\\n",
       "UF_1                            1.000000  0.209093  0.048255  0.146628   \n",
       "UF_2                            0.209093  1.000000  0.123264  0.247423   \n",
       "UF_3                            0.048255  0.123264  1.000000  0.275167   \n",
       "UF_4                            0.146628  0.247423  0.275167  1.000000   \n",
       "UF_5                            0.118488  0.187327  0.269899  0.126074   \n",
       "UF_6                            0.100570  0.171868  0.246315  0.126333   \n",
       "UF_7                            0.087990  0.180898  0.216494  0.135131   \n",
       "IDADE                           0.019386  0.012217  0.031256  0.020921   \n",
       "SEXO_1                          0.007811  0.013103  0.003892  0.004924   \n",
       "NIVEL_RELACIONAMENTO_CREDITO01  0.006435  0.014506  0.013546  0.041647   \n",
       "NIVEL_RELACIONAMENTO_CREDITO02  0.001615  0.000890  0.010338  0.009182   \n",
       "BANCO_REST_IRPF_ULTIMA_1        0.007550  0.048365  0.042261  0.036186   \n",
       "BANCO_REST_IRPF_ULTIMA_2        0.027318  0.013636  0.009286  0.000790   \n",
       "BANCO_REST_IRPF_ULTIMA_3        0.031309  0.049316  0.007395  0.035204   \n",
       "BANCO_REST_IRPF_ULTIMA_4        0.009614  0.011060  0.029721  0.024070   \n",
       "BANCO_REST_IRPF_ULTIMA_5        0.000016  0.003451  0.007674  0.002916   \n",
       "BANCO_REST_IRPF_ULTIMA_6        0.004719  0.036600  0.024210  0.031489   \n",
       "BANCO_REST_IRPF_ULTIMA_7        0.004345  0.048489  0.038199  0.031314   \n",
       "ATIVIDADE_EMAIL                 0.029827  0.102135  0.053917  0.079640   \n",
       "EXPOSICAO_ENDERECO              0.050144  0.068285  0.010087  0.071787   \n",
       "EXPOSICAO_EMAIL                 0.023400  0.076136  0.038393  0.065260   \n",
       "EXPOSICAO_TELEFONE              0.036865  0.089696  0.040969  0.067006   \n",
       "ATIVIDADE_ENDERECO              0.022894  0.053707  0.036434  0.033969   \n",
       "ATUALIZACAO_ENDERECO            0.079764  0.133604  0.085711  0.128637   \n",
       "ATUALIZACAO_EMAIL               0.022480  0.064821  0.029610  0.043340   \n",
       "EXPOSICAO_CONSUMIDOR_EMAILS     0.028191  0.100637  0.066333  0.092479   \n",
       "EXPOSICAO_CONSUMIDOR_TELEFONES  0.043818  0.123445  0.046967  0.100710   \n",
       "ATIVIDADE_TELEFONE              0.048842  0.123535  0.054476  0.097383   \n",
       "VALOR_PARCELA_BOLSA_FAMILIA     0.029549  0.078861  0.030546  0.075914   \n",
       "FLAG_BOLSA_FAMILIA_1            0.017125  0.076686  0.048595  0.073702   \n",
       "...                                  ...       ...       ...       ...   \n",
       "CEP2_6                          0.010724  0.049254  0.227824  0.151508   \n",
       "CEP2_7                          0.035253  0.036345  0.092329  0.042431   \n",
       "CEP2_8                          0.127231  0.064413  0.153344  0.004123   \n",
       "CEP2_9                          0.035706  0.160233  0.040816  0.157641   \n",
       "CEP3_1                          0.079478  0.013082  0.024672  0.115169   \n",
       "CEP3_2                          0.095808  0.012289  0.032843  0.019285   \n",
       "CEP3_3                          0.005244  0.044583  0.021466  0.047603   \n",
       "CEP3_4                          0.036935  0.068332  0.002233  0.006970   \n",
       "CEP3_5                          0.018686  0.007016  0.044004  0.021937   \n",
       "CEP3_6                          0.030020  0.033136  0.100501  0.026748   \n",
       "CEP3_7                          0.005571  0.070140  0.066772  0.044413   \n",
       "CEP3_8                          0.007747  0.038914  0.014766  0.155868   \n",
       "CEP3_9                          0.007316  0.051206  0.018560  0.050332   \n",
       "CEP3_10                         0.037401  0.122573  0.032248  0.009712   \n",
       "CEP3_11                         0.038761  0.003692  0.032516  0.032584   \n",
       "CEP3_12                         0.009115  0.089565  0.044717  0.027196   \n",
       "CEP4_1                          0.003057  0.023137  0.010847  0.042641   \n",
       "CEP4_2                          0.041778  0.003489  0.045959  0.016462   \n",
       "CEP4_3                          0.023338  0.015772  0.025754  0.002694   \n",
       "CEP4_4                          0.012945  0.051797  0.016761  0.004748   \n",
       "CEP4_5                          0.025403  0.040997  0.011452  0.001024   \n",
       "CEP4_6                          0.017901  0.006801  0.008139  0.005757   \n",
       "CEP4_7                          0.002279  0.002159  0.009605  0.009747   \n",
       "CEP4_8                          0.000400  0.035769  0.062716  0.021085   \n",
       "CEP4_9                          0.041249  0.002821  0.011476  0.012738   \n",
       "CEP4_10                         0.004074  0.023900  0.038354  0.019959   \n",
       "CEP4_11                         0.004246  0.012583  0.017366  0.028406   \n",
       "CEP4_12                         0.009868  0.021424  0.002350  0.010240   \n",
       "CEP4_13                         0.022239  0.007369  0.018033  0.023383   \n",
       "CEP4_14                         0.035315  0.029016  0.011395  0.047764   \n",
       "\n",
       "                                    UF_5      UF_6      UF_7     IDADE  \\\n",
       "UF_1                            0.118488  0.100570  0.087990  0.019386   \n",
       "UF_2                            0.187327  0.171868  0.180898  0.012217   \n",
       "UF_3                            0.269899  0.246315  0.216494  0.031256   \n",
       "UF_4                            0.126074  0.126333  0.135131  0.020921   \n",
       "UF_5                            1.000000  0.156790  0.121600  0.003239   \n",
       "UF_6                            0.156790  1.000000  0.137971  0.026368   \n",
       "UF_7                            0.121600  0.137971  1.000000  0.002974   \n",
       "IDADE                           0.003239  0.026368  0.002974  1.000000   \n",
       "SEXO_1                          0.006073  0.017433  0.022839  0.017405   \n",
       "NIVEL_RELACIONAMENTO_CREDITO01  0.018759  0.028672  0.000691  0.029988   \n",
       "NIVEL_RELACIONAMENTO_CREDITO02  0.007102  0.002931  0.000145  0.009357   \n",
       "BANCO_REST_IRPF_ULTIMA_1        0.006520  0.036946  0.028865  0.011831   \n",
       "BANCO_REST_IRPF_ULTIMA_2        0.015587  0.012387  0.002948  0.035525   \n",
       "BANCO_REST_IRPF_ULTIMA_3        0.002591  0.009251  0.039252  0.002203   \n",
       "BANCO_REST_IRPF_ULTIMA_4        0.004330  0.012961  0.021763  0.010099   \n",
       "BANCO_REST_IRPF_ULTIMA_5        0.009894  0.020938  0.000802  0.013540   \n",
       "BANCO_REST_IRPF_ULTIMA_6        0.008058  0.008847  0.023075  0.017595   \n",
       "BANCO_REST_IRPF_ULTIMA_7        0.012052  0.021653  0.037037  0.017687   \n",
       "ATIVIDADE_EMAIL                 0.008905  0.067921  0.058710  0.022313   \n",
       "EXPOSICAO_ENDERECO              0.007488  0.025830  0.014593  0.037784   \n",
       "EXPOSICAO_EMAIL                 0.000574  0.041351  0.038661  0.036607   \n",
       "EXPOSICAO_TELEFONE              0.002890  0.053896  0.049747  0.012228   \n",
       "ATIVIDADE_ENDERECO              0.043457  0.020355  0.021810  0.053765   \n",
       "ATUALIZACAO_ENDERECO            0.028621  0.081709  0.063768  0.028367   \n",
       "ATUALIZACAO_EMAIL               0.007848  0.048778  0.039065  0.007181   \n",
       "EXPOSICAO_CONSUMIDOR_EMAILS     0.003326  0.056396  0.055250  0.029127   \n",
       "EXPOSICAO_CONSUMIDOR_TELEFONES  0.005675  0.038440  0.076835  0.015251   \n",
       "ATIVIDADE_TELEFONE              0.004529  0.060096  0.082791  0.013744   \n",
       "VALOR_PARCELA_BOLSA_FAMILIA     0.007226  0.034562  0.033717  0.019411   \n",
       "FLAG_BOLSA_FAMILIA_1            0.011201  0.057516  0.029261  0.056231   \n",
       "...                                  ...       ...       ...       ...   \n",
       "CEP2_6                          0.067630  0.118541  0.018354  0.017671   \n",
       "CEP2_7                          0.019542  0.107576  0.132370  0.002385   \n",
       "CEP2_8                          0.231533  0.110188  0.080085  0.011028   \n",
       "CEP2_9                          0.044606  0.021549  0.002541  0.006815   \n",
       "CEP3_1                          0.019630  0.076478  0.047759  0.030490   \n",
       "CEP3_2                          0.013063  0.086146  0.050879  0.022153   \n",
       "CEP3_3                          0.044638  0.005848  0.033995  0.009803   \n",
       "CEP3_4                          0.018711  0.067506  0.046090  0.000177   \n",
       "CEP3_5                          0.035649  0.034387  0.055902  0.020135   \n",
       "CEP3_6                          0.014460  0.010951  0.084968  0.008376   \n",
       "CEP3_7                          0.111133  0.078501  0.082090  0.006493   \n",
       "CEP3_8                          0.078621  0.040540  0.019838  0.002797   \n",
       "CEP3_9                          0.065487  0.088553  0.028149  0.007804   \n",
       "CEP3_10                         0.040417  0.054517  0.020581  0.007211   \n",
       "CEP3_11                         0.059035  0.029763  0.002990  0.019295   \n",
       "CEP3_12                         0.014113  0.003386  0.009442  0.001182   \n",
       "CEP4_1                          0.007986  0.053411  0.013797  0.026147   \n",
       "CEP4_2                          0.072975  0.115646  0.026872  0.014857   \n",
       "CEP4_3                          0.050612  0.092219  0.005744  0.009344   \n",
       "CEP4_4                          0.018837  0.014398  0.018447  0.003289   \n",
       "CEP4_5                          0.000297  0.002480  0.044504  0.001120   \n",
       "CEP4_6                          0.002524  0.023013  0.024435  0.004402   \n",
       "CEP4_7                          0.060533  0.067999  0.005311  0.013037   \n",
       "CEP4_8                          0.009569  0.022139  0.000662  0.001559   \n",
       "CEP4_9                          0.000885  0.029033  0.006608  0.008037   \n",
       "CEP4_10                         0.000713  0.065947  0.035075  0.004025   \n",
       "CEP4_11                         0.001331  0.025372  0.001038  0.000544   \n",
       "CEP4_12                         0.023599  0.000670  0.017101  0.002066   \n",
       "CEP4_13                         0.026219  0.015740  0.034493  0.000616   \n",
       "CEP4_14                         0.026264  0.003706  0.003431  0.006353   \n",
       "\n",
       "                                  SEXO_1  NIVEL_RELACIONAMENTO_CREDITO01  \\\n",
       "UF_1                            0.007811                        0.006435   \n",
       "UF_2                            0.013103                        0.014506   \n",
       "UF_3                            0.003892                        0.013546   \n",
       "UF_4                            0.004924                        0.041647   \n",
       "UF_5                            0.006073                        0.018759   \n",
       "UF_6                            0.017433                        0.028672   \n",
       "UF_7                            0.022839                        0.000691   \n",
       "IDADE                           0.017405                        0.029988   \n",
       "SEXO_1                          1.000000                        0.020646   \n",
       "NIVEL_RELACIONAMENTO_CREDITO01  0.020646                        1.000000   \n",
       "NIVEL_RELACIONAMENTO_CREDITO02  0.004807                        0.239705   \n",
       "BANCO_REST_IRPF_ULTIMA_1        0.041594                        0.014328   \n",
       "BANCO_REST_IRPF_ULTIMA_2        0.010267                        0.012884   \n",
       "BANCO_REST_IRPF_ULTIMA_3        0.022476                        0.003451   \n",
       "BANCO_REST_IRPF_ULTIMA_4        0.031053                        0.008848   \n",
       "BANCO_REST_IRPF_ULTIMA_5        0.019192                        0.009553   \n",
       "BANCO_REST_IRPF_ULTIMA_6        0.041111                        0.015834   \n",
       "BANCO_REST_IRPF_ULTIMA_7        0.040374                        0.016688   \n",
       "ATIVIDADE_EMAIL                 0.010091                        0.015398   \n",
       "EXPOSICAO_ENDERECO              0.029683                        0.043574   \n",
       "EXPOSICAO_EMAIL                 0.010047                        0.013042   \n",
       "EXPOSICAO_TELEFONE              0.008596                        0.029972   \n",
       "ATIVIDADE_ENDERECO              0.004899                        0.010995   \n",
       "ATUALIZACAO_ENDERECO            0.009754                        0.055744   \n",
       "ATUALIZACAO_EMAIL               0.026544                        0.007267   \n",
       "EXPOSICAO_CONSUMIDOR_EMAILS     0.002422                        0.026866   \n",
       "EXPOSICAO_CONSUMIDOR_TELEFONES  0.009026                        0.042013   \n",
       "ATIVIDADE_TELEFONE              0.000816                        0.029384   \n",
       "VALOR_PARCELA_BOLSA_FAMILIA     0.224650                        0.015068   \n",
       "FLAG_BOLSA_FAMILIA_1            0.246700                        0.018757   \n",
       "...                                  ...                             ...   \n",
       "CEP2_6                          0.002026                        0.009349   \n",
       "CEP2_7                          0.015988                        0.013299   \n",
       "CEP2_8                          0.013940                        0.000648   \n",
       "CEP2_9                          0.002322                        0.007211   \n",
       "CEP3_1                          0.003950                        0.005457   \n",
       "CEP3_2                          0.006760                        0.010664   \n",
       "CEP3_3                          0.009796                        0.004269   \n",
       "CEP3_4                          0.004429                        0.005953   \n",
       "CEP3_5                          0.005227                        0.000593   \n",
       "CEP3_6                          0.004291                        0.000195   \n",
       "CEP3_7                          0.004277                        0.004795   \n",
       "CEP3_8                          0.009405                        0.009370   \n",
       "CEP3_9                          0.002677                        0.000952   \n",
       "CEP3_10                         0.003127                        0.003563   \n",
       "CEP3_11                         0.004793                        0.004151   \n",
       "CEP3_12                         0.005584                        0.000917   \n",
       "CEP4_1                          0.002971                        0.012223   \n",
       "CEP4_2                          0.000759                        0.009663   \n",
       "CEP4_3                          0.008977                        0.000904   \n",
       "CEP4_4                          0.005784                        0.001465   \n",
       "CEP4_5                          0.000789                        0.002201   \n",
       "CEP4_6                          0.008388                        0.004603   \n",
       "CEP4_7                          0.000917                        0.001246   \n",
       "CEP4_8                          0.002623                        0.002234   \n",
       "CEP4_9                          0.002129                        0.003535   \n",
       "CEP4_10                         0.002683                        0.001846   \n",
       "CEP4_11                         0.001580                        0.000003   \n",
       "CEP4_12                         0.004715                        0.000372   \n",
       "CEP4_13                         0.002303                        0.004002   \n",
       "CEP4_14                         0.003675                        0.005085   \n",
       "\n",
       "                                  ...       CEP4_5    CEP4_6    CEP4_7  \\\n",
       "UF_1                              ...     0.025403  0.017901  0.002279   \n",
       "UF_2                              ...     0.040997  0.006801  0.002159   \n",
       "UF_3                              ...     0.011452  0.008139  0.009605   \n",
       "UF_4                              ...     0.001024  0.005757  0.009747   \n",
       "UF_5                              ...     0.000297  0.002524  0.060533   \n",
       "UF_6                              ...     0.002480  0.023013  0.067999   \n",
       "UF_7                              ...     0.044504  0.024435  0.005311   \n",
       "IDADE                             ...     0.001120  0.004402  0.013037   \n",
       "SEXO_1                            ...     0.000789  0.008388  0.000917   \n",
       "NIVEL_RELACIONAMENTO_CREDITO01    ...     0.002201  0.004603  0.001246   \n",
       "NIVEL_RELACIONAMENTO_CREDITO02    ...     0.001662  0.000234  0.000432   \n",
       "BANCO_REST_IRPF_ULTIMA_1          ...     0.012245  0.016455  0.005782   \n",
       "BANCO_REST_IRPF_ULTIMA_2          ...     0.004858  0.009597  0.004823   \n",
       "BANCO_REST_IRPF_ULTIMA_3          ...     0.011136  0.002867  0.002796   \n",
       "BANCO_REST_IRPF_ULTIMA_4          ...     0.006003  0.005124  0.008856   \n",
       "BANCO_REST_IRPF_ULTIMA_5          ...     0.003891  0.008531  0.007255   \n",
       "BANCO_REST_IRPF_ULTIMA_6          ...     0.012357  0.015106  0.006938   \n",
       "BANCO_REST_IRPF_ULTIMA_7          ...     0.012903  0.014959  0.007677   \n",
       "ATIVIDADE_EMAIL                   ...     0.009134  0.017565  0.001078   \n",
       "EXPOSICAO_ENDERECO                ...     0.000716  0.000250  0.002238   \n",
       "EXPOSICAO_EMAIL                   ...     0.008211  0.016051  0.001216   \n",
       "EXPOSICAO_TELEFONE                ...     0.008441  0.012044  0.003002   \n",
       "ATIVIDADE_ENDERECO                ...     0.005599  0.001461  0.004068   \n",
       "ATUALIZACAO_ENDERECO              ...     0.003096  0.004754  0.000765   \n",
       "ATUALIZACAO_EMAIL                 ...     0.003380  0.009938  0.002884   \n",
       "EXPOSICAO_CONSUMIDOR_EMAILS       ...     0.011044  0.017121  0.000029   \n",
       "EXPOSICAO_CONSUMIDOR_TELEFONES    ...     0.016380  0.012466  0.002132   \n",
       "ATIVIDADE_TELEFONE                ...     0.012557  0.015946  0.000594   \n",
       "VALOR_PARCELA_BOLSA_FAMILIA       ...     0.006317  0.000778  0.014631   \n",
       "FLAG_BOLSA_FAMILIA_1              ...     0.006456  0.000662  0.018833   \n",
       "...                               ...          ...       ...       ...   \n",
       "CEP2_6                            ...     0.028036  0.012740  0.003134   \n",
       "CEP2_7                            ...     0.003456  0.021336  0.014143   \n",
       "CEP2_8                            ...     0.026070  0.000659  0.023503   \n",
       "CEP2_9                            ...     0.049948  0.003169  0.013246   \n",
       "CEP3_1                            ...     0.011758  0.026038  0.048094   \n",
       "CEP3_2                            ...     0.027264  0.054886  0.053113   \n",
       "CEP3_3                            ...     0.011289  0.012343  0.054169   \n",
       "CEP3_4                            ...     0.015391  0.025864  0.056434   \n",
       "CEP3_5                            ...     0.026954  0.014938  0.021426   \n",
       "CEP3_6                            ...     0.013941  0.033553  0.008870   \n",
       "CEP3_7                            ...     0.037716  0.032734  0.042090   \n",
       "CEP3_8                            ...     0.013239  0.020391  0.001042   \n",
       "CEP3_9                            ...     0.003629  0.058565  0.002754   \n",
       "CEP3_10                           ...     0.012316  0.011996  0.001078   \n",
       "CEP3_11                           ...     0.001041  0.024088  0.016885   \n",
       "CEP3_12                           ...     0.005185  0.008472  0.038325   \n",
       "CEP4_1                            ...     0.050156  0.066598  0.062154   \n",
       "CEP4_2                            ...     0.077276  0.079951  0.108763   \n",
       "CEP4_3                            ...     0.055127  0.100593  0.098300   \n",
       "CEP4_4                            ...     0.110578  0.082239  0.059399   \n",
       "CEP4_5                            ...     1.000000  0.081452  0.084146   \n",
       "CEP4_6                            ...     0.081452  1.000000  0.061243   \n",
       "CEP4_7                            ...     0.084146  0.061243  1.000000   \n",
       "CEP4_8                            ...     0.068273  0.055286  0.076438   \n",
       "CEP4_9                            ...     0.074884  0.057445  0.065009   \n",
       "CEP4_10                           ...     0.114886  0.067454  0.079427   \n",
       "CEP4_11                           ...     0.076358  0.093325  0.053802   \n",
       "CEP4_12                           ...     0.081288  0.109380  0.095205   \n",
       "CEP4_13                           ...     0.077429  0.059392  0.093120   \n",
       "CEP4_14                           ...     0.070549  0.105031  0.079717   \n",
       "\n",
       "                                  CEP4_8    CEP4_9   CEP4_10   CEP4_11  \\\n",
       "UF_1                            0.000400  0.041249  0.004074  0.004246   \n",
       "UF_2                            0.035769  0.002821  0.023900  0.012583   \n",
       "UF_3                            0.062716  0.011476  0.038354  0.017366   \n",
       "UF_4                            0.021085  0.012738  0.019959  0.028406   \n",
       "UF_5                            0.009569  0.000885  0.000713  0.001331   \n",
       "UF_6                            0.022139  0.029033  0.065947  0.025372   \n",
       "UF_7                            0.000662  0.006608  0.035075  0.001038   \n",
       "IDADE                           0.001559  0.008037  0.004025  0.000544   \n",
       "SEXO_1                          0.002623  0.002129  0.002683  0.001580   \n",
       "NIVEL_RELACIONAMENTO_CREDITO01  0.002234  0.003535  0.001846  0.000003   \n",
       "NIVEL_RELACIONAMENTO_CREDITO02  0.002970  0.000242  0.003913  0.002860   \n",
       "BANCO_REST_IRPF_ULTIMA_1        0.004235  0.002374  0.004159  0.004780   \n",
       "BANCO_REST_IRPF_ULTIMA_2        0.009435  0.003250  0.007759  0.002070   \n",
       "BANCO_REST_IRPF_ULTIMA_3        0.000919  0.006268  0.004781  0.009614   \n",
       "BANCO_REST_IRPF_ULTIMA_4        0.002532  0.001209  0.002564  0.003083   \n",
       "BANCO_REST_IRPF_ULTIMA_5        0.003513  0.001576  0.003156  0.000101   \n",
       "BANCO_REST_IRPF_ULTIMA_6        0.006781  0.000470  0.004426  0.005728   \n",
       "BANCO_REST_IRPF_ULTIMA_7        0.006785  0.001073  0.002700  0.003872   \n",
       "ATIVIDADE_EMAIL                 0.000889  0.003669  0.001380  0.002623   \n",
       "EXPOSICAO_ENDERECO              0.001343  0.000541  0.005199  0.002688   \n",
       "EXPOSICAO_EMAIL                 0.002955  0.000915  0.000205  0.001108   \n",
       "EXPOSICAO_TELEFONE              0.002395  0.002630  0.000210  0.003113   \n",
       "ATIVIDADE_ENDERECO              0.001806  0.006177  0.005720  0.003607   \n",
       "ATUALIZACAO_ENDERECO            0.005503  0.004270  0.003634  0.011011   \n",
       "ATUALIZACAO_EMAIL               0.000042  0.001869  0.001017  0.000632   \n",
       "EXPOSICAO_CONSUMIDOR_EMAILS     0.002683  0.002318  0.001352  0.004446   \n",
       "EXPOSICAO_CONSUMIDOR_TELEFONES  0.005159  0.000541  0.001936  0.007509   \n",
       "ATIVIDADE_TELEFONE              0.002983  0.002939  0.001914  0.004522   \n",
       "VALOR_PARCELA_BOLSA_FAMILIA     0.009022  0.007882  0.008043  0.008097   \n",
       "FLAG_BOLSA_FAMILIA_1            0.008540  0.011924  0.008404  0.004892   \n",
       "...                                  ...       ...       ...       ...   \n",
       "CEP2_6                          0.033257  0.041206  0.002075  0.022095   \n",
       "CEP2_7                          0.027258  0.002792  0.003459  0.005254   \n",
       "CEP2_8                          0.024130  0.000183  0.015350  0.001205   \n",
       "CEP2_9                          0.003809  0.026293  0.039538  0.031095   \n",
       "CEP3_1                          0.033452  0.058999  0.035789  0.047201   \n",
       "CEP3_2                          0.054921  0.079345  0.059479  0.034065   \n",
       "CEP3_3                          0.021250  0.004511  0.018212  0.011057   \n",
       "CEP3_4                          0.021252  0.014778  0.034971  0.021035   \n",
       "CEP3_5                          0.007138  0.051028  0.003520  0.016496   \n",
       "CEP3_6                          0.013424  0.008919  0.068129  0.010120   \n",
       "CEP3_7                          0.028335  0.022631  0.009884  0.006030   \n",
       "CEP3_8                          0.021430  0.030134  0.009896  0.036293   \n",
       "CEP3_9                          0.048102  0.039036  0.006741  0.009801   \n",
       "CEP3_10                         0.021077  0.042262  0.038610  0.005878   \n",
       "CEP3_11                         0.016830  0.016259  0.008468  0.004203   \n",
       "CEP3_12                         0.030986  0.021511  0.011453  0.014967   \n",
       "CEP4_1                          0.069148  0.057546  0.034671  0.079745   \n",
       "CEP4_2                          0.099927  0.064027  0.066742  0.060307   \n",
       "CEP4_3                          0.068514  0.091356  0.126188  0.057642   \n",
       "CEP4_4                          0.102702  0.086201  0.092063  0.089606   \n",
       "CEP4_5                          0.068273  0.074884  0.114886  0.076358   \n",
       "CEP4_6                          0.055286  0.057445  0.067454  0.093325   \n",
       "CEP4_7                          0.076438  0.065009  0.079427  0.053802   \n",
       "CEP4_8                          1.000000  0.070476  0.081482  0.094420   \n",
       "CEP4_9                          0.070476  1.000000  0.056205  0.107209   \n",
       "CEP4_10                         0.081482  0.056205  1.000000  0.077964   \n",
       "CEP4_11                         0.094420  0.107209  0.077964  1.000000   \n",
       "CEP4_12                         0.037541  0.104018  0.093005  0.065892   \n",
       "CEP4_13                         0.100988  0.096174  0.059894  0.077590   \n",
       "CEP4_14                         0.089647  0.081960  0.067307  0.087774   \n",
       "\n",
       "                                 CEP4_12   CEP4_13   CEP4_14  \n",
       "UF_1                            0.009868  0.022239  0.035315  \n",
       "UF_2                            0.021424  0.007369  0.029016  \n",
       "UF_3                            0.002350  0.018033  0.011395  \n",
       "UF_4                            0.010240  0.023383  0.047764  \n",
       "UF_5                            0.023599  0.026219  0.026264  \n",
       "UF_6                            0.000670  0.015740  0.003706  \n",
       "UF_7                            0.017101  0.034493  0.003431  \n",
       "IDADE                           0.002066  0.000616  0.006353  \n",
       "SEXO_1                          0.004715  0.002303  0.003675  \n",
       "NIVEL_RELACIONAMENTO_CREDITO01  0.000372  0.004002  0.005085  \n",
       "NIVEL_RELACIONAMENTO_CREDITO02  0.001918  0.000591  0.001580  \n",
       "BANCO_REST_IRPF_ULTIMA_1        0.007634  0.000321  0.011306  \n",
       "BANCO_REST_IRPF_ULTIMA_2        0.006667  0.002163  0.012610  \n",
       "BANCO_REST_IRPF_ULTIMA_3        0.000145  0.004880  0.004504  \n",
       "BANCO_REST_IRPF_ULTIMA_4        0.001932  0.001854  0.000901  \n",
       "BANCO_REST_IRPF_ULTIMA_5        0.004460  0.000758  0.006276  \n",
       "BANCO_REST_IRPF_ULTIMA_6        0.006814  0.000359  0.012221  \n",
       "BANCO_REST_IRPF_ULTIMA_7        0.006262  0.001432  0.011833  \n",
       "ATIVIDADE_EMAIL                 0.008246  0.001737  0.015123  \n",
       "EXPOSICAO_ENDERECO              0.000534  0.006409  0.019879  \n",
       "EXPOSICAO_EMAIL                 0.006326  0.002026  0.007416  \n",
       "EXPOSICAO_TELEFONE              0.006901  0.001755  0.008774  \n",
       "ATIVIDADE_ENDERECO              0.004260  0.004610  0.017025  \n",
       "ATUALIZACAO_ENDERECO            0.006841  0.005685  0.021115  \n",
       "ATUALIZACAO_EMAIL               0.005740  0.000358  0.011939  \n",
       "EXPOSICAO_CONSUMIDOR_EMAILS     0.007219  0.001482  0.014085  \n",
       "EXPOSICAO_CONSUMIDOR_TELEFONES  0.007721  0.002992  0.015405  \n",
       "ATIVIDADE_TELEFONE              0.012180  0.000529  0.018880  \n",
       "VALOR_PARCELA_BOLSA_FAMILIA     0.000593  0.008237  0.016280  \n",
       "FLAG_BOLSA_FAMILIA_1            0.000170  0.007389  0.018539  \n",
       "...                                  ...       ...       ...  \n",
       "CEP2_6                          0.000501  0.033753  0.008207  \n",
       "CEP2_7                          0.025808  0.002482  0.016561  \n",
       "CEP2_8                          0.018287  0.027417  0.024925  \n",
       "CEP2_9                          0.007514  0.006430  0.058079  \n",
       "CEP3_1                          0.033384  0.017597  0.019042  \n",
       "CEP3_2                          0.006475  0.003271  0.059274  \n",
       "CEP3_3                          0.061374  0.019429  0.040716  \n",
       "CEP3_4                          0.015093  0.002690  0.003043  \n",
       "CEP3_5                          0.019804  0.003867  0.011449  \n",
       "CEP3_6                          0.009546  0.002526  0.058430  \n",
       "CEP3_7                          0.043659  0.022275  0.006181  \n",
       "CEP3_8                          0.005137  0.000335  0.002855  \n",
       "CEP3_9                          0.007158  0.023076  0.001276  \n",
       "CEP3_10                         0.034739  0.034160  0.015346  \n",
       "CEP3_11                         0.011100  0.007912  0.012464  \n",
       "CEP3_12                         0.014722  0.004071  0.009819  \n",
       "CEP4_1                          0.080468  0.042412  0.056045  \n",
       "CEP4_2                          0.064826  0.068966  0.079220  \n",
       "CEP4_3                          0.055201  0.096777  0.092043  \n",
       "CEP4_4                          0.091386  0.093666  0.076223  \n",
       "CEP4_5                          0.081288  0.077429  0.070549  \n",
       "CEP4_6                          0.109380  0.059392  0.105031  \n",
       "CEP4_7                          0.095205  0.093120  0.079717  \n",
       "CEP4_8                          0.037541  0.100988  0.089647  \n",
       "CEP4_9                          0.104018  0.096174  0.081960  \n",
       "CEP4_10                         0.093005  0.059894  0.067307  \n",
       "CEP4_11                         0.065892  0.077590  0.087774  \n",
       "CEP4_12                         1.000000  0.078021  0.064582  \n",
       "CEP4_13                         0.078021  1.000000  0.068267  \n",
       "CEP4_14                         0.064582  0.068267  1.000000  \n",
       "\n",
       "[243 rows x 243 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Zt72Gp2gf7We",
    "outputId": "b461faa1-d8cf-4d94-ccb3-20784271de10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33220</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.217846</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750400</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340086</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074953</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>237182</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.355855</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>335250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.930834</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>149584</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.678045</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>71560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.485231</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>118664</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.654419</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19053</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.358808</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>368546</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132485</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id UF_1 UF_2 UF_3 UF_4 UF_5 UF_6 UF_7     IDADE  SEXO_1     ...       \\\n",
       "0   33220    1    1    1    0    0    0    0  0.217846       0     ...        \n",
       "1  164123    0    0    1    1    0    1    0  0.750400       0     ...        \n",
       "2  340086    1    0    0    0    1    1    0  0.074953       0     ...        \n",
       "3  237182    1    1    1    0    0    0    0  0.355855       0     ...        \n",
       "4  335250    1    0    1    0    0    1    0  0.930834       1     ...        \n",
       "5  149584    1    1    1    0    0    0    0  0.678045       0     ...        \n",
       "6   71560    1    1    0    0    0    0    1  0.485231       1     ...        \n",
       "7  118664    0    1    1    0    1    0    0  0.654419       1     ...        \n",
       "8   19053    1    1    0    1    0    0    0  0.358808       1     ...        \n",
       "9  368546    1    1    1    0    0    0    0  0.132485       1     ...        \n",
       "\n",
       "   CEP4_7  CEP4_8 CEP4_9 CEP4_10 CEP4_11 CEP4_12 CEP4_13 CEP4_14 IND_BOM_1_1  \\\n",
       "0       0       0      1       1       0       0       0       0           0   \n",
       "1       0       1      0       1       1       0       0       0           0   \n",
       "2       0       0      0       0       0       1       1       1           1   \n",
       "3       0       1      1       1       0       0       0       1           1   \n",
       "4       0       1      0       0       0       1       0       0           1   \n",
       "5       1       0      0       1       0       0       1       0           1   \n",
       "6       1       0      1       0       1       0       0       0           1   \n",
       "7       0       0      0       0       0       1       1       1           1   \n",
       "8       0       0      0       0       1       1       0       1           1   \n",
       "9       1       1      1       1       0       0       0       1           1   \n",
       "\n",
       "   IND_BOM_1_2  \n",
       "0            1  \n",
       "1            1  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "5            0  \n",
       "6            0  \n",
       "7            0  \n",
       "8            0  \n",
       "9            0  \n",
       "\n",
       "[10 rows x 246 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "8SWa1sFkf7Wh"
   },
   "outputs": [],
   "source": [
    "corr_matrix = features.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Mmg3lV6df7Wk"
   },
   "outputs": [],
   "source": [
    "values = corr_matrix[corr_matrix > 0.95].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xDl_gqVdf7Wn",
    "outputId": "8e97c2b1-d549-477f-ca37-3d85adc4205a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLAG_BOLSA_FAMILIA_1        2\n",
       "RENDA_VIZINHANCA_1          2\n",
       "RENDA_VIZINHANCA_4          2\n",
       "FLAG_PROGRAMAS_SOCIAIS_1    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[values > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "p4_M6HP1f7Wq",
    "outputId": "e6d2bd55-082c-450c-8f45-ac7d2f30852a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_5</th>\n",
       "      <th>CEP4_6</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RENDA_VIZINHANCA_1</th>\n",
       "      <td>0.039497</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>0.095179</td>\n",
       "      <td>0.120255</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>0.021913</td>\n",
       "      <td>0.094908</td>\n",
       "      <td>0.056833</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014022</td>\n",
       "      <td>0.030272</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.022686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RENDA_VIZINHANCA_4</th>\n",
       "      <td>0.042773</td>\n",
       "      <td>0.123006</td>\n",
       "      <td>0.096118</td>\n",
       "      <td>0.121031</td>\n",
       "      <td>0.041934</td>\n",
       "      <td>0.020677</td>\n",
       "      <td>0.093601</td>\n",
       "      <td>0.053994</td>\n",
       "      <td>0.009825</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014699</td>\n",
       "      <td>0.027470</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>0.020939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        UF_1      UF_2      UF_3      UF_4      UF_5  \\\n",
       "RENDA_VIZINHANCA_1  0.039497  0.126106  0.095179  0.120255  0.040225   \n",
       "RENDA_VIZINHANCA_4  0.042773  0.123006  0.096118  0.121031  0.041934   \n",
       "\n",
       "                        UF_6      UF_7     IDADE    SEXO_1  \\\n",
       "RENDA_VIZINHANCA_1  0.021913  0.094908  0.056833  0.011343   \n",
       "RENDA_VIZINHANCA_4  0.020677  0.093601  0.053994  0.009825   \n",
       "\n",
       "                    NIVEL_RELACIONAMENTO_CREDITO01    ...       CEP4_5  \\\n",
       "RENDA_VIZINHANCA_1                        0.004249    ...     0.014022   \n",
       "RENDA_VIZINHANCA_4                        0.003914    ...     0.014699   \n",
       "\n",
       "                      CEP4_6    CEP4_7    CEP4_8    CEP4_9   CEP4_10  \\\n",
       "RENDA_VIZINHANCA_1  0.030272  0.002249  0.002028  0.003034  0.005432   \n",
       "RENDA_VIZINHANCA_4  0.027470  0.003278  0.000880  0.003880  0.005072   \n",
       "\n",
       "                     CEP4_11   CEP4_12   CEP4_13   CEP4_14  \n",
       "RENDA_VIZINHANCA_1  0.003514  0.008236  0.007406  0.022686  \n",
       "RENDA_VIZINHANCA_4  0.002067  0.006980  0.006323  0.020939  \n",
       "\n",
       "[2 rows x 243 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix[corr_matrix[\"RENDA_VIZINHANCA_1\"] > 0.90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-EcYcC7f7Ws"
   },
   "source": [
    "RENDA_VIZINHANCA_1 e  RENDA_VIZINHANCA_4 possuem alta correlação e FLAG_BOLSA_FAMILIA_1 e FLAG_PROGRAMAS_SOCIAIS_1\n",
    "também. Logo, vou ficar com somente duas das 4.\n",
    "Contudo, este teste é para apenas para variáveis correlacionadas linearmente, existem testes melhores para as variáveis categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "CUw5h-3-f7Wv"
   },
   "outputs": [],
   "source": [
    "features = features.drop([\"RENDA_VIZINHANCA_1\", \"FLAG_BOLSA_FAMILIA_1\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DW2eZPNqf7Ww",
    "outputId": "12e06a68-652f-4862-afec-c71cf7b83125"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194598, 244)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "r7Fy_BfIf7W0",
    "outputId": "378e6199-1661-4c9e-b6f2-53ae48ab021a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194598, 244)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.drop_duplicates(inplace=True)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "pMKX3EYpf7W2"
   },
   "outputs": [],
   "source": [
    "training_data_model = pandas.concat([features, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qDz38AF4f7W4",
    "outputId": "7d52be84-9540-40da-f835-55f9b0f77aca"
   },
   "outputs": [],
   "source": [
    "training_data_model.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5IRkO1O5f7W8",
    "outputId": "5cec10ba-db60-4ef9-d629-a1a906377ee6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    76592\n",
       "0    40167\n",
       "Name: IND_BOM_1_1, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paWFizV2f7W-"
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4WPUJbff7XC"
   },
   "source": [
    "In this module we're trying to build the feature that we see will be more useful in order to learn about\n",
    "the class we need to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NHVg252Vf7XF"
   },
   "source": [
    "# Model Tranining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "VtaX3fzFf7XH"
   },
   "outputs": [],
   "source": [
    "features = training_data.drop([\"IND_BOM_1_1\", \"IND_BOM_1_2\", \"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DfSOkMvof7XK",
    "outputId": "b53fa1b1-6050-4d99-deee-156cc011dedc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_5</th>\n",
       "      <th>CEP4_6</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.774140</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.644480</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112948</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.348926</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631134</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.591719</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.511981</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "0     1     1     0     1     0     0     0  0.907889       1   \n",
       "1     1     1     0     0     0     1     0  0.526122       1   \n",
       "2     1     1     1     0     0     0     0  0.225400       1   \n",
       "3     1     1     1     0     0     0     0  0.774140       1   \n",
       "4     1     1     1     0     0     0     0  0.644480       0   \n",
       "5     1     1     0     0     1     0     0  0.112948       1   \n",
       "6     0     1     1     1     0     0     0  0.348926       0   \n",
       "7     1     1     0     1     0     0     0  0.631134       0   \n",
       "8     1     1     0     1     0     0     0  0.591719       0   \n",
       "9     1     1     1     0     0     0     0  0.511981       1   \n",
       "\n",
       "   NIVEL_RELACIONAMENTO_CREDITO01   ...     CEP4_5  CEP4_6  CEP4_7  CEP4_8  \\\n",
       "0                        0.111111   ...          0       1       1       1   \n",
       "1                        0.111111   ...          0       1       1       1   \n",
       "2                        0.111111   ...          0       0       1       1   \n",
       "3                        0.111111   ...          1       0       0       1   \n",
       "4                        0.111111   ...          0       0       1       0   \n",
       "5                        0.111111   ...          0       0       0       0   \n",
       "6                        0.111111   ...          1       0       1       0   \n",
       "7                        0.000000   ...          1       1       0       0   \n",
       "8                        0.111111   ...          0       0       1       1   \n",
       "9                        0.111111   ...          1       0       0       1   \n",
       "\n",
       "   CEP4_9  CEP4_10  CEP4_11  CEP4_12  CEP4_13  CEP4_14  \n",
       "0       1        0        0        0        0        0  \n",
       "1       0        1        1        1        0        0  \n",
       "2       1        1        0        1        0        0  \n",
       "3       1        1        0        0        1        0  \n",
       "4       0        1        0        1        0        1  \n",
       "5       1        0        1        1        1        0  \n",
       "6       0        0        1        0        0        0  \n",
       "7       0        1        1        0        0        1  \n",
       "8       0        0        0        1        1        1  \n",
       "9       0        1        0        1        0        0  \n",
       "\n",
       "[10 rows x 243 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "vrTBDGb0f7XO"
   },
   "outputs": [],
   "source": [
    "labels = training_data[\"IND_BOM_1_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38920,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "pt0S5t9yf7XQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "xrXbhsrRf7XT"
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=1/4, \n",
    "#                                                    random_state=42, stratify=labels)\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=1/3, \n",
    "#                                                  random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "xrXbhsrRf7XT"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create function to plot AUC_ROC given model and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc_roc(model, x_test, y_test):\n",
    "    probs = model.predict_proba(x_test)\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=20,\n",
    "                              verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_1 = Sequential()\n",
    "classifier_1.add(Dense(16, activation='tanh', input_dim=input_dimension))\n",
    "classifier_1.add(Dense(16, activation='relu', input_dim=input_dimension))\n",
    "classifier_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "classifier_1.compile(optimizer='adam', loss='mean_squared_error', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "senmQCDef7Xc"
   },
   "outputs": [],
   "source": [
    "classifier_2 = Sequential()\n",
    "classifier_2.add(Dense(16, activation='tanh', input_dim=input_dimension))\n",
    "classifier_2.add(Dense(16, activation='tanh', input_dim=input_dimension))\n",
    "classifier_2.add(Dense(8, activation='relu', input_dim=input_dimension/2))\n",
    "classifier_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "classifier_2.compile(optimizer='adam', loss='mean_squared_error', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_3 = Sequential()\n",
    "classifier_3.add(Dense(16, activation='relu', input_dim=input_dimension))\n",
    "classifier_3.add(Dense(8, activation='relu', input_dim=input_dimension))\n",
    "classifier_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "classifier_3.compile(optimizer='adam', loss='mean_squared_error', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z7_JtotLf7Xe"
   },
   "source": [
    "I use as_matrix because Keras expects a Numpy array instead of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Rri7yLInf7Xf",
    "outputId": "7f969378-2d9a-4069-98d5-578e60ec4ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                3904      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 4,193\n",
      "Trainable params: 4,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                3904      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 4,321\n",
      "Trainable params: 4,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 16)                3904      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 4,049\n",
      "Trainable params: 4,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49622 samples, validate on 8757 samples\n",
      "Epoch 1/500\n",
      "49622/49622 [==============================] - 6s 124us/step - loss: 0.2145 - acc: 0.6632 - val_loss: 0.2072 - val_acc: 0.6735\n",
      "Epoch 2/500\n",
      "49622/49622 [==============================] - 7s 134us/step - loss: 0.2083 - acc: 0.6707 - val_loss: 0.2057 - val_acc: 0.6763\n",
      "Epoch 3/500\n",
      "49622/49622 [==============================] - 6s 124us/step - loss: 0.2066 - acc: 0.6737 - val_loss: 0.2047 - val_acc: 0.6788\n",
      "Epoch 4/500\n",
      "49622/49622 [==============================] - 5s 110us/step - loss: 0.2050 - acc: 0.6768 - val_loss: 0.2047 - val_acc: 0.6752\n",
      "Epoch 5/500\n",
      "49622/49622 [==============================] - 5s 105us/step - loss: 0.2039 - acc: 0.6798 - val_loss: 0.2041 - val_acc: 0.6780\n",
      "Epoch 6/500\n",
      "49622/49622 [==============================] - 8s 160us/step - loss: 0.2030 - acc: 0.6832 - val_loss: 0.2039 - val_acc: 0.6753\n",
      "Epoch 7/500\n",
      "49622/49622 [==============================] - 7s 144us/step - loss: 0.2021 - acc: 0.6834 - val_loss: 0.2041 - val_acc: 0.6788\n",
      "Epoch 8/500\n",
      "49622/49622 [==============================] - 9s 188us/step - loss: 0.2016 - acc: 0.6842 - val_loss: 0.2038 - val_acc: 0.6779\n",
      "Epoch 9/500\n",
      "49622/49622 [==============================] - 8s 156us/step - loss: 0.2010 - acc: 0.6860 - val_loss: 0.2041 - val_acc: 0.6782\n",
      "Epoch 10/500\n",
      "49622/49622 [==============================] - 6s 127us/step - loss: 0.1999 - acc: 0.6872 - val_loss: 0.2037 - val_acc: 0.6766\n",
      "Epoch 11/500\n",
      "49622/49622 [==============================] - 6s 124us/step - loss: 0.1994 - acc: 0.6888 - val_loss: 0.2052 - val_acc: 0.6800\n",
      "Epoch 12/500\n",
      "49622/49622 [==============================] - 7s 143us/step - loss: 0.1988 - acc: 0.6892 - val_loss: 0.2045 - val_acc: 0.6749\n",
      "Epoch 13/500\n",
      "49622/49622 [==============================] - 6s 120us/step - loss: 0.1981 - acc: 0.6911 - val_loss: 0.2051 - val_acc: 0.6732\n",
      "Epoch 14/500\n",
      "49622/49622 [==============================] - 7s 150us/step - loss: 0.1976 - acc: 0.6929 - val_loss: 0.2063 - val_acc: 0.6815\n",
      "Epoch 15/500\n",
      "49622/49622 [==============================] - 7s 148us/step - loss: 0.1965 - acc: 0.6957 - val_loss: 0.2054 - val_acc: 0.6741\n",
      "Epoch 16/500\n",
      "49622/49622 [==============================] - 9s 188us/step - loss: 0.1962 - acc: 0.6963 - val_loss: 0.2067 - val_acc: 0.6726\n",
      "Epoch 17/500\n",
      "49622/49622 [==============================] - 7s 140us/step - loss: 0.1956 - acc: 0.6960 - val_loss: 0.2058 - val_acc: 0.6765\n",
      "Epoch 18/500\n",
      "49622/49622 [==============================] - 6s 126us/step - loss: 0.1949 - acc: 0.6996 - val_loss: 0.2062 - val_acc: 0.6736\n",
      "Epoch 19/500\n",
      "49622/49622 [==============================] - 6s 126us/step - loss: 0.1944 - acc: 0.7000 - val_loss: 0.2083 - val_acc: 0.6690\n",
      "Epoch 20/500\n",
      "49622/49622 [==============================] - 7s 140us/step - loss: 0.1941 - acc: 0.7030 - val_loss: 0.2086 - val_acc: 0.6646\n",
      "Epoch 21/500\n",
      "49622/49622 [==============================] - 9s 187us/step - loss: 0.1933 - acc: 0.7033 - val_loss: 0.2081 - val_acc: 0.6662\n",
      "Epoch 22/500\n",
      "49622/49622 [==============================] - 7s 139us/step - loss: 0.1927 - acc: 0.7048 - val_loss: 0.2083 - val_acc: 0.6648\n",
      "Epoch 23/500\n",
      "49622/49622 [==============================] - 7s 141us/step - loss: 0.1926 - acc: 0.7058 - val_loss: 0.2094 - val_acc: 0.6663\n",
      "Epoch 24/500\n",
      "49622/49622 [==============================] - 8s 168us/step - loss: 0.1919 - acc: 0.7067 - val_loss: 0.2087 - val_acc: 0.6679\n",
      "Epoch 25/500\n",
      "49622/49622 [==============================] - 7s 147us/step - loss: 0.1914 - acc: 0.7085 - val_loss: 0.2105 - val_acc: 0.6610\n",
      "Epoch 26/500\n",
      "49622/49622 [==============================] - 6s 128us/step - loss: 0.1908 - acc: 0.7109 - val_loss: 0.2115 - val_acc: 0.6724\n",
      "Epoch 27/500\n",
      "49622/49622 [==============================] - 7s 135us/step - loss: 0.1906 - acc: 0.7087 - val_loss: 0.2111 - val_acc: 0.6598\n",
      "Epoch 28/500\n",
      "49622/49622 [==============================] - 7s 136us/step - loss: 0.1903 - acc: 0.7120 - val_loss: 0.2104 - val_acc: 0.6676\n",
      "Epoch 29/500\n",
      "49622/49622 [==============================] - 9s 187us/step - loss: 0.1898 - acc: 0.7120 - val_loss: 0.2111 - val_acc: 0.6713\n",
      "Epoch 30/500\n",
      "49622/49622 [==============================] - 6s 119us/step - loss: 0.1893 - acc: 0.7103 - val_loss: 0.2105 - val_acc: 0.6674\n"
     ]
    }
   ],
   "source": [
    "model = classifier_1.fit(X_train.as_matrix(), y_train.as_matrix(),epochs=500, callbacks=[early_stopping], validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49622 samples, validate on 8757 samples\n",
      "Epoch 1/500\n",
      "49622/49622 [==============================] - 8s 164us/step - loss: 0.2154 - acc: 0.6602 - val_loss: 0.2080 - val_acc: 0.6726\n",
      "Epoch 2/500\n",
      "49622/49622 [==============================] - 7s 136us/step - loss: 0.2080 - acc: 0.6707 - val_loss: 0.2056 - val_acc: 0.6783\n",
      "Epoch 3/500\n",
      "49622/49622 [==============================] - 8s 167us/step - loss: 0.2059 - acc: 0.6748 - val_loss: 0.2071 - val_acc: 0.6758\n",
      "Epoch 4/500\n",
      "49622/49622 [==============================] - 6s 122us/step - loss: 0.2049 - acc: 0.6765 - val_loss: 0.2038 - val_acc: 0.6763\n",
      "Epoch 5/500\n",
      "49622/49622 [==============================] - 7s 139us/step - loss: 0.2039 - acc: 0.6809 - val_loss: 0.2052 - val_acc: 0.6750\n",
      "Epoch 6/500\n",
      "49622/49622 [==============================] - 7s 132us/step - loss: 0.2030 - acc: 0.6818 - val_loss: 0.2060 - val_acc: 0.6684\n",
      "Epoch 7/500\n",
      "49622/49622 [==============================] - 6s 130us/step - loss: 0.2026 - acc: 0.6838 - val_loss: 0.2033 - val_acc: 0.6775\n",
      "Epoch 8/500\n",
      "49622/49622 [==============================] - 6s 124us/step - loss: 0.2019 - acc: 0.6840 - val_loss: 0.2051 - val_acc: 0.6725\n",
      "Epoch 9/500\n",
      "49622/49622 [==============================] - 6s 115us/step - loss: 0.2015 - acc: 0.6844 - val_loss: 0.2047 - val_acc: 0.6784\n",
      "Epoch 10/500\n",
      "49622/49622 [==============================] - 6s 116us/step - loss: 0.2010 - acc: 0.6859 - val_loss: 0.2064 - val_acc: 0.6696\n",
      "Epoch 11/500\n",
      "49622/49622 [==============================] - 6s 116us/step - loss: 0.2005 - acc: 0.6884 - val_loss: 0.2052 - val_acc: 0.6800\n",
      "Epoch 12/500\n",
      "49622/49622 [==============================] - 6s 113us/step - loss: 0.2001 - acc: 0.6882 - val_loss: 0.2040 - val_acc: 0.6775\n",
      "Epoch 13/500\n",
      "49622/49622 [==============================] - 6s 116us/step - loss: 0.1995 - acc: 0.6899 - val_loss: 0.2064 - val_acc: 0.6699\n",
      "Epoch 14/500\n",
      "49622/49622 [==============================] - 6s 120us/step - loss: 0.1993 - acc: 0.6901 - val_loss: 0.2064 - val_acc: 0.6685\n",
      "Epoch 15/500\n",
      "49622/49622 [==============================] - 6s 116us/step - loss: 0.1987 - acc: 0.6906 - val_loss: 0.2065 - val_acc: 0.6779\n",
      "Epoch 16/500\n",
      "49622/49622 [==============================] - 6s 111us/step - loss: 0.1981 - acc: 0.6927 - val_loss: 0.2055 - val_acc: 0.6789\n",
      "Epoch 17/500\n",
      "49622/49622 [==============================] - 6s 118us/step - loss: 0.1976 - acc: 0.6945 - val_loss: 0.2083 - val_acc: 0.6655\n",
      "Epoch 18/500\n",
      "49622/49622 [==============================] - 6s 117us/step - loss: 0.1974 - acc: 0.6952 - val_loss: 0.2075 - val_acc: 0.6660\n",
      "Epoch 19/500\n",
      "49622/49622 [==============================] - 6s 117us/step - loss: 0.1970 - acc: 0.6960 - val_loss: 0.2061 - val_acc: 0.6775\n",
      "Epoch 20/500\n",
      "49622/49622 [==============================] - 6s 113us/step - loss: 0.1966 - acc: 0.6972 - val_loss: 0.2068 - val_acc: 0.6796\n",
      "Epoch 21/500\n",
      "49622/49622 [==============================] - 6s 115us/step - loss: 0.1964 - acc: 0.6976 - val_loss: 0.2069 - val_acc: 0.6675\n",
      "Epoch 22/500\n",
      "49622/49622 [==============================] - 6s 113us/step - loss: 0.1958 - acc: 0.6978 - val_loss: 0.2067 - val_acc: 0.6765\n",
      "Epoch 23/500\n",
      "49622/49622 [==============================] - 6s 116us/step - loss: 0.1958 - acc: 0.6972 - val_loss: 0.2087 - val_acc: 0.6639\n",
      "Epoch 24/500\n",
      "49622/49622 [==============================] - 6s 118us/step - loss: 0.1954 - acc: 0.7001 - val_loss: 0.2087 - val_acc: 0.6771\n",
      "Epoch 25/500\n",
      "49622/49622 [==============================] - 6s 113us/step - loss: 0.1951 - acc: 0.7002 - val_loss: 0.2088 - val_acc: 0.6701\n",
      "Epoch 26/500\n",
      "49622/49622 [==============================] - 6s 112us/step - loss: 0.1948 - acc: 0.7010 - val_loss: 0.2078 - val_acc: 0.6757\n",
      "Epoch 27/500\n",
      "49622/49622 [==============================] - 6s 111us/step - loss: 0.1946 - acc: 0.7021 - val_loss: 0.2085 - val_acc: 0.6694\n"
     ]
    }
   ],
   "source": [
    "model = classifier_3.fit(X_train.as_matrix(), y_train.as_matrix(),epochs=500, callbacks=[early_stopping], validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "96eZigggf7Xg",
    "outputId": "a59b89bb-a36b-4145-9574-55dd6d273c8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49622 samples, validate on 8757 samples\n",
      "Epoch 1/500\n",
      "49622/49622 [==============================] - 6s 125us/step - loss: 0.2142 - acc: 0.6627 - val_loss: 0.2063 - val_acc: 0.6773\n",
      "Epoch 2/500\n",
      "49622/49622 [==============================] - 6s 114us/step - loss: 0.2075 - acc: 0.6710 - val_loss: 0.2053 - val_acc: 0.6817\n",
      "Epoch 3/500\n",
      "49622/49622 [==============================] - 6s 118us/step - loss: 0.2057 - acc: 0.6737 - val_loss: 0.2077 - val_acc: 0.6815\n",
      "Epoch 4/500\n",
      "49622/49622 [==============================] - 6s 127us/step - loss: 0.2042 - acc: 0.6785 - val_loss: 0.2043 - val_acc: 0.6824\n",
      "Epoch 5/500\n",
      "49622/49622 [==============================] - 8s 156us/step - loss: 0.2034 - acc: 0.6784 - val_loss: 0.2042 - val_acc: 0.6845\n",
      "Epoch 6/500\n",
      "49622/49622 [==============================] - 6s 125us/step - loss: 0.2024 - acc: 0.6815 - val_loss: 0.2042 - val_acc: 0.6759\n",
      "Epoch 7/500\n",
      "49622/49622 [==============================] - 6s 119us/step - loss: 0.2014 - acc: 0.6844 - val_loss: 0.2036 - val_acc: 0.6838\n",
      "Epoch 8/500\n",
      "49622/49622 [==============================] - 6s 116us/step - loss: 0.2008 - acc: 0.6842 - val_loss: 0.2058 - val_acc: 0.6871\n",
      "Epoch 9/500\n",
      "49622/49622 [==============================] - 6s 119us/step - loss: 0.1999 - acc: 0.6870 - val_loss: 0.2035 - val_acc: 0.6831\n",
      "Epoch 10/500\n",
      "49622/49622 [==============================] - 5s 107us/step - loss: 0.1994 - acc: 0.6883 - val_loss: 0.2045 - val_acc: 0.6788\n",
      "Epoch 11/500\n",
      "49622/49622 [==============================] - 5s 100us/step - loss: 0.1984 - acc: 0.6902 - val_loss: 0.2061 - val_acc: 0.6680\n",
      "Epoch 12/500\n",
      "49622/49622 [==============================] - 5s 108us/step - loss: 0.1978 - acc: 0.6911 - val_loss: 0.2059 - val_acc: 0.6732\n",
      "Epoch 13/500\n",
      "49622/49622 [==============================] - 7s 142us/step - loss: 0.1971 - acc: 0.6943 - val_loss: 0.2052 - val_acc: 0.6825\n",
      "Epoch 14/500\n",
      "49622/49622 [==============================] - 9s 187us/step - loss: 0.1969 - acc: 0.6926 - val_loss: 0.2060 - val_acc: 0.6815\n",
      "Epoch 15/500\n",
      "49622/49622 [==============================] - 7s 138us/step - loss: 0.1961 - acc: 0.6958 - val_loss: 0.2055 - val_acc: 0.6733\n",
      "Epoch 16/500\n",
      "49622/49622 [==============================] - 6s 120us/step - loss: 0.1952 - acc: 0.6981 - val_loss: 0.2063 - val_acc: 0.6723\n",
      "Epoch 17/500\n",
      "49622/49622 [==============================] - 6s 119us/step - loss: 0.1947 - acc: 0.6984 - val_loss: 0.2064 - val_acc: 0.6731\n",
      "Epoch 18/500\n",
      "49622/49622 [==============================] - 7s 133us/step - loss: 0.1940 - acc: 0.7009 - val_loss: 0.2081 - val_acc: 0.6623\n",
      "Epoch 19/500\n",
      "49622/49622 [==============================] - 6s 118us/step - loss: 0.1933 - acc: 0.7013 - val_loss: 0.2074 - val_acc: 0.6753\n",
      "Epoch 20/500\n",
      "49622/49622 [==============================] - 6s 114us/step - loss: 0.1929 - acc: 0.7040 - val_loss: 0.2071 - val_acc: 0.6708\n",
      "Epoch 21/500\n",
      "49622/49622 [==============================] - 6s 115us/step - loss: 0.1925 - acc: 0.7044 - val_loss: 0.2101 - val_acc: 0.6622\n",
      "Epoch 22/500\n",
      "49622/49622 [==============================] - 6s 114us/step - loss: 0.1921 - acc: 0.7049 - val_loss: 0.2088 - val_acc: 0.6692\n",
      "Epoch 23/500\n",
      "49622/49622 [==============================] - 6s 118us/step - loss: 0.1916 - acc: 0.7051 - val_loss: 0.2093 - val_acc: 0.6739\n",
      "Epoch 24/500\n",
      "49622/49622 [==============================] - 6s 120us/step - loss: 0.1910 - acc: 0.7074 - val_loss: 0.2108 - val_acc: 0.6686\n",
      "Epoch 25/500\n",
      "49622/49622 [==============================] - 7s 147us/step - loss: 0.1906 - acc: 0.7093 - val_loss: 0.2097 - val_acc: 0.6751\n",
      "Epoch 26/500\n",
      "49622/49622 [==============================] - 7s 146us/step - loss: 0.1901 - acc: 0.7100 - val_loss: 0.2089 - val_acc: 0.6721\n",
      "Epoch 27/500\n",
      "49622/49622 [==============================] - 7s 146us/step - loss: 0.1894 - acc: 0.7115 - val_loss: 0.2102 - val_acc: 0.6693\n",
      "Epoch 28/500\n",
      "49622/49622 [==============================] - 9s 175us/step - loss: 0.1891 - acc: 0.7128 - val_loss: 0.2112 - val_acc: 0.6646\n",
      "Epoch 29/500\n",
      "49622/49622 [==============================] - 12s 246us/step - loss: 0.1889 - acc: 0.7139 - val_loss: 0.2118 - val_acc: 0.6634\n"
     ]
    }
   ],
   "source": [
    "model = classifier_2.fit(X_train.as_matrix(), y_train.as_matrix(),epochs=500, callbacks=[early_stopping], validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(243,))\n",
    "\n",
    "x1 = Dense(16, activation=\"tanh\")(inputs)\n",
    "x1 = Dense(16, activation=\"relu\")(x1)\n",
    "\n",
    "x2 = Dense(16, activation=\"tanh\")(inputs)\n",
    "x2 = Dense(8, activation=\"relu\")(x2)\n",
    "\n",
    "x3 = Dense(16, activation=\"tanh\")(inputs)\n",
    "x3 = Dense(16, activation=\"tanh\")(x3)\n",
    "x3 = Dense(8, activation=\"relu\")(x3)\n",
    "\n",
    "x4 = concatenate([x1,x2,x3])\n",
    "\n",
    "prediction = Dense(1, activation=\"sigmoid\")(x4)\n",
    "\n",
    "voting_classifier = Model(inputs=inputs, outputs= prediction)\n",
    "voting_classifier.compile(optimizer='adam', loss='mean_squared_error', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_voting = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=10,\n",
    "                              verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49622 samples, validate on 8757 samples\n",
      "Epoch 1/500\n",
      "49622/49622 [==============================] - 6s 127us/step - loss: 0.1666 - acc: 0.7577 - val_loss: 0.2292 - val_acc: 0.6459\n",
      "Epoch 2/500\n",
      "49622/49622 [==============================] - 7s 136us/step - loss: 0.1654 - acc: 0.7612 - val_loss: 0.2301 - val_acc: 0.6517\n",
      "Epoch 3/500\n",
      "49622/49622 [==============================] - 7s 140us/step - loss: 0.1639 - acc: 0.7650 - val_loss: 0.2323 - val_acc: 0.6433\n",
      "Epoch 4/500\n",
      "49622/49622 [==============================] - 6s 126us/step - loss: 0.1629 - acc: 0.7669 - val_loss: 0.2308 - val_acc: 0.6599\n",
      "Epoch 5/500\n",
      "49622/49622 [==============================] - 7s 131us/step - loss: 0.1617 - acc: 0.7688 - val_loss: 0.2331 - val_acc: 0.6493\n",
      "Epoch 6/500\n",
      "49622/49622 [==============================] - 7s 136us/step - loss: 0.1604 - acc: 0.7738 - val_loss: 0.2350 - val_acc: 0.6433\n",
      "Epoch 7/500\n",
      "49622/49622 [==============================] - 7s 135us/step - loss: 0.1592 - acc: 0.7733 - val_loss: 0.2365 - val_acc: 0.6426\n",
      "Epoch 8/500\n",
      "49622/49622 [==============================] - 7s 133us/step - loss: 0.1583 - acc: 0.7753 - val_loss: 0.2370 - val_acc: 0.6437\n",
      "Epoch 9/500\n",
      "49622/49622 [==============================] - 6s 129us/step - loss: 0.1569 - acc: 0.7787 - val_loss: 0.2341 - val_acc: 0.6558\n",
      "Epoch 10/500\n",
      "49622/49622 [==============================] - 7s 132us/step - loss: 0.1563 - acc: 0.7801 - val_loss: 0.2376 - val_acc: 0.6571\n",
      "Epoch 11/500\n",
      "49622/49622 [==============================] - 7s 133us/step - loss: 0.1547 - acc: 0.7836 - val_loss: 0.2374 - val_acc: 0.6534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a449f3c9e8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier.fit(X_train.as_matrix(), y_train.as_matrix(),epochs=500, callbacks=[early_stopping_voting], validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "IPdXIjuef7Xk"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier = VotingClassifier([('classifier_1', classifier_1), ('classifier_2', classifier_2), ('classifier_3',classifier_3)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gltINz0wf7Xn"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters to choose\n",
    "number_estimators =  [160, 200]\n",
    "max_features = [\"sqrt\"]\n",
    "max_depth = [10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = GridSearchCV(estimator=RandomForestClassifier(), \n",
    "                          param_grid=dict(\n",
    "                              n_estimators=number_estimators,\n",
    "                              max_features=max_features,\n",
    "                              max_depth=max_depth), cv=5, verbose=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=160 ...............\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=160 ...............\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=160 ...............\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=160 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=160, score=0.6667278399706368, total=  42.5s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=160 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=160, score=0.6687465590016517, total=  42.8s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=160, score=0.6685630390897412, total=  42.9s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=160, score=0.6637915213800697, total=  44.1s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=160, score=0.6703377386196769, total=  38.2s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=200, score=0.6696641585612039, total=  48.0s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=200, score=0.6669113598825472, total=  49.3s\n",
      "[CV] max_depth=15, max_features=sqrt, n_estimators=160 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=200, score=0.6672783997063682, total=  49.2s\n",
      "[CV] max_depth=15, max_features=sqrt, n_estimators=160 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=200, score=0.6687465590016517, total=  48.5s\n",
      "[CV] max_depth=15, max_features=sqrt, n_estimators=160 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=200, score=0.6690528634361234, total=  49.1s\n",
      "[CV] max_depth=15, max_features=sqrt, n_estimators=160 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=15, max_features=sqrt, n_estimators=160, score=0.672600477151771, total=  55.8s\n",
      "[CV] max_depth=15, max_features=sqrt, n_estimators=160 ...............\n",
      "[CV]  max_depth=15, max_features=sqrt, n_estimators=160, score=0.669297118737383, total=  57.8s\n",
      "[CV] max_depth=15, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=15, max_features=sqrt, n_estimators=160, score=0.6689300789135622, total=  59.1s\n",
      "[CV] max_depth=15, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=15, max_features=sqrt, n_estimators=160, score=0.669297118737383, total=  55.5s\n",
      "[CV] max_depth=15, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=15, max_features=sqrt, n_estimators=160, score=0.663546255506608, total=  53.4s\n",
      "[CV] max_depth=15, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=15, max_features=sqrt, n_estimators=200, score=0.6705817581207562, total= 1.1min\n",
      "[CV] max_depth=15, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=15, max_features=sqrt, n_estimators=200, score=0.6641585612038906, total=  59.5s\n",
      "[CV]  max_depth=15, max_features=sqrt, n_estimators=200, score=0.6658102404110846, total= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed:  4.4min remaining:   29.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=15, max_features=sqrt, n_estimators=200, score=0.6716828775922188, total=  57.8s\n",
      "[CV]  max_depth=15, max_features=sqrt, n_estimators=200, score=0.663546255506608, total=  54.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [160, 200], 'max_features': ['sqrt'], 'max_depth': [10, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [160, 200], 'max_features': ['sqrt'], 'max_depth': [10, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15, 'max_features': 'sqrt', 'n_estimators': 160}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsNvsgwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc9a90e2ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_auc_roc(rf_classifier.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The score of the rf_classifier alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = rf_classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_train_pred = classifier.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = classifier.predict(X_test.as_matrix()).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XXpon-XGf7X9",
    "outputId": "e3724372-f7c7-42b7-ab07-db29750a1d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier.predict_proba(X_test.as_matrix())[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HC--sBLtf7YC",
    "outputId": "5633e246-2e20-4b4a-ee44-0dd2056dc0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6717\n",
      "Recall:           0.9274\n",
      "Precision:        0.6851\n",
      "F1:               0.7880\n",
      "AUROC:            0.6705\n",
      "AUPR:             0.7949\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use grid search to improve our search for parameters using Cross Validation\n",
    "number_estimators = [100, 120, 140]\n",
    "loss_function = [\"deviance\", \"exponential\"]\n",
    "min_samples_leaf = [1, 0.05, 0.5]\n",
    "sub_samples = [0.85, 0.8, 0.7]\n",
    "max_features = [\"sqrt\"]\n",
    "xgboost_classifier = GridSearchCV(estimator=GradientBoostingClassifier(), \n",
    "                          param_grid=dict(\n",
    "                              n_estimators=number_estimators,\n",
    "                              max_features=max_features,\n",
    "                              subsample=sub_samples,\n",
    "                          min_samples_leaf=min_samples_leaf,\n",
    "                          loss=loss_function), verbose=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85 \n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85 \n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85 \n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85, score=0.6803726379773598, total=  44.4s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85, score=0.6851297185394001, total=  46.7s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8, score=0.6807250143152888, total=  47.4s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85, score=0.6825749900894155, total=  48.6s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8, score=0.6839624719200106, total=  43.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7, score=0.6817160727657138, total=  42.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7, score=0.6840285424833722, total=  42.0s\n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8, score=0.6849535303704356, total=  45.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85 \n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7, score=0.6834999779764789, total=  45.9s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85, score=0.6834339074131172, total=  53.4s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85, score=0.6849094833281945, total=  54.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85, score=0.6871999295247324, total=  57.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8, score=0.6840285424833722, total=  53.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8, score=0.6881909879751574, total=  53.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8, score=0.6860987534687045, total=  57.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7, score=0.6831916486807911, total=  57.1s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7, score=0.6876844469893847, total=  59.6s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7, score=0.6843148482579395, total=  56.9s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85, score=0.6845791305113862, total= 1.1min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85, score=0.6884332467074836, total= 1.1min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85, score=0.6860987534687045, total= 1.0min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8, score=0.6844029423424217, total= 1.0min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8, score=0.6885213407919658, total=  59.9s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8, score=0.6857023300885345, total=  58.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7, score=0.6830374840329472, total= 1.0min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85, score=0.6796899088226226, total=  42.7s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7, score=0.6878826586794696, total= 1.0min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7, score=0.6864511298066335, total= 1.0min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85, score=0.6838083072721667, total=  39.1s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85, score=0.6814517905122671, total=  41.2s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8, score=0.6780381447385808, total=  43.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8, score=0.6829273664273444, total=  38.4s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8, score=0.6811434612165793, total=  36.2s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7, score=0.6789631326256442, total=  34.9s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7, score=0.682200590230366, total=  36.4s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7, score=0.6787869444566798, total=  36.2s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85, score=0.6803726379773598, total=  54.7s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85, score=0.6862529181165484, total=  50.7s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85, score=0.6833678368497555, total=  51.9s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8, score=0.6791833678368497, total=  49.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8, score=0.6848654362859534, total=  47.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8, score=0.6822666607937277, total=  46.4s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7, score=0.6822886843148482, total=  41.2s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7, score=0.684292824736819, total=  40.4s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7, score=0.6821785667092455, total=  40.7s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85, score=0.6822226137514866, total=  54.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85, score=0.686274941637669, total=  54.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85, score=0.6858344712152579, total=  53.6s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8, score=0.6822886843148482, total=  54.6s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8, score=0.6894463286790292, total=  54.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8, score=0.6865172003699952, total=  55.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7, score=0.6827732017795005, total=  49.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85, score=0.6554420120688895, total=   9.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85, score=0.6554420120688895, total=   9.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85, score=0.6554420120688895, total=   7.6s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8, score=0.6554420120688895, total=   7.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8, score=0.6554420120688895, total=   7.4s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8, score=0.6554420120688895, total=   7.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7, score=0.6855481654406906, total=  50.6s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7, score=0.6554420120688895, total=   8.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7, score=0.6554420120688895, total=   8.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7, score=0.6554420120688895, total=   8.6s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85, score=0.6554420120688895, total=   8.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85, score=0.6554420120688895, total=   8.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 12.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7, score=0.6832136722019116, total=  50.1s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85, score=0.6554420120688895, total=   8.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8, score=0.6554420120688895, total=   9.4s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8, score=0.6554420120688895, total=   9.2s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8, score=0.6554420120688895, total=   9.2s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7, score=0.6554420120688895, total=   9.7s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7, score=0.6554420120688895, total=   9.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7, score=0.6554420120688895, total=   9.1s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85, score=0.6554420120688895, total=   9.9s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85, score=0.6554420120688895, total=   9.6s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85, score=0.6554420120688895, total=   9.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8, score=0.6554420120688895, total=   9.6s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8, score=0.6554420120688895, total=   9.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8, score=0.6554420120688895, total=   9.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7, score=0.6554420120688895, total=  10.0s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7, score=0.6554420120688895, total=  10.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7, score=0.6554420120688895, total=   9.5s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85, score=0.6822226137514866, total=  41.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85, score=0.6840065189622517, total=  41.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85, score=0.6854160243139673, total=  46.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8, score=0.6808351319208915, total=  45.3s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8, score=0.6857023300885345, total=  41.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7, score=0.6824428489626921, total=  37.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8, score=0.6843588953001806, total=  43.3s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7, score=0.6867594591023213, total=  41.1s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7, score=0.6832136722019116, total=  41.3s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85, score=0.6828392723428621, total=  47.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85, score=0.6863410122010307, total=  48.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85, score=0.6844029423424217, total=  50.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8, score=0.682597013610536, total=  48.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8, score=0.6870677883980091, total=  48.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8, score=0.6858124476941373, total=  50.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7, score=0.6821124961458838, total=  46.2s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7, score=0.6870457648768885, total=  43.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7, score=0.6853279302294851, total=  44.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85, score=0.6838743778355283, total=  57.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85, score=0.688807646566533, total=  59.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85, score=0.6848654362859534, total=  56.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8, score=0.6839844954411312, total=  56.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8, score=0.6875743293837818, total=  56.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8, score=0.6855922124829318, total=  54.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7, score=0.6846452010747478, total=  52.0s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7, score=0.6880808703695547, total=  51.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85, score=0.6801303792450337, total=  37.2s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7, score=0.6857463771307757, total=  53.3s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85, score=0.6843588953001806, total=  35.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85, score=0.6828833193851033, total=  36.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8, score=0.6784345681187508, total=  38.3s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8, score=0.6833898603708761, total=  36.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8, score=0.6810553671320971, total=  35.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7, score=0.6779940976963397, total=  33.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7, score=0.6838743778355283, total=  33.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7, score=0.6818261903713165, total=  35.0s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85, score=0.6793155089635731, total=  43.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85, score=0.6847332951592301, total=  42.5s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85, score=0.6811654847376999, total=  45.1s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8, score=0.6823327313570894, total=  44.5s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8, score=0.6853059067083646, total=  44.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8, score=0.6832577192441528, total=  43.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7, score=0.6798660969915871, total=  39.2s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7, score=0.6854160243139673, total=  40.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7, score=0.6830815310751883, total=  37.5s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85, score=0.682002378540281, total=  48.2s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85, score=0.6869576707924063, total=  53.0s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85, score=0.6846672245958684, total=  51.3s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8, score=0.6826630841738978, total=  46.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8, score=0.6875302823415408, total=  49.0s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8, score=0.6831696251596705, total=  48.5s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85, score=0.6554420120688895, total=   7.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7, score=0.6817380962868343, total=  48.1s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7, score=0.6866493414967185, total=  43.5s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85, score=0.6554420120688895, total=   8.1s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85, score=0.6554420120688895, total=   8.2s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8, score=0.6554420120688895, total=   7.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8, score=0.6554420120688895, total=   8.3s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8, score=0.6554420120688895, total=   7.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7, score=0.6554420120688895, total=   8.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7, score=0.6554420120688895, total=   8.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7, score=0.6822446372726071, total=  43.2s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7, score=0.6554420120688895, total=   8.2s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85, score=0.6554420120688895, total=   8.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85, score=0.6554420120688895, total=   9.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85, score=0.6554420120688895, total=   9.2s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8, score=0.6554420120688895, total=   8.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8, score=0.6554420120688895, total=   9.2s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8, score=0.6554420120688895, total=   8.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7, score=0.6554420120688895, total=   9.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7, score=0.6554420120688895, total=   9.5s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7, score=0.6554420120688895, total=   9.0s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85, score=0.6554420120688895, total=  10.0s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 24.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85, score=0.6554420120688895, total=  10.1s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85, score=0.6554420120688895, total=   9.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8, score=0.6554420120688895, total=  10.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8, score=0.6554420120688895, total=  10.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8, score=0.6554420120688895, total=  11.5s\n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7, score=0.6554420120688895, total=  10.6s\n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7, score=0.6554420120688895, total=   8.6s\n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7, score=0.6554420120688895, total=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed: 24.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [100, 120, 140], 'max_features': ['sqrt'], 'subsample': [0.85, 0.8, 0.7], 'min_samples_leaf': [1, 0.05, 0.5], 'loss': ['deviance', 'exponential']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'deviance',\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 140,\n",
       " 'subsample': 0.85}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as I said in the documentation, GridSeach uses a stratified 3-fold cross validation because a Classifier was passed\n",
    "# instead of a recgressor\n",
    "\n",
    "xgboost_classifier.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score of the single XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = xgboost_classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_train_pred = classifier.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = classifier.predict(X_test.as_matrix()).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XXpon-XGf7X9",
    "outputId": "e3724372-f7c7-42b7-ab07-db29750a1d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier.predict_proba(X_test.as_matrix())[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HC--sBLtf7YC",
    "outputId": "5633e246-2e20-4b4a-ee44-0dd2056dc0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6856\n",
      "Recall:           0.9121\n",
      "Precision:        0.7002\n",
      "F1:               0.7922\n",
      "AUROC:            0.6971\n",
      "AUPR:             0.8065\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble classifiers (Voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest and XGBoost together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I get the best estimator of a previous chosen xgboost classifier\n",
    "classifier = VotingClassifier([('xgboost', xgboost_classifier.best_estimator_), ('randomforest', rf_classifier.best_estimator_)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgboost', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_l...imators=50, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgboost', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_l...imators=50, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnMarR8Cf7Xx"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "1PYMF-fcf7Xx"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_train_pred = classifier.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = classifier.predict(X_test.as_matrix()).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kB9rJAI6f7X1"
   },
   "source": [
    "é bom prestar atenção se os valores estão próximo, caso contrário, existe uma boa indicação de que houve\n",
    "overfitting e o modelo não consegue generalizar tão bem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7BtRFR1Uf7X3",
    "outputId": "4371cb58-7193-4487-fc91-e5685127acf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square error in train: 0.1\n",
      "Mean Square error in test: 0.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Square error in train: {:0.1f}\".format(mse(y_train, y_train_pred)))\n",
    "print(\"Mean Square error in test: {:0.1f}\".format(mse(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "5iRz5PRVf7X6"
   },
   "outputs": [],
   "source": [
    "def compute_performance_metrics(y, y_pred_class, y_pred_scores=None):\n",
    "    accuracy = accuracy_score(y, y_pred_class)\n",
    "    recall = recall_score(y, y_pred_class)\n",
    "    precision = precision_score(y, y_pred_class)\n",
    "    f1 = f1_score(y, y_pred_class)\n",
    "    performance_metrics = (accuracy, recall, precision, f1)\n",
    "    if y_pred_scores is not None:\n",
    "        auroc = roc_auc_score(y, y_pred_scores)\n",
    "        aupr = average_precision_score(y, y_pred_scores)\n",
    "        performance_metrics = performance_metrics + (auroc, aupr)\n",
    "    return performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "X4UtgNY5f7X6"
   },
   "outputs": [],
   "source": [
    "def print_metrics_summary(accuracy, recall, precision, f1, auroc=None, aupr=None):\n",
    "    print()\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Accuracy:\", value=accuracy))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Recall:\", value=recall))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Precision:\", value=precision))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"F1:\", value=f1))\n",
    "    if auroc is not None:\n",
    "        print(\"{metric:<18}{value:.4f}\".format(metric=\"AUROC:\", value=auroc))\n",
    "    if aupr is not None:\n",
    "        print(\"{metric:<18}{value:.4f}\".format(metric=\"AUPR:\", value=aupr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XXpon-XGf7X9",
    "outputId": "e3724372-f7c7-42b7-ab07-db29750a1d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier.predict_proba(X_test.as_matrix())[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29190,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29190,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29190,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HC--sBLtf7YC",
    "outputId": "5633e246-2e20-4b4a-ee44-0dd2056dc0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6844\n",
      "Recall:           0.9165\n",
      "Precision:        0.6974\n",
      "F1:               0.7921\n",
      "AUROC:            0.7012\n",
      "AUPR:             0.8113\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WTW9B1nRf7YG"
   },
   "source": [
    "# Evaluate for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "lyBq2QWyf7YH"
   },
   "outputs": [],
   "source": [
    "kaggle_test_data = pandas.read_csv(\"real_test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eGiaJwKzf7YJ",
    "outputId": "eff32b6b-7971-43cd-cc05-49562d3d62e6"
   },
   "outputs": [],
   "source": [
    "kaggle_test_data.shape\n",
    "features_kaggle = kaggle_test_data.drop([\"id\"], axis=1)\n",
    "features_kaggle.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ibft8n9Ef7YN"
   },
   "outputs": [],
   "source": [
    "rf_pred_test_class = rf_clf.predict(features_kaggle)\n",
    "rf_pred_test_scores = rf_clf.predict_proba(features_kaggle)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xtuergdcf7YP",
    "outputId": "171f3cf1-2878-4283-a784-de001c38ac10"
   },
   "outputs": [],
   "source": [
    "rf_pred_test_class.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PiHOmQg9f7YS",
    "outputId": "545442e3-9b36-4123-a8f8-730cda6a24fa"
   },
   "outputs": [],
   "source": [
    "rf_pred_test_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yBEXHwduf7YX"
   },
   "source": [
    "Se ligar que na hora que cria o csv, na primeira linha (a linha do header), ele coloca \",0\", tem que substituir para \"id,IND_BOM_1_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "NOE4SMRxf7YY"
   },
   "outputs": [],
   "source": [
    "df = pandas.DataFrame(data=rf_pred_test_class)\n",
    "df.to_csv('test.csv', mode='a', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "jruxoZPlf7Ye"
   },
   "outputs": [],
   "source": [
    "# For in ensemble classifiers\n",
    "classifier = xgboost_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS LOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost - 120 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HC--sBLtf7YC",
    "outputId": "5633e246-2e20-4b4a-ee44-0dd2056dc0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6607\n",
      "Recall:           0.9790\n",
      "Precision:        0.6636\n",
      "F1:               0.7910\n",
      "AUROC:            0.6295\n",
      "AUPR:             0.7507\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6607\n",
      "Recall:           0.9790\n",
      "Precision:        0.6636\n",
      "F1:               0.7910\n",
      "AUROC:            0.6295\n",
      "AUPR:             0.7507\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost - 2nd configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "number_estimators = [30, 60, 120, 200]\n",
    "loss_function = [\"deviance\", \"exponential\"]\n",
    "min_samples_leaf = [1, 0.05]\n",
    "sub_samples = [1.0, 0.8, 0.6]\n",
    "max_features = [\"log2\", \"sqrt\", \"auto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'deviance',\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 0.05,\n",
       " 'n_estimators': 200,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6878\n",
      "Recall:           0.9007\n",
      "Precision:        0.7052\n",
      "F1:               0.7910\n",
      "AUROC:            0.7065\n",
      "AUPR:             0.8131\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Of XBGoost and RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Tuning of the random forest parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgboost', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_l...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6766\n",
      "Recall:           0.8842\n",
      "Precision:        0.7010\n",
      "F1:               0.7820\n",
      "AUROC:            0.6773\n",
      "AUPR:             0.7933\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'deviance',\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 120,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as I said in the documentation, GridSeach uses a stratified 3-fold cross validation because a Classifier was passed\n",
    "# instead of a recgressor\n",
    "\n",
    "xgboost_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': {0: 1, 1: 1},\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 20}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HC--sBLtf7YC",
    "outputId": "5633e246-2e20-4b4a-ee44-0dd2056dc0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6829\n",
      "Recall:           0.9383\n",
      "Precision:        0.6899\n",
      "F1:               0.7952\n",
      "AUROC:            0.7052\n",
      "AUPR:             0.8132\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPs and Ensemble MLPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6664\n",
      "Recall:           0.8560\n",
      "Precision:        0.7013\n",
      "F1:               0.7710\n",
      "AUROC:            0.6650\n",
      "AUPR:             0.7853\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = classifier_1.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = classifier_1.predict(X_test.as_matrix()).ravel()\n",
    "\n",
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier_1.predict_proba(X_test.as_matrix())[:, 0]\n",
    "\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6660\n",
      "Recall:           0.8400\n",
      "Precision:        0.7064\n",
      "F1:               0.7674\n",
      "AUROC:            0.6698\n",
      "AUPR:             0.7878\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = classifier_2.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = classifier_2.predict(X_test.as_matrix()).ravel()\n",
    "\n",
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier_2.predict_proba(X_test.as_matrix())[:, 0]\n",
    "\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6684\n",
      "Recall:           0.8315\n",
      "Precision:        0.7116\n",
      "F1:               0.7669\n",
      "AUROC:            0.6739\n",
      "AUPR:             0.7916\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = classifier_3.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = classifier_3.predict(X_test.as_matrix()).ravel()\n",
    "\n",
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier_3.predict_proba(X_test.as_matrix())[:, 0]\n",
    "\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6493\n",
      "Recall:           0.7997\n",
      "Precision:        0.7051\n",
      "F1:               0.7495\n",
      "AUROC:            0.6650\n",
      "AUPR:             0.7853\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = voting_classifier.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = voting_classifier.predict(X_test.as_matrix()).ravel()\n",
    "\n",
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier_1.predict_proba(X_test.as_matrix())[:, 0]\n",
    "\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking RF and XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify data based on RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_train_pred = rf_classifier.best_estimator_.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = rf_classifier.best_estimator_.predict(X_test.as_matrix()).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XXpon-XGf7X9",
    "outputId": "e3724372-f7c7-42b7-ab07-db29750a1d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = rf_classifier.predict_proba(X_test.drop(\"rf_feature\", axis=1).as_matrix())[:, 1]\n",
    "y_train_pred_prob = rf_classifier.predict_proba(X_train.drop(\"rf_feature\", axis=1).as_matrix())[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# add random forest prediction as feature\n",
    "X_train[\"rf_feature\"] = y_train_pred_prob \n",
    "X_test[\"rf_feature\"] = y_test_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XXpon-XGf7X9",
    "outputId": "e3724372-f7c7-42b7-ab07-db29750a1d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier.predict_proba(X_test.as_matrix())[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add XGBoost to read from new X_train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'deviance',\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 140,\n",
       " 'subsample': 0.85}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_classifier = GradientBoostingClassifier(n_estimators=140, subsample=0.85, max_features=\"sqrt\", min_samples_leaf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=140,\n",
       "              presort='auto', random_state=None, subsample=0.85, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_train_pred = xgboost_classifier.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = xgboost_classifier.predict(X_test.as_matrix()).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XXpon-XGf7X9",
    "outputId": "e3724372-f7c7-42b7-ab07-db29750a1d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = xgboost_classifier.predict_proba(X_test.as_matrix())[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6670\n",
      "Recall:           0.8012\n",
      "Precision:        0.7224\n",
      "F1:               0.7598\n",
      "AUROC:            0.6742\n",
      "AUPR:             0.7823\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.12871287128712872, pvalue=0.34994207557716706)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "position = 0\n",
    "class_0 = 0\n",
    "class_1 = 0\n",
    "counting_class_0 = [0] * 101\n",
    "counting_class_1 = [0] * 101\n",
    "grouped_counting_class_0 = [0] * 101\n",
    "grouped_counting_class_1 = [0] * 101\n",
    "percentage_counting_class_0 = [0.0] * 101\n",
    "percentage_counting_class_1 = [0.0] * 101\n",
    "\n",
    "for x in y_test:\n",
    "    score = math.floor(y_test_pred_prob[position]*100)\n",
    "    if x == 0:\n",
    "        class_0 += 1\n",
    "        counting_class_0[score] += 1\n",
    "    else:\n",
    "        class_1 += 1\n",
    "        counting_class_1[score] += 1\n",
    "    position += 1\n",
    "\n",
    "last_value_class_0 = 0\n",
    "last_value_class_1 = 0\n",
    "\n",
    "for x in range(0, 101):\n",
    "    last_value_class_0 += counting_class_0[x]\n",
    "    grouped_counting_class_0[x] = last_value_class_0\n",
    "    percentage_counting_class_0[x] = last_value_class_0/class_0\n",
    "    \n",
    "    last_value_class_1 += counting_class_1[x]\n",
    "    grouped_counting_class_1[x] = last_value_class_1\n",
    "    percentage_counting_class_1[x] = last_value_class_1/class_1\n",
    "\n",
    "#stats.ks_2samp(percentage_counting_class_0, percentage_counting_class_1)\n",
    "stats.ks_2samp(grouped_counting_class_0, grouped_counting_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Kaggle_Submission.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
