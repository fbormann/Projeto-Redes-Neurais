{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ftFvfpxnf7U7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas\n",
    "import sklearn\n",
    "import scipy\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier, BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RK7tQhKHf7VN"
   },
   "outputs": [],
   "source": [
    "original_training_data = pandas.read_csv(\"train_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "o07Q4SALf7VQ"
   },
   "outputs": [],
   "source": [
    "training_sample = original_training_data.sample(frac=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "TIx6bw-af7VX"
   },
   "outputs": [],
   "source": [
    "training_sample.to_csv(\"train_data_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Training and Test samples from the training data we have available, so all models access the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389196, 246)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.350979e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.735041e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.819095e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.257406e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.804034e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.193229e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.734882e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.343982e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.474494e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.506237e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7         IDADE  SEXO_1  \\\n",
       "0   0     1     1     1     0     0     0     0  1.350979e-01       1   \n",
       "1   1     1     0     1     0     0     1     0  2.735041e-01       1   \n",
       "2   2     1     0     1     0     0     1     0  2.819095e-01       0   \n",
       "3   3     1     1     1     0     0     0     0  2.257406e-01       0   \n",
       "4   4     1     1     0     0     0     1     0  4.804034e-01       0   \n",
       "5   5     0     1     1     0     0     0     1  2.193229e-01       0   \n",
       "6   6     1     1     1     0     0     0     0  5.734882e-01       0   \n",
       "7   7     0     1     0     0     1     0     1  8.343982e-01       1   \n",
       "8   8     1     1     0     1     0     0     0  3.474494e-01       1   \n",
       "9   9     1     1     1     0     0     0     0  5.506237e-16       1   \n",
       "\n",
       "      ...       CEP4_7  CEP4_8  CEP4_9  CEP4_10  CEP4_11  CEP4_12  CEP4_13  \\\n",
       "0     ...            0       0       1        1        0        1        1   \n",
       "1     ...            0       1       0        1        1        0        0   \n",
       "2     ...            1       1       0        0        0        0        1   \n",
       "3     ...            1       1       0        1        1        0        1   \n",
       "4     ...            1       1       1        0        0        1        0   \n",
       "5     ...            0       1       1        0        1        0        0   \n",
       "6     ...            0       0       0        1        1        0        0   \n",
       "7     ...            0       1       0        0        0        1        1   \n",
       "8     ...            1       0       0        0        1        0        1   \n",
       "9     ...            1       1       0        0        0        1        0   \n",
       "\n",
       "   CEP4_14  IND_BOM_1_1  IND_BOM_1_2  \n",
       "0        1            0            1  \n",
       "1        0            1            0  \n",
       "2        0            1            0  \n",
       "3        0            1            0  \n",
       "4        1            1            0  \n",
       "5        1            1            0  \n",
       "6        0            1            0  \n",
       "7        1            1            0  \n",
       "8        1            1            0  \n",
       "9        0            1            0  \n",
       "\n",
       "[10 rows x 246 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_training_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop one of the the label columns\n",
    "original_training_data.drop([\"IND_BOM_1_2\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(original_training_data.drop(\"IND_BOM_1_1\", axis=1), original_training_data[\"IND_BOM_1_1\"],test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pandas.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260761, 245)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.drop(\"id\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260761, 244)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write common training sample to dataset\n",
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.to_csv(\"training_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pandas.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_6</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80781</th>\n",
       "      <td>80781</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.453938</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96217</th>\n",
       "      <td>96217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.322631</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145553</th>\n",
       "      <td>145553</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.733192</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246883</th>\n",
       "      <td>246883</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388795</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192908</th>\n",
       "      <td>192908</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.711497</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70399</th>\n",
       "      <td>70399</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561959</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148944</th>\n",
       "      <td>148944</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375278</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68658</th>\n",
       "      <td>68658</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259987</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187123</th>\n",
       "      <td>187123</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013503</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235113</th>\n",
       "      <td>235113</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661348</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "80781    80781     1     0     1     1     0     0     0  0.453938       1   \n",
       "96217    96217     0     0     1     1     1     0     0  0.322631       1   \n",
       "145553  145553     1     1     1     0     0     0     0  0.733192       1   \n",
       "246883  246883     1     0     0     1     1     0     0  0.388795       1   \n",
       "192908  192908     1     1     0     0     1     0     0  0.711497       1   \n",
       "70399    70399     1     0     0     0     1     1     0  0.561959       1   \n",
       "148944  148944     1     0     1     0     1     0     0  0.375278       1   \n",
       "68658    68658     1     0     1     0     0     1     0  0.259987       1   \n",
       "187123  187123     1     1     1     0     0     0     0  0.013503       1   \n",
       "235113  235113     1     0     1     0     1     0     0  0.661348       1   \n",
       "\n",
       "           ...       CEP4_6  CEP4_7  CEP4_8  CEP4_9  CEP4_10  CEP4_11  \\\n",
       "80781      ...            0       1       0       0        1        1   \n",
       "96217      ...            0       0       0       0        1        0   \n",
       "145553     ...            0       1       1       0        0        0   \n",
       "246883     ...            1       1       0       1        0        0   \n",
       "192908     ...            0       1       1       0        0        1   \n",
       "70399      ...            1       0       1       1        0        0   \n",
       "148944     ...            0       1       1       1        1        1   \n",
       "68658      ...            0       0       0       1        0        1   \n",
       "187123     ...            1       0       0       1        0        1   \n",
       "235113     ...            0       1       0       0        0        1   \n",
       "\n",
       "        CEP4_12  CEP4_13  CEP4_14  IND_BOM_1_1  \n",
       "80781         1        0        1            1  \n",
       "96217         1        0        1            1  \n",
       "145553        0        1        0            1  \n",
       "246883        1        1        0            0  \n",
       "192908        0        1        1            0  \n",
       "70399         0        1        1            1  \n",
       "148944        0        0        0            1  \n",
       "68658         1        0        0            1  \n",
       "187123        0        0        0            1  \n",
       "235113        0        0        0            1  \n",
       "\n",
       "[10 rows x 245 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop id column because the index has the same values\n",
    "test.drop(\"id\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128435, 244)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"test_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FdcCmdK2f7Va"
   },
   "source": [
    "# read sample if already available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pandas.read_csv(\"training_sample.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pandas.read_csv(\"test_sample.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_test_data = pandas.read_table(\"data/TST.cod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_x_test = kaggle_test_data.drop([\"INDEX\", \"IND_BOM_1_2\", \"IND_BOM_1_1\"], axis=1)\n",
    "kaggle_y_test = kaggle_test_data[\"IND_BOM_1_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129733, 246)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.898745</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.847404</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016513</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688950</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230114</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433833</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339328</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170480</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.676625</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229319</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   INDEX  UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "0      0     1     1     1     0     0     0     0  0.898745       1   \n",
       "1      1     1     1     0     1     0     0     0  0.847404       1   \n",
       "2      2     1     1     0     0     0     0     1  0.016513       0   \n",
       "3      3     1     1     0     1     0     0     0  0.688950       0   \n",
       "4      4     0     1     1     0     0     1     0  0.230114       1   \n",
       "5      5     1     0     0     1     1     0     0  0.433833       1   \n",
       "6      6     0     1     1     1     0     0     0  0.339328       1   \n",
       "7      7     1     1     0     0     1     0     0  0.170480       0   \n",
       "8      8     1     1     0     0     1     0     0  0.676625       1   \n",
       "9      9     1     1     0     0     0     1     0  0.229319       1   \n",
       "\n",
       "      ...       CEP4_7  CEP4_8  CEP4_9  CEP4_10  CEP4_11  CEP4_12  CEP4_13  \\\n",
       "0     ...            0       1       1        1        0        0        0   \n",
       "1     ...            0       0       0        1        1        1        0   \n",
       "2     ...            0       1       0        0        1        0        0   \n",
       "3     ...            0       0       0        0        0        1        0   \n",
       "4     ...            0       1       0        0        1        0        1   \n",
       "5     ...            1       1       0        0        0        0        1   \n",
       "6     ...            0       0       0        1        0        0        1   \n",
       "7     ...            0       1       0        0        0        1        0   \n",
       "8     ...            1       0       0        1        1        0        1   \n",
       "9     ...            0       0       0        1        1        0        0   \n",
       "\n",
       "   CEP4_14  IND_BOM_1_1  IND_BOM_1_2  \n",
       "0        0            1            0  \n",
       "1        0            1            0  \n",
       "2        1            0            1  \n",
       "3        1            1            0  \n",
       "4        0            1            0  \n",
       "5        0            1            0  \n",
       "6        0            0            1  \n",
       "7        1            1            0  \n",
       "8        0            1            0  \n",
       "9        0            0            1  \n",
       "\n",
       "[10 rows x 246 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2Ly7xloIf7Ve",
    "outputId": "7a5edec3-61ed-406f-f2a5-a7372d380aa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UF_1', 'UF_2', 'UF_3', 'UF_4', 'UF_5', 'UF_6', 'UF_7', 'IDADE',\n",
       "       'SEXO_1', 'NIVEL_RELACIONAMENTO_CREDITO01',\n",
       "       ...\n",
       "       'CEP4_6', 'CEP4_7', 'CEP4_8', 'CEP4_9', 'CEP4_10', 'CEP4_11', 'CEP4_12',\n",
       "       'CEP4_13', 'CEP4_14', 'IND_BOM_1_1'],\n",
       "      dtype='object', length=244)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "6C0sx7Tif7Vj"
   },
   "outputs": [],
   "source": [
    "features = training_data.drop([\"IND_BOM_1_1\", \"IND_BOM_1_2\", \"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4udGl4tKf7Vm",
    "outputId": "b929b576-1e63-4a12-df67-d74fb554f238"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_5</th>\n",
       "      <th>CEP4_6</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533846</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604895</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571103</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625795</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107837</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.566673</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174853</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394475</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310590</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "0     1     0     1     1     0     0     0  0.533846       0   \n",
       "1     1     1     0     0     0     1     0  0.604895       1   \n",
       "2     1     0     1     1     0     0     0  0.571103       1   \n",
       "3     1     0     1     0     0     0     1  0.625795       0   \n",
       "4     0     1     1     0     0     1     0  0.272198       0   \n",
       "5     1     1     0     0     0     0     1  0.107837       1   \n",
       "6     1     0     0     1     1     0     0  0.566673       1   \n",
       "7     1     1     0     1     0     0     0  0.174853       1   \n",
       "8     1     1     0     0     0     1     0  0.394475       0   \n",
       "9     0     1     1     0     1     0     0  0.310590       0   \n",
       "\n",
       "   NIVEL_RELACIONAMENTO_CREDITO01   ...     CEP4_5  CEP4_6  CEP4_7  CEP4_8  \\\n",
       "0                        0.111111   ...          1       0       0       0   \n",
       "1                        0.000000   ...          1       0       0       1   \n",
       "2                        0.111111   ...          1       1       0       1   \n",
       "3                        0.111111   ...          0       1       0       1   \n",
       "4                        0.111111   ...          0       0       0       0   \n",
       "5                        0.111111   ...          1       0       0       0   \n",
       "6                        0.111111   ...          1       1       1       1   \n",
       "7                        0.111111   ...          1       1       1       1   \n",
       "8                        0.111111   ...          1       0       1       1   \n",
       "9                        0.111111   ...          1       0       1       0   \n",
       "\n",
       "   CEP4_9  CEP4_10  CEP4_11  CEP4_12  CEP4_13  CEP4_14  \n",
       "0       0        1        1        0        1        0  \n",
       "1       1        1        1        0        0        0  \n",
       "2       0        0        1        0        1        0  \n",
       "3       0        1        0        0        1        0  \n",
       "4       0        1        1        0        0        1  \n",
       "5       0        0        0        1        0        1  \n",
       "6       1        1        0        0        0        0  \n",
       "7       1        0        0        0        0        0  \n",
       "8       0        1        0        0        1        0  \n",
       "9       0        0        0        0        0        1  \n",
       "\n",
       "[10 rows x 243 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "z-XYnde-f7Vs"
   },
   "outputs": [],
   "source": [
    "labels = training_data[\"IND_BOM_1_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PUAV5GkMf7Vv"
   },
   "source": [
    "Vou tentar reduzir a dimensionalidade do dataframe utilizando LDA para poder analisar \n",
    "melhor um subconjunto de variáveis e mensurar a acurácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYDQV9idf7V8"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "c1WYqc8Gf7V-",
    "outputId": "34c86b31-11e0-43b6-d51d-1add48cb3406"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    144\n",
       "int64      102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQM5hPKMf7WB"
   },
   "source": [
    "Pandas leu muito dos valores de forma errada, gerando até problemas para o uso de memória, existem formas\n",
    "melhores de representar estas variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sfF7azoAf7WC",
    "outputId": "44ffb9d7-50ce-4293-97eb-391a90ad70b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'UF_1', 'UF_2', 'UF_3', 'UF_4', 'UF_5', 'UF_6', 'UF_7', 'IDADE',\n",
       "       'SEXO_1',\n",
       "       ...\n",
       "       'CEP4_7', 'CEP4_8', 'CEP4_9', 'CEP4_10', 'CEP4_11', 'CEP4_12',\n",
       "       'CEP4_13', 'CEP4_14', 'IND_BOM_1_1', 'IND_BOM_1_2'],\n",
       "      dtype='object', length=246)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "VOz6CYXCf7WJ"
   },
   "outputs": [],
   "source": [
    "category_columns = [\"UF_1\", \"UF_2\", \"UF_3\", \"UF_4\", \"UF_5\", \"UF_6\", \"UF_7\",\n",
    "                   \"BANCO_REST_IRPF_ULTIMA_1\", \"BANCO_REST_IRPF_ULTIMA_2\", \"BANCO_REST_IRPF_ULTIMA_3\",\n",
    "                   \"BANCO_REST_IRPF_ULTIMA_4\", \"BANCO_REST_IRPF_ULTIMA_5\", \"BANCO_REST_IRPF_ULTIMA_6\",\n",
    "                   \"BANCO_REST_IRPF_ULTIMA_7\", \"FLAG_BOLSA_FAMILIA_1\", \"SIGLA_PARTIDO_FILIADO_1\",\n",
    "                   \"SIGLA_PARTIDO_FILIADO_2\", \"SIGLA_PARTIDO_FILIADO_3\", \"SIGLA_PARTIDO_FILIADO_4\",\n",
    "                   \"SIGLA_PARTIDO_FILIADO_5\", \"SIGLA_PARTIDO_FILIADO_6\", \"SIGLA_PARTIDO_FILIADO_7\",\n",
    "                   \"FLAG_FILIADO_PARTIDO_POLITICO_1\", \"FLAG_PROUNI_1\", \"RENDA_VIZINHANCA_1\", \n",
    "                   \"RENDA_VIZINHANCA_2\", \"RENDA_VIZINHANCA_3\", \"RENDA_VIZINHANCA_4\", \n",
    "                    \"COMPARATIVO_RENDA_CEP_1\", \"COMPARATIVO_RENDA_CEP_2\", \"COMPARATIVO_RENDA_CEP_3\",\n",
    "                   \"COMPARATIVO_RENDA_CEP_4\", \"COMPARATIVO_RENDA_CEP_5\", \"CLASSE_SOCIAL_CONSUMIDOR_1\",\n",
    "                   \"CLASSE_SOCIAL_CONSUMIDOR_2\", \"CLASSE_SOCIAL_CONSUMIDOR_3\", \"CLASSE_SOCIAL_CONSUMIDOR_4\",\n",
    "                   \"FLAG_REDE_SOCIAL_1\", \"FLAG_REDE_SOCIAL_2\", \"FLAG_REDE_SOCIAL_3\",\n",
    "                   \"CEP1_1\", \"CEP1_2\", \"CEP1_3\", \"CEP1_4\", \"CEP1_5\", \"CEP2_1\", \"CEP2_2\", \"CEP2_3\", \"CEP2_4\",\n",
    "                   \"CEP2_5\", \"CEP2_6\", \"CEP2_7\", \"CEP2_8\", \"CEP2_9\", \"CEP3_1\", \"CEP3_2\", \"CEP3_3\", \"CEP3_4\",\n",
    "                   \"CEP3_5\", \"CEP3_6\", \"CEP3_7\", \"CEP3_8\", \"CEP3_9\", \"CEP3_10\", \"CEP3_11\", \"CEP3_12\",\n",
    "                   \"CEP4_1\", \"CEP4_2\", \"CEP4_3\", \"CEP4_4\", \"CEP4_5\", \"CEP4_6\", \"CEP4_7\", \"CEP4_8\", \"CEP4_9\",\n",
    "                   \"CEP4_10\", \"CEP4_11\", \"CEP4_12\", \"CEP4_13\", \"CEP4_14\"]\n",
    "\n",
    "ordered_category_columns = [\"NIVEL_RELACIONAMENTO_CREDITO02\", \"EXPOSICAO_CONSUMIDOR_EMAILS\", \n",
    "                            \"EXPOSICAO_CONSUMIDOR_TELEFONES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Rne2Z-82f7WL",
    "outputId": "221c332b-b531-4c10-e309-23245f2fcf3f"
   },
   "outputs": [],
   "source": [
    "for column in training_data.columns:\n",
    "    print(column)\n",
    "    values = training_data[column].value_counts()\n",
    "    if type(values) == list:\n",
    "        print(values[:10])\n",
    "    else:\n",
    "        print(values.head(10))\n",
    "    print(len(values))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "M1Eay13Kf7WN"
   },
   "outputs": [],
   "source": [
    "for column in category_columns:\n",
    "    training_data[column] = training_data[column].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "o6KVdoYNf7WR",
    "outputId": "0e997d3b-17f3-498a-f057-32538b7434b4"
   },
   "outputs": [],
   "source": [
    "training_data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dPNgFMCRf7WU",
    "outputId": "80579775-f6b3-4a70-a140-25b6be1f267c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEXO_1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19330</td>\n",
       "      <td>36823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20837</td>\n",
       "      <td>39769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "IND_BOM_1_1      0      1\n",
       "SEXO_1                   \n",
       "0            19330  36823\n",
       "1            20837  39769"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confunsion_matrix = pandas.crosstab(training_data[\"SEXO_1\"], training_data[\"IND_BOM_1_1\"])\n",
    "confunsion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "F_wc44luf7WX",
    "outputId": "8f948f8f-ea80-42ea-923e-f5a79ea8e8c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=array([  56.54016979,  113.31360978]), pvalue=array([  5.50619646e-14,   1.84208521e-26]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "chisquare(confunsion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HE8lepFEf7Wa"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tvOkSKebf7Wb",
    "outputId": "c70f39c8-fe00-49f1-ef67-235eea0792e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_5</th>\n",
       "      <th>CEP4_6</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UF_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209093</td>\n",
       "      <td>0.048255</td>\n",
       "      <td>0.146628</td>\n",
       "      <td>0.118488</td>\n",
       "      <td>0.100570</td>\n",
       "      <td>0.087990</td>\n",
       "      <td>0.019386</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.017901</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.041249</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>0.022239</td>\n",
       "      <td>0.035315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UF_2</th>\n",
       "      <td>0.209093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>0.247423</td>\n",
       "      <td>0.187327</td>\n",
       "      <td>0.171868</td>\n",
       "      <td>0.180898</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>0.014506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040997</td>\n",
       "      <td>0.006801</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.035769</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0.021424</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>0.029016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UF_3</th>\n",
       "      <td>0.048255</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.275167</td>\n",
       "      <td>0.269899</td>\n",
       "      <td>0.246315</td>\n",
       "      <td>0.216494</td>\n",
       "      <td>0.031256</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011452</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>0.062716</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>0.038354</td>\n",
       "      <td>0.017366</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>0.011395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UF_4</th>\n",
       "      <td>0.146628</td>\n",
       "      <td>0.247423</td>\n",
       "      <td>0.275167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.126074</td>\n",
       "      <td>0.126333</td>\n",
       "      <td>0.135131</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.041647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.021085</td>\n",
       "      <td>0.012738</td>\n",
       "      <td>0.019959</td>\n",
       "      <td>0.028406</td>\n",
       "      <td>0.010240</td>\n",
       "      <td>0.023383</td>\n",
       "      <td>0.047764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UF_5</th>\n",
       "      <td>0.118488</td>\n",
       "      <td>0.187327</td>\n",
       "      <td>0.269899</td>\n",
       "      <td>0.126074</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.156790</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.018759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.060533</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.026264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UF_6</th>\n",
       "      <td>0.100570</td>\n",
       "      <td>0.171868</td>\n",
       "      <td>0.246315</td>\n",
       "      <td>0.126333</td>\n",
       "      <td>0.156790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.137971</td>\n",
       "      <td>0.026368</td>\n",
       "      <td>0.017433</td>\n",
       "      <td>0.028672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.023013</td>\n",
       "      <td>0.067999</td>\n",
       "      <td>0.022139</td>\n",
       "      <td>0.029033</td>\n",
       "      <td>0.065947</td>\n",
       "      <td>0.025372</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.015740</td>\n",
       "      <td>0.003706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UF_7</th>\n",
       "      <td>0.087990</td>\n",
       "      <td>0.180898</td>\n",
       "      <td>0.216494</td>\n",
       "      <td>0.135131</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.137971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.022839</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044504</td>\n",
       "      <td>0.024435</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.017101</td>\n",
       "      <td>0.034493</td>\n",
       "      <td>0.003431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDADE</th>\n",
       "      <td>0.019386</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.031256</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>0.026368</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>0.029988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.008037</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.006353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEXO_1</th>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.017433</td>\n",
       "      <td>0.022839</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.003675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.014506</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.041647</td>\n",
       "      <td>0.018759</td>\n",
       "      <td>0.028672</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.029988</td>\n",
       "      <td>0.020646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.005085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO02</th>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.239705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.001580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANCO_REST_IRPF_ULTIMA_1</th>\n",
       "      <td>0.007550</td>\n",
       "      <td>0.048365</td>\n",
       "      <td>0.042261</td>\n",
       "      <td>0.036186</td>\n",
       "      <td>0.006520</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.028865</td>\n",
       "      <td>0.011831</td>\n",
       "      <td>0.041594</td>\n",
       "      <td>0.014328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012245</td>\n",
       "      <td>0.016455</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.011306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANCO_REST_IRPF_ULTIMA_2</th>\n",
       "      <td>0.027318</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.015587</td>\n",
       "      <td>0.012387</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.035525</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.012884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.009435</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.007759</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.012610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANCO_REST_IRPF_ULTIMA_3</th>\n",
       "      <td>0.031309</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.035204</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.009251</td>\n",
       "      <td>0.039252</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.022476</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011136</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.004504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANCO_REST_IRPF_ULTIMA_4</th>\n",
       "      <td>0.009614</td>\n",
       "      <td>0.011060</td>\n",
       "      <td>0.029721</td>\n",
       "      <td>0.024070</td>\n",
       "      <td>0.004330</td>\n",
       "      <td>0.012961</td>\n",
       "      <td>0.021763</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>0.031053</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.008856</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANCO_REST_IRPF_ULTIMA_5</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.009894</td>\n",
       "      <td>0.020938</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.013540</td>\n",
       "      <td>0.019192</td>\n",
       "      <td>0.009553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.004460</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.006276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANCO_REST_IRPF_ULTIMA_6</th>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.024210</td>\n",
       "      <td>0.031489</td>\n",
       "      <td>0.008058</td>\n",
       "      <td>0.008847</td>\n",
       "      <td>0.023075</td>\n",
       "      <td>0.017595</td>\n",
       "      <td>0.041111</td>\n",
       "      <td>0.015834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012357</td>\n",
       "      <td>0.015106</td>\n",
       "      <td>0.006938</td>\n",
       "      <td>0.006781</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.004426</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.012221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANCO_REST_IRPF_ULTIMA_7</th>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.048489</td>\n",
       "      <td>0.038199</td>\n",
       "      <td>0.031314</td>\n",
       "      <td>0.012052</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.017687</td>\n",
       "      <td>0.040374</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.014959</td>\n",
       "      <td>0.007677</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.011833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATIVIDADE_EMAIL</th>\n",
       "      <td>0.029827</td>\n",
       "      <td>0.102135</td>\n",
       "      <td>0.053917</td>\n",
       "      <td>0.079640</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.067921</td>\n",
       "      <td>0.058710</td>\n",
       "      <td>0.022313</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.015398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>0.017565</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXPOSICAO_ENDERECO</th>\n",
       "      <td>0.050144</td>\n",
       "      <td>0.068285</td>\n",
       "      <td>0.010087</td>\n",
       "      <td>0.071787</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.025830</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>0.037784</td>\n",
       "      <td>0.029683</td>\n",
       "      <td>0.043574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.019879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXPOSICAO_EMAIL</th>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.076136</td>\n",
       "      <td>0.038393</td>\n",
       "      <td>0.065260</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.041351</td>\n",
       "      <td>0.038661</td>\n",
       "      <td>0.036607</td>\n",
       "      <td>0.010047</td>\n",
       "      <td>0.013042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.016051</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.006326</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.007416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXPOSICAO_TELEFONE</th>\n",
       "      <td>0.036865</td>\n",
       "      <td>0.089696</td>\n",
       "      <td>0.040969</td>\n",
       "      <td>0.067006</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.053896</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>0.008596</td>\n",
       "      <td>0.029972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008441</td>\n",
       "      <td>0.012044</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.008774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATIVIDADE_ENDERECO</th>\n",
       "      <td>0.022894</td>\n",
       "      <td>0.053707</td>\n",
       "      <td>0.036434</td>\n",
       "      <td>0.033969</td>\n",
       "      <td>0.043457</td>\n",
       "      <td>0.020355</td>\n",
       "      <td>0.021810</td>\n",
       "      <td>0.053765</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.010995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.017025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATUALIZACAO_ENDERECO</th>\n",
       "      <td>0.079764</td>\n",
       "      <td>0.133604</td>\n",
       "      <td>0.085711</td>\n",
       "      <td>0.128637</td>\n",
       "      <td>0.028621</td>\n",
       "      <td>0.081709</td>\n",
       "      <td>0.063768</td>\n",
       "      <td>0.028367</td>\n",
       "      <td>0.009754</td>\n",
       "      <td>0.055744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.004754</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.011011</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>0.021115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATUALIZACAO_EMAIL</th>\n",
       "      <td>0.022480</td>\n",
       "      <td>0.064821</td>\n",
       "      <td>0.029610</td>\n",
       "      <td>0.043340</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.048778</td>\n",
       "      <td>0.039065</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.026544</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.009938</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.011939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXPOSICAO_CONSUMIDOR_EMAILS</th>\n",
       "      <td>0.028191</td>\n",
       "      <td>0.100637</td>\n",
       "      <td>0.066333</td>\n",
       "      <td>0.092479</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.056396</td>\n",
       "      <td>0.055250</td>\n",
       "      <td>0.029127</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.026866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011044</td>\n",
       "      <td>0.017121</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.007219</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.014085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXPOSICAO_CONSUMIDOR_TELEFONES</th>\n",
       "      <td>0.043818</td>\n",
       "      <td>0.123445</td>\n",
       "      <td>0.046967</td>\n",
       "      <td>0.100710</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.038440</td>\n",
       "      <td>0.076835</td>\n",
       "      <td>0.015251</td>\n",
       "      <td>0.009026</td>\n",
       "      <td>0.042013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016380</td>\n",
       "      <td>0.012466</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.007509</td>\n",
       "      <td>0.007721</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.015405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATIVIDADE_TELEFONE</th>\n",
       "      <td>0.048842</td>\n",
       "      <td>0.123535</td>\n",
       "      <td>0.054476</td>\n",
       "      <td>0.097383</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.060096</td>\n",
       "      <td>0.082791</td>\n",
       "      <td>0.013744</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.029384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.015946</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.004522</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.018880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VALOR_PARCELA_BOLSA_FAMILIA</th>\n",
       "      <td>0.029549</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>0.030546</td>\n",
       "      <td>0.075914</td>\n",
       "      <td>0.007226</td>\n",
       "      <td>0.034562</td>\n",
       "      <td>0.033717</td>\n",
       "      <td>0.019411</td>\n",
       "      <td>0.224650</td>\n",
       "      <td>0.015068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.014631</td>\n",
       "      <td>0.009022</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.016280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_BOLSA_FAMILIA_1</th>\n",
       "      <td>0.017125</td>\n",
       "      <td>0.076686</td>\n",
       "      <td>0.048595</td>\n",
       "      <td>0.073702</td>\n",
       "      <td>0.011201</td>\n",
       "      <td>0.057516</td>\n",
       "      <td>0.029261</td>\n",
       "      <td>0.056231</td>\n",
       "      <td>0.246700</td>\n",
       "      <td>0.018757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.018833</td>\n",
       "      <td>0.008540</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.007389</td>\n",
       "      <td>0.018539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP2_6</th>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.049254</td>\n",
       "      <td>0.227824</td>\n",
       "      <td>0.151508</td>\n",
       "      <td>0.067630</td>\n",
       "      <td>0.118541</td>\n",
       "      <td>0.018354</td>\n",
       "      <td>0.017671</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028036</td>\n",
       "      <td>0.012740</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.033257</td>\n",
       "      <td>0.041206</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.022095</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.033753</td>\n",
       "      <td>0.008207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP2_7</th>\n",
       "      <td>0.035253</td>\n",
       "      <td>0.036345</td>\n",
       "      <td>0.092329</td>\n",
       "      <td>0.042431</td>\n",
       "      <td>0.019542</td>\n",
       "      <td>0.107576</td>\n",
       "      <td>0.132370</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.015988</td>\n",
       "      <td>0.013299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.021336</td>\n",
       "      <td>0.014143</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.003459</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>0.025808</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.016561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP2_8</th>\n",
       "      <td>0.127231</td>\n",
       "      <td>0.064413</td>\n",
       "      <td>0.153344</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.231533</td>\n",
       "      <td>0.110188</td>\n",
       "      <td>0.080085</td>\n",
       "      <td>0.011028</td>\n",
       "      <td>0.013940</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026070</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.023503</td>\n",
       "      <td>0.024130</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.015350</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.018287</td>\n",
       "      <td>0.027417</td>\n",
       "      <td>0.024925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP2_9</th>\n",
       "      <td>0.035706</td>\n",
       "      <td>0.160233</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.157641</td>\n",
       "      <td>0.044606</td>\n",
       "      <td>0.021549</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049948</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.013246</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.026293</td>\n",
       "      <td>0.039538</td>\n",
       "      <td>0.031095</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>0.058079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_1</th>\n",
       "      <td>0.079478</td>\n",
       "      <td>0.013082</td>\n",
       "      <td>0.024672</td>\n",
       "      <td>0.115169</td>\n",
       "      <td>0.019630</td>\n",
       "      <td>0.076478</td>\n",
       "      <td>0.047759</td>\n",
       "      <td>0.030490</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011758</td>\n",
       "      <td>0.026038</td>\n",
       "      <td>0.048094</td>\n",
       "      <td>0.033452</td>\n",
       "      <td>0.058999</td>\n",
       "      <td>0.035789</td>\n",
       "      <td>0.047201</td>\n",
       "      <td>0.033384</td>\n",
       "      <td>0.017597</td>\n",
       "      <td>0.019042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_2</th>\n",
       "      <td>0.095808</td>\n",
       "      <td>0.012289</td>\n",
       "      <td>0.032843</td>\n",
       "      <td>0.019285</td>\n",
       "      <td>0.013063</td>\n",
       "      <td>0.086146</td>\n",
       "      <td>0.050879</td>\n",
       "      <td>0.022153</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.010664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027264</td>\n",
       "      <td>0.054886</td>\n",
       "      <td>0.053113</td>\n",
       "      <td>0.054921</td>\n",
       "      <td>0.079345</td>\n",
       "      <td>0.059479</td>\n",
       "      <td>0.034065</td>\n",
       "      <td>0.006475</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.059274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_3</th>\n",
       "      <td>0.005244</td>\n",
       "      <td>0.044583</td>\n",
       "      <td>0.021466</td>\n",
       "      <td>0.047603</td>\n",
       "      <td>0.044638</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.033995</td>\n",
       "      <td>0.009803</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011289</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>0.021250</td>\n",
       "      <td>0.004511</td>\n",
       "      <td>0.018212</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>0.061374</td>\n",
       "      <td>0.019429</td>\n",
       "      <td>0.040716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_4</th>\n",
       "      <td>0.036935</td>\n",
       "      <td>0.068332</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.006970</td>\n",
       "      <td>0.018711</td>\n",
       "      <td>0.067506</td>\n",
       "      <td>0.046090</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015391</td>\n",
       "      <td>0.025864</td>\n",
       "      <td>0.056434</td>\n",
       "      <td>0.021252</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>0.034971</td>\n",
       "      <td>0.021035</td>\n",
       "      <td>0.015093</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.003043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_5</th>\n",
       "      <td>0.018686</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.044004</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>0.035649</td>\n",
       "      <td>0.034387</td>\n",
       "      <td>0.055902</td>\n",
       "      <td>0.020135</td>\n",
       "      <td>0.005227</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026954</td>\n",
       "      <td>0.014938</td>\n",
       "      <td>0.021426</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.051028</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.011449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_6</th>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.033136</td>\n",
       "      <td>0.100501</td>\n",
       "      <td>0.026748</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>0.010951</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>0.008376</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013941</td>\n",
       "      <td>0.033553</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.013424</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.068129</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.058430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_7</th>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.070140</td>\n",
       "      <td>0.066772</td>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.111133</td>\n",
       "      <td>0.078501</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.006493</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037716</td>\n",
       "      <td>0.032734</td>\n",
       "      <td>0.042090</td>\n",
       "      <td>0.028335</td>\n",
       "      <td>0.022631</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>0.043659</td>\n",
       "      <td>0.022275</td>\n",
       "      <td>0.006181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_8</th>\n",
       "      <td>0.007747</td>\n",
       "      <td>0.038914</td>\n",
       "      <td>0.014766</td>\n",
       "      <td>0.155868</td>\n",
       "      <td>0.078621</td>\n",
       "      <td>0.040540</td>\n",
       "      <td>0.019838</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>0.009370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013239</td>\n",
       "      <td>0.020391</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.021430</td>\n",
       "      <td>0.030134</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>0.036293</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_9</th>\n",
       "      <td>0.007316</td>\n",
       "      <td>0.051206</td>\n",
       "      <td>0.018560</td>\n",
       "      <td>0.050332</td>\n",
       "      <td>0.065487</td>\n",
       "      <td>0.088553</td>\n",
       "      <td>0.028149</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.058565</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.048102</td>\n",
       "      <td>0.039036</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.009801</td>\n",
       "      <td>0.007158</td>\n",
       "      <td>0.023076</td>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_10</th>\n",
       "      <td>0.037401</td>\n",
       "      <td>0.122573</td>\n",
       "      <td>0.032248</td>\n",
       "      <td>0.009712</td>\n",
       "      <td>0.040417</td>\n",
       "      <td>0.054517</td>\n",
       "      <td>0.020581</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.021077</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.038610</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>0.034739</td>\n",
       "      <td>0.034160</td>\n",
       "      <td>0.015346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_11</th>\n",
       "      <td>0.038761</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.032516</td>\n",
       "      <td>0.032584</td>\n",
       "      <td>0.059035</td>\n",
       "      <td>0.029763</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.019295</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.016885</td>\n",
       "      <td>0.016830</td>\n",
       "      <td>0.016259</td>\n",
       "      <td>0.008468</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.007912</td>\n",
       "      <td>0.012464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP3_12</th>\n",
       "      <td>0.009115</td>\n",
       "      <td>0.089565</td>\n",
       "      <td>0.044717</td>\n",
       "      <td>0.027196</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.009442</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>0.038325</td>\n",
       "      <td>0.030986</td>\n",
       "      <td>0.021511</td>\n",
       "      <td>0.011453</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>0.014722</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>0.009819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_1</th>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.023137</td>\n",
       "      <td>0.010847</td>\n",
       "      <td>0.042641</td>\n",
       "      <td>0.007986</td>\n",
       "      <td>0.053411</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.026147</td>\n",
       "      <td>0.002971</td>\n",
       "      <td>0.012223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050156</td>\n",
       "      <td>0.066598</td>\n",
       "      <td>0.062154</td>\n",
       "      <td>0.069148</td>\n",
       "      <td>0.057546</td>\n",
       "      <td>0.034671</td>\n",
       "      <td>0.079745</td>\n",
       "      <td>0.080468</td>\n",
       "      <td>0.042412</td>\n",
       "      <td>0.056045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_2</th>\n",
       "      <td>0.041778</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>0.045959</td>\n",
       "      <td>0.016462</td>\n",
       "      <td>0.072975</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>0.014857</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077276</td>\n",
       "      <td>0.079951</td>\n",
       "      <td>0.108763</td>\n",
       "      <td>0.099927</td>\n",
       "      <td>0.064027</td>\n",
       "      <td>0.066742</td>\n",
       "      <td>0.060307</td>\n",
       "      <td>0.064826</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.079220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_3</th>\n",
       "      <td>0.023338</td>\n",
       "      <td>0.015772</td>\n",
       "      <td>0.025754</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.050612</td>\n",
       "      <td>0.092219</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>0.009344</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055127</td>\n",
       "      <td>0.100593</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>0.068514</td>\n",
       "      <td>0.091356</td>\n",
       "      <td>0.126188</td>\n",
       "      <td>0.057642</td>\n",
       "      <td>0.055201</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.092043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_4</th>\n",
       "      <td>0.012945</td>\n",
       "      <td>0.051797</td>\n",
       "      <td>0.016761</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.018837</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>0.018447</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110578</td>\n",
       "      <td>0.082239</td>\n",
       "      <td>0.059399</td>\n",
       "      <td>0.102702</td>\n",
       "      <td>0.086201</td>\n",
       "      <td>0.092063</td>\n",
       "      <td>0.089606</td>\n",
       "      <td>0.091386</td>\n",
       "      <td>0.093666</td>\n",
       "      <td>0.076223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_5</th>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.040997</td>\n",
       "      <td>0.011452</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.044504</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.081452</td>\n",
       "      <td>0.084146</td>\n",
       "      <td>0.068273</td>\n",
       "      <td>0.074884</td>\n",
       "      <td>0.114886</td>\n",
       "      <td>0.076358</td>\n",
       "      <td>0.081288</td>\n",
       "      <td>0.077429</td>\n",
       "      <td>0.070549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_6</th>\n",
       "      <td>0.017901</td>\n",
       "      <td>0.006801</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.023013</td>\n",
       "      <td>0.024435</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061243</td>\n",
       "      <td>0.055286</td>\n",
       "      <td>0.057445</td>\n",
       "      <td>0.067454</td>\n",
       "      <td>0.093325</td>\n",
       "      <td>0.109380</td>\n",
       "      <td>0.059392</td>\n",
       "      <td>0.105031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_7</th>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.060533</td>\n",
       "      <td>0.067999</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084146</td>\n",
       "      <td>0.061243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076438</td>\n",
       "      <td>0.065009</td>\n",
       "      <td>0.079427</td>\n",
       "      <td>0.053802</td>\n",
       "      <td>0.095205</td>\n",
       "      <td>0.093120</td>\n",
       "      <td>0.079717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_8</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.035769</td>\n",
       "      <td>0.062716</td>\n",
       "      <td>0.021085</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>0.022139</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068273</td>\n",
       "      <td>0.055286</td>\n",
       "      <td>0.076438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070476</td>\n",
       "      <td>0.081482</td>\n",
       "      <td>0.094420</td>\n",
       "      <td>0.037541</td>\n",
       "      <td>0.100988</td>\n",
       "      <td>0.089647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_9</th>\n",
       "      <td>0.041249</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>0.012738</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.029033</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.008037</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074884</td>\n",
       "      <td>0.057445</td>\n",
       "      <td>0.065009</td>\n",
       "      <td>0.070476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.056205</td>\n",
       "      <td>0.107209</td>\n",
       "      <td>0.104018</td>\n",
       "      <td>0.096174</td>\n",
       "      <td>0.081960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_10</th>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.038354</td>\n",
       "      <td>0.019959</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.065947</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114886</td>\n",
       "      <td>0.067454</td>\n",
       "      <td>0.079427</td>\n",
       "      <td>0.081482</td>\n",
       "      <td>0.056205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077964</td>\n",
       "      <td>0.093005</td>\n",
       "      <td>0.059894</td>\n",
       "      <td>0.067307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_11</th>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0.017366</td>\n",
       "      <td>0.028406</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.025372</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076358</td>\n",
       "      <td>0.093325</td>\n",
       "      <td>0.053802</td>\n",
       "      <td>0.094420</td>\n",
       "      <td>0.107209</td>\n",
       "      <td>0.077964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065892</td>\n",
       "      <td>0.077590</td>\n",
       "      <td>0.087774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_12</th>\n",
       "      <td>0.009868</td>\n",
       "      <td>0.021424</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.010240</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.017101</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081288</td>\n",
       "      <td>0.109380</td>\n",
       "      <td>0.095205</td>\n",
       "      <td>0.037541</td>\n",
       "      <td>0.104018</td>\n",
       "      <td>0.093005</td>\n",
       "      <td>0.065892</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078021</td>\n",
       "      <td>0.064582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_13</th>\n",
       "      <td>0.022239</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>0.023383</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.015740</td>\n",
       "      <td>0.034493</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077429</td>\n",
       "      <td>0.059392</td>\n",
       "      <td>0.093120</td>\n",
       "      <td>0.100988</td>\n",
       "      <td>0.096174</td>\n",
       "      <td>0.059894</td>\n",
       "      <td>0.077590</td>\n",
       "      <td>0.078021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP4_14</th>\n",
       "      <td>0.035315</td>\n",
       "      <td>0.029016</td>\n",
       "      <td>0.011395</td>\n",
       "      <td>0.047764</td>\n",
       "      <td>0.026264</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070549</td>\n",
       "      <td>0.105031</td>\n",
       "      <td>0.079717</td>\n",
       "      <td>0.089647</td>\n",
       "      <td>0.081960</td>\n",
       "      <td>0.067307</td>\n",
       "      <td>0.087774</td>\n",
       "      <td>0.064582</td>\n",
       "      <td>0.068267</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    UF_1      UF_2      UF_3      UF_4  \\\n",
       "UF_1                            1.000000  0.209093  0.048255  0.146628   \n",
       "UF_2                            0.209093  1.000000  0.123264  0.247423   \n",
       "UF_3                            0.048255  0.123264  1.000000  0.275167   \n",
       "UF_4                            0.146628  0.247423  0.275167  1.000000   \n",
       "UF_5                            0.118488  0.187327  0.269899  0.126074   \n",
       "UF_6                            0.100570  0.171868  0.246315  0.126333   \n",
       "UF_7                            0.087990  0.180898  0.216494  0.135131   \n",
       "IDADE                           0.019386  0.012217  0.031256  0.020921   \n",
       "SEXO_1                          0.007811  0.013103  0.003892  0.004924   \n",
       "NIVEL_RELACIONAMENTO_CREDITO01  0.006435  0.014506  0.013546  0.041647   \n",
       "NIVEL_RELACIONAMENTO_CREDITO02  0.001615  0.000890  0.010338  0.009182   \n",
       "BANCO_REST_IRPF_ULTIMA_1        0.007550  0.048365  0.042261  0.036186   \n",
       "BANCO_REST_IRPF_ULTIMA_2        0.027318  0.013636  0.009286  0.000790   \n",
       "BANCO_REST_IRPF_ULTIMA_3        0.031309  0.049316  0.007395  0.035204   \n",
       "BANCO_REST_IRPF_ULTIMA_4        0.009614  0.011060  0.029721  0.024070   \n",
       "BANCO_REST_IRPF_ULTIMA_5        0.000016  0.003451  0.007674  0.002916   \n",
       "BANCO_REST_IRPF_ULTIMA_6        0.004719  0.036600  0.024210  0.031489   \n",
       "BANCO_REST_IRPF_ULTIMA_7        0.004345  0.048489  0.038199  0.031314   \n",
       "ATIVIDADE_EMAIL                 0.029827  0.102135  0.053917  0.079640   \n",
       "EXPOSICAO_ENDERECO              0.050144  0.068285  0.010087  0.071787   \n",
       "EXPOSICAO_EMAIL                 0.023400  0.076136  0.038393  0.065260   \n",
       "EXPOSICAO_TELEFONE              0.036865  0.089696  0.040969  0.067006   \n",
       "ATIVIDADE_ENDERECO              0.022894  0.053707  0.036434  0.033969   \n",
       "ATUALIZACAO_ENDERECO            0.079764  0.133604  0.085711  0.128637   \n",
       "ATUALIZACAO_EMAIL               0.022480  0.064821  0.029610  0.043340   \n",
       "EXPOSICAO_CONSUMIDOR_EMAILS     0.028191  0.100637  0.066333  0.092479   \n",
       "EXPOSICAO_CONSUMIDOR_TELEFONES  0.043818  0.123445  0.046967  0.100710   \n",
       "ATIVIDADE_TELEFONE              0.048842  0.123535  0.054476  0.097383   \n",
       "VALOR_PARCELA_BOLSA_FAMILIA     0.029549  0.078861  0.030546  0.075914   \n",
       "FLAG_BOLSA_FAMILIA_1            0.017125  0.076686  0.048595  0.073702   \n",
       "...                                  ...       ...       ...       ...   \n",
       "CEP2_6                          0.010724  0.049254  0.227824  0.151508   \n",
       "CEP2_7                          0.035253  0.036345  0.092329  0.042431   \n",
       "CEP2_8                          0.127231  0.064413  0.153344  0.004123   \n",
       "CEP2_9                          0.035706  0.160233  0.040816  0.157641   \n",
       "CEP3_1                          0.079478  0.013082  0.024672  0.115169   \n",
       "CEP3_2                          0.095808  0.012289  0.032843  0.019285   \n",
       "CEP3_3                          0.005244  0.044583  0.021466  0.047603   \n",
       "CEP3_4                          0.036935  0.068332  0.002233  0.006970   \n",
       "CEP3_5                          0.018686  0.007016  0.044004  0.021937   \n",
       "CEP3_6                          0.030020  0.033136  0.100501  0.026748   \n",
       "CEP3_7                          0.005571  0.070140  0.066772  0.044413   \n",
       "CEP3_8                          0.007747  0.038914  0.014766  0.155868   \n",
       "CEP3_9                          0.007316  0.051206  0.018560  0.050332   \n",
       "CEP3_10                         0.037401  0.122573  0.032248  0.009712   \n",
       "CEP3_11                         0.038761  0.003692  0.032516  0.032584   \n",
       "CEP3_12                         0.009115  0.089565  0.044717  0.027196   \n",
       "CEP4_1                          0.003057  0.023137  0.010847  0.042641   \n",
       "CEP4_2                          0.041778  0.003489  0.045959  0.016462   \n",
       "CEP4_3                          0.023338  0.015772  0.025754  0.002694   \n",
       "CEP4_4                          0.012945  0.051797  0.016761  0.004748   \n",
       "CEP4_5                          0.025403  0.040997  0.011452  0.001024   \n",
       "CEP4_6                          0.017901  0.006801  0.008139  0.005757   \n",
       "CEP4_7                          0.002279  0.002159  0.009605  0.009747   \n",
       "CEP4_8                          0.000400  0.035769  0.062716  0.021085   \n",
       "CEP4_9                          0.041249  0.002821  0.011476  0.012738   \n",
       "CEP4_10                         0.004074  0.023900  0.038354  0.019959   \n",
       "CEP4_11                         0.004246  0.012583  0.017366  0.028406   \n",
       "CEP4_12                         0.009868  0.021424  0.002350  0.010240   \n",
       "CEP4_13                         0.022239  0.007369  0.018033  0.023383   \n",
       "CEP4_14                         0.035315  0.029016  0.011395  0.047764   \n",
       "\n",
       "                                    UF_5      UF_6      UF_7     IDADE  \\\n",
       "UF_1                            0.118488  0.100570  0.087990  0.019386   \n",
       "UF_2                            0.187327  0.171868  0.180898  0.012217   \n",
       "UF_3                            0.269899  0.246315  0.216494  0.031256   \n",
       "UF_4                            0.126074  0.126333  0.135131  0.020921   \n",
       "UF_5                            1.000000  0.156790  0.121600  0.003239   \n",
       "UF_6                            0.156790  1.000000  0.137971  0.026368   \n",
       "UF_7                            0.121600  0.137971  1.000000  0.002974   \n",
       "IDADE                           0.003239  0.026368  0.002974  1.000000   \n",
       "SEXO_1                          0.006073  0.017433  0.022839  0.017405   \n",
       "NIVEL_RELACIONAMENTO_CREDITO01  0.018759  0.028672  0.000691  0.029988   \n",
       "NIVEL_RELACIONAMENTO_CREDITO02  0.007102  0.002931  0.000145  0.009357   \n",
       "BANCO_REST_IRPF_ULTIMA_1        0.006520  0.036946  0.028865  0.011831   \n",
       "BANCO_REST_IRPF_ULTIMA_2        0.015587  0.012387  0.002948  0.035525   \n",
       "BANCO_REST_IRPF_ULTIMA_3        0.002591  0.009251  0.039252  0.002203   \n",
       "BANCO_REST_IRPF_ULTIMA_4        0.004330  0.012961  0.021763  0.010099   \n",
       "BANCO_REST_IRPF_ULTIMA_5        0.009894  0.020938  0.000802  0.013540   \n",
       "BANCO_REST_IRPF_ULTIMA_6        0.008058  0.008847  0.023075  0.017595   \n",
       "BANCO_REST_IRPF_ULTIMA_7        0.012052  0.021653  0.037037  0.017687   \n",
       "ATIVIDADE_EMAIL                 0.008905  0.067921  0.058710  0.022313   \n",
       "EXPOSICAO_ENDERECO              0.007488  0.025830  0.014593  0.037784   \n",
       "EXPOSICAO_EMAIL                 0.000574  0.041351  0.038661  0.036607   \n",
       "EXPOSICAO_TELEFONE              0.002890  0.053896  0.049747  0.012228   \n",
       "ATIVIDADE_ENDERECO              0.043457  0.020355  0.021810  0.053765   \n",
       "ATUALIZACAO_ENDERECO            0.028621  0.081709  0.063768  0.028367   \n",
       "ATUALIZACAO_EMAIL               0.007848  0.048778  0.039065  0.007181   \n",
       "EXPOSICAO_CONSUMIDOR_EMAILS     0.003326  0.056396  0.055250  0.029127   \n",
       "EXPOSICAO_CONSUMIDOR_TELEFONES  0.005675  0.038440  0.076835  0.015251   \n",
       "ATIVIDADE_TELEFONE              0.004529  0.060096  0.082791  0.013744   \n",
       "VALOR_PARCELA_BOLSA_FAMILIA     0.007226  0.034562  0.033717  0.019411   \n",
       "FLAG_BOLSA_FAMILIA_1            0.011201  0.057516  0.029261  0.056231   \n",
       "...                                  ...       ...       ...       ...   \n",
       "CEP2_6                          0.067630  0.118541  0.018354  0.017671   \n",
       "CEP2_7                          0.019542  0.107576  0.132370  0.002385   \n",
       "CEP2_8                          0.231533  0.110188  0.080085  0.011028   \n",
       "CEP2_9                          0.044606  0.021549  0.002541  0.006815   \n",
       "CEP3_1                          0.019630  0.076478  0.047759  0.030490   \n",
       "CEP3_2                          0.013063  0.086146  0.050879  0.022153   \n",
       "CEP3_3                          0.044638  0.005848  0.033995  0.009803   \n",
       "CEP3_4                          0.018711  0.067506  0.046090  0.000177   \n",
       "CEP3_5                          0.035649  0.034387  0.055902  0.020135   \n",
       "CEP3_6                          0.014460  0.010951  0.084968  0.008376   \n",
       "CEP3_7                          0.111133  0.078501  0.082090  0.006493   \n",
       "CEP3_8                          0.078621  0.040540  0.019838  0.002797   \n",
       "CEP3_9                          0.065487  0.088553  0.028149  0.007804   \n",
       "CEP3_10                         0.040417  0.054517  0.020581  0.007211   \n",
       "CEP3_11                         0.059035  0.029763  0.002990  0.019295   \n",
       "CEP3_12                         0.014113  0.003386  0.009442  0.001182   \n",
       "CEP4_1                          0.007986  0.053411  0.013797  0.026147   \n",
       "CEP4_2                          0.072975  0.115646  0.026872  0.014857   \n",
       "CEP4_3                          0.050612  0.092219  0.005744  0.009344   \n",
       "CEP4_4                          0.018837  0.014398  0.018447  0.003289   \n",
       "CEP4_5                          0.000297  0.002480  0.044504  0.001120   \n",
       "CEP4_6                          0.002524  0.023013  0.024435  0.004402   \n",
       "CEP4_7                          0.060533  0.067999  0.005311  0.013037   \n",
       "CEP4_8                          0.009569  0.022139  0.000662  0.001559   \n",
       "CEP4_9                          0.000885  0.029033  0.006608  0.008037   \n",
       "CEP4_10                         0.000713  0.065947  0.035075  0.004025   \n",
       "CEP4_11                         0.001331  0.025372  0.001038  0.000544   \n",
       "CEP4_12                         0.023599  0.000670  0.017101  0.002066   \n",
       "CEP4_13                         0.026219  0.015740  0.034493  0.000616   \n",
       "CEP4_14                         0.026264  0.003706  0.003431  0.006353   \n",
       "\n",
       "                                  SEXO_1  NIVEL_RELACIONAMENTO_CREDITO01  \\\n",
       "UF_1                            0.007811                        0.006435   \n",
       "UF_2                            0.013103                        0.014506   \n",
       "UF_3                            0.003892                        0.013546   \n",
       "UF_4                            0.004924                        0.041647   \n",
       "UF_5                            0.006073                        0.018759   \n",
       "UF_6                            0.017433                        0.028672   \n",
       "UF_7                            0.022839                        0.000691   \n",
       "IDADE                           0.017405                        0.029988   \n",
       "SEXO_1                          1.000000                        0.020646   \n",
       "NIVEL_RELACIONAMENTO_CREDITO01  0.020646                        1.000000   \n",
       "NIVEL_RELACIONAMENTO_CREDITO02  0.004807                        0.239705   \n",
       "BANCO_REST_IRPF_ULTIMA_1        0.041594                        0.014328   \n",
       "BANCO_REST_IRPF_ULTIMA_2        0.010267                        0.012884   \n",
       "BANCO_REST_IRPF_ULTIMA_3        0.022476                        0.003451   \n",
       "BANCO_REST_IRPF_ULTIMA_4        0.031053                        0.008848   \n",
       "BANCO_REST_IRPF_ULTIMA_5        0.019192                        0.009553   \n",
       "BANCO_REST_IRPF_ULTIMA_6        0.041111                        0.015834   \n",
       "BANCO_REST_IRPF_ULTIMA_7        0.040374                        0.016688   \n",
       "ATIVIDADE_EMAIL                 0.010091                        0.015398   \n",
       "EXPOSICAO_ENDERECO              0.029683                        0.043574   \n",
       "EXPOSICAO_EMAIL                 0.010047                        0.013042   \n",
       "EXPOSICAO_TELEFONE              0.008596                        0.029972   \n",
       "ATIVIDADE_ENDERECO              0.004899                        0.010995   \n",
       "ATUALIZACAO_ENDERECO            0.009754                        0.055744   \n",
       "ATUALIZACAO_EMAIL               0.026544                        0.007267   \n",
       "EXPOSICAO_CONSUMIDOR_EMAILS     0.002422                        0.026866   \n",
       "EXPOSICAO_CONSUMIDOR_TELEFONES  0.009026                        0.042013   \n",
       "ATIVIDADE_TELEFONE              0.000816                        0.029384   \n",
       "VALOR_PARCELA_BOLSA_FAMILIA     0.224650                        0.015068   \n",
       "FLAG_BOLSA_FAMILIA_1            0.246700                        0.018757   \n",
       "...                                  ...                             ...   \n",
       "CEP2_6                          0.002026                        0.009349   \n",
       "CEP2_7                          0.015988                        0.013299   \n",
       "CEP2_8                          0.013940                        0.000648   \n",
       "CEP2_9                          0.002322                        0.007211   \n",
       "CEP3_1                          0.003950                        0.005457   \n",
       "CEP3_2                          0.006760                        0.010664   \n",
       "CEP3_3                          0.009796                        0.004269   \n",
       "CEP3_4                          0.004429                        0.005953   \n",
       "CEP3_5                          0.005227                        0.000593   \n",
       "CEP3_6                          0.004291                        0.000195   \n",
       "CEP3_7                          0.004277                        0.004795   \n",
       "CEP3_8                          0.009405                        0.009370   \n",
       "CEP3_9                          0.002677                        0.000952   \n",
       "CEP3_10                         0.003127                        0.003563   \n",
       "CEP3_11                         0.004793                        0.004151   \n",
       "CEP3_12                         0.005584                        0.000917   \n",
       "CEP4_1                          0.002971                        0.012223   \n",
       "CEP4_2                          0.000759                        0.009663   \n",
       "CEP4_3                          0.008977                        0.000904   \n",
       "CEP4_4                          0.005784                        0.001465   \n",
       "CEP4_5                          0.000789                        0.002201   \n",
       "CEP4_6                          0.008388                        0.004603   \n",
       "CEP4_7                          0.000917                        0.001246   \n",
       "CEP4_8                          0.002623                        0.002234   \n",
       "CEP4_9                          0.002129                        0.003535   \n",
       "CEP4_10                         0.002683                        0.001846   \n",
       "CEP4_11                         0.001580                        0.000003   \n",
       "CEP4_12                         0.004715                        0.000372   \n",
       "CEP4_13                         0.002303                        0.004002   \n",
       "CEP4_14                         0.003675                        0.005085   \n",
       "\n",
       "                                  ...       CEP4_5    CEP4_6    CEP4_7  \\\n",
       "UF_1                              ...     0.025403  0.017901  0.002279   \n",
       "UF_2                              ...     0.040997  0.006801  0.002159   \n",
       "UF_3                              ...     0.011452  0.008139  0.009605   \n",
       "UF_4                              ...     0.001024  0.005757  0.009747   \n",
       "UF_5                              ...     0.000297  0.002524  0.060533   \n",
       "UF_6                              ...     0.002480  0.023013  0.067999   \n",
       "UF_7                              ...     0.044504  0.024435  0.005311   \n",
       "IDADE                             ...     0.001120  0.004402  0.013037   \n",
       "SEXO_1                            ...     0.000789  0.008388  0.000917   \n",
       "NIVEL_RELACIONAMENTO_CREDITO01    ...     0.002201  0.004603  0.001246   \n",
       "NIVEL_RELACIONAMENTO_CREDITO02    ...     0.001662  0.000234  0.000432   \n",
       "BANCO_REST_IRPF_ULTIMA_1          ...     0.012245  0.016455  0.005782   \n",
       "BANCO_REST_IRPF_ULTIMA_2          ...     0.004858  0.009597  0.004823   \n",
       "BANCO_REST_IRPF_ULTIMA_3          ...     0.011136  0.002867  0.002796   \n",
       "BANCO_REST_IRPF_ULTIMA_4          ...     0.006003  0.005124  0.008856   \n",
       "BANCO_REST_IRPF_ULTIMA_5          ...     0.003891  0.008531  0.007255   \n",
       "BANCO_REST_IRPF_ULTIMA_6          ...     0.012357  0.015106  0.006938   \n",
       "BANCO_REST_IRPF_ULTIMA_7          ...     0.012903  0.014959  0.007677   \n",
       "ATIVIDADE_EMAIL                   ...     0.009134  0.017565  0.001078   \n",
       "EXPOSICAO_ENDERECO                ...     0.000716  0.000250  0.002238   \n",
       "EXPOSICAO_EMAIL                   ...     0.008211  0.016051  0.001216   \n",
       "EXPOSICAO_TELEFONE                ...     0.008441  0.012044  0.003002   \n",
       "ATIVIDADE_ENDERECO                ...     0.005599  0.001461  0.004068   \n",
       "ATUALIZACAO_ENDERECO              ...     0.003096  0.004754  0.000765   \n",
       "ATUALIZACAO_EMAIL                 ...     0.003380  0.009938  0.002884   \n",
       "EXPOSICAO_CONSUMIDOR_EMAILS       ...     0.011044  0.017121  0.000029   \n",
       "EXPOSICAO_CONSUMIDOR_TELEFONES    ...     0.016380  0.012466  0.002132   \n",
       "ATIVIDADE_TELEFONE                ...     0.012557  0.015946  0.000594   \n",
       "VALOR_PARCELA_BOLSA_FAMILIA       ...     0.006317  0.000778  0.014631   \n",
       "FLAG_BOLSA_FAMILIA_1              ...     0.006456  0.000662  0.018833   \n",
       "...                               ...          ...       ...       ...   \n",
       "CEP2_6                            ...     0.028036  0.012740  0.003134   \n",
       "CEP2_7                            ...     0.003456  0.021336  0.014143   \n",
       "CEP2_8                            ...     0.026070  0.000659  0.023503   \n",
       "CEP2_9                            ...     0.049948  0.003169  0.013246   \n",
       "CEP3_1                            ...     0.011758  0.026038  0.048094   \n",
       "CEP3_2                            ...     0.027264  0.054886  0.053113   \n",
       "CEP3_3                            ...     0.011289  0.012343  0.054169   \n",
       "CEP3_4                            ...     0.015391  0.025864  0.056434   \n",
       "CEP3_5                            ...     0.026954  0.014938  0.021426   \n",
       "CEP3_6                            ...     0.013941  0.033553  0.008870   \n",
       "CEP3_7                            ...     0.037716  0.032734  0.042090   \n",
       "CEP3_8                            ...     0.013239  0.020391  0.001042   \n",
       "CEP3_9                            ...     0.003629  0.058565  0.002754   \n",
       "CEP3_10                           ...     0.012316  0.011996  0.001078   \n",
       "CEP3_11                           ...     0.001041  0.024088  0.016885   \n",
       "CEP3_12                           ...     0.005185  0.008472  0.038325   \n",
       "CEP4_1                            ...     0.050156  0.066598  0.062154   \n",
       "CEP4_2                            ...     0.077276  0.079951  0.108763   \n",
       "CEP4_3                            ...     0.055127  0.100593  0.098300   \n",
       "CEP4_4                            ...     0.110578  0.082239  0.059399   \n",
       "CEP4_5                            ...     1.000000  0.081452  0.084146   \n",
       "CEP4_6                            ...     0.081452  1.000000  0.061243   \n",
       "CEP4_7                            ...     0.084146  0.061243  1.000000   \n",
       "CEP4_8                            ...     0.068273  0.055286  0.076438   \n",
       "CEP4_9                            ...     0.074884  0.057445  0.065009   \n",
       "CEP4_10                           ...     0.114886  0.067454  0.079427   \n",
       "CEP4_11                           ...     0.076358  0.093325  0.053802   \n",
       "CEP4_12                           ...     0.081288  0.109380  0.095205   \n",
       "CEP4_13                           ...     0.077429  0.059392  0.093120   \n",
       "CEP4_14                           ...     0.070549  0.105031  0.079717   \n",
       "\n",
       "                                  CEP4_8    CEP4_9   CEP4_10   CEP4_11  \\\n",
       "UF_1                            0.000400  0.041249  0.004074  0.004246   \n",
       "UF_2                            0.035769  0.002821  0.023900  0.012583   \n",
       "UF_3                            0.062716  0.011476  0.038354  0.017366   \n",
       "UF_4                            0.021085  0.012738  0.019959  0.028406   \n",
       "UF_5                            0.009569  0.000885  0.000713  0.001331   \n",
       "UF_6                            0.022139  0.029033  0.065947  0.025372   \n",
       "UF_7                            0.000662  0.006608  0.035075  0.001038   \n",
       "IDADE                           0.001559  0.008037  0.004025  0.000544   \n",
       "SEXO_1                          0.002623  0.002129  0.002683  0.001580   \n",
       "NIVEL_RELACIONAMENTO_CREDITO01  0.002234  0.003535  0.001846  0.000003   \n",
       "NIVEL_RELACIONAMENTO_CREDITO02  0.002970  0.000242  0.003913  0.002860   \n",
       "BANCO_REST_IRPF_ULTIMA_1        0.004235  0.002374  0.004159  0.004780   \n",
       "BANCO_REST_IRPF_ULTIMA_2        0.009435  0.003250  0.007759  0.002070   \n",
       "BANCO_REST_IRPF_ULTIMA_3        0.000919  0.006268  0.004781  0.009614   \n",
       "BANCO_REST_IRPF_ULTIMA_4        0.002532  0.001209  0.002564  0.003083   \n",
       "BANCO_REST_IRPF_ULTIMA_5        0.003513  0.001576  0.003156  0.000101   \n",
       "BANCO_REST_IRPF_ULTIMA_6        0.006781  0.000470  0.004426  0.005728   \n",
       "BANCO_REST_IRPF_ULTIMA_7        0.006785  0.001073  0.002700  0.003872   \n",
       "ATIVIDADE_EMAIL                 0.000889  0.003669  0.001380  0.002623   \n",
       "EXPOSICAO_ENDERECO              0.001343  0.000541  0.005199  0.002688   \n",
       "EXPOSICAO_EMAIL                 0.002955  0.000915  0.000205  0.001108   \n",
       "EXPOSICAO_TELEFONE              0.002395  0.002630  0.000210  0.003113   \n",
       "ATIVIDADE_ENDERECO              0.001806  0.006177  0.005720  0.003607   \n",
       "ATUALIZACAO_ENDERECO            0.005503  0.004270  0.003634  0.011011   \n",
       "ATUALIZACAO_EMAIL               0.000042  0.001869  0.001017  0.000632   \n",
       "EXPOSICAO_CONSUMIDOR_EMAILS     0.002683  0.002318  0.001352  0.004446   \n",
       "EXPOSICAO_CONSUMIDOR_TELEFONES  0.005159  0.000541  0.001936  0.007509   \n",
       "ATIVIDADE_TELEFONE              0.002983  0.002939  0.001914  0.004522   \n",
       "VALOR_PARCELA_BOLSA_FAMILIA     0.009022  0.007882  0.008043  0.008097   \n",
       "FLAG_BOLSA_FAMILIA_1            0.008540  0.011924  0.008404  0.004892   \n",
       "...                                  ...       ...       ...       ...   \n",
       "CEP2_6                          0.033257  0.041206  0.002075  0.022095   \n",
       "CEP2_7                          0.027258  0.002792  0.003459  0.005254   \n",
       "CEP2_8                          0.024130  0.000183  0.015350  0.001205   \n",
       "CEP2_9                          0.003809  0.026293  0.039538  0.031095   \n",
       "CEP3_1                          0.033452  0.058999  0.035789  0.047201   \n",
       "CEP3_2                          0.054921  0.079345  0.059479  0.034065   \n",
       "CEP3_3                          0.021250  0.004511  0.018212  0.011057   \n",
       "CEP3_4                          0.021252  0.014778  0.034971  0.021035   \n",
       "CEP3_5                          0.007138  0.051028  0.003520  0.016496   \n",
       "CEP3_6                          0.013424  0.008919  0.068129  0.010120   \n",
       "CEP3_7                          0.028335  0.022631  0.009884  0.006030   \n",
       "CEP3_8                          0.021430  0.030134  0.009896  0.036293   \n",
       "CEP3_9                          0.048102  0.039036  0.006741  0.009801   \n",
       "CEP3_10                         0.021077  0.042262  0.038610  0.005878   \n",
       "CEP3_11                         0.016830  0.016259  0.008468  0.004203   \n",
       "CEP3_12                         0.030986  0.021511  0.011453  0.014967   \n",
       "CEP4_1                          0.069148  0.057546  0.034671  0.079745   \n",
       "CEP4_2                          0.099927  0.064027  0.066742  0.060307   \n",
       "CEP4_3                          0.068514  0.091356  0.126188  0.057642   \n",
       "CEP4_4                          0.102702  0.086201  0.092063  0.089606   \n",
       "CEP4_5                          0.068273  0.074884  0.114886  0.076358   \n",
       "CEP4_6                          0.055286  0.057445  0.067454  0.093325   \n",
       "CEP4_7                          0.076438  0.065009  0.079427  0.053802   \n",
       "CEP4_8                          1.000000  0.070476  0.081482  0.094420   \n",
       "CEP4_9                          0.070476  1.000000  0.056205  0.107209   \n",
       "CEP4_10                         0.081482  0.056205  1.000000  0.077964   \n",
       "CEP4_11                         0.094420  0.107209  0.077964  1.000000   \n",
       "CEP4_12                         0.037541  0.104018  0.093005  0.065892   \n",
       "CEP4_13                         0.100988  0.096174  0.059894  0.077590   \n",
       "CEP4_14                         0.089647  0.081960  0.067307  0.087774   \n",
       "\n",
       "                                 CEP4_12   CEP4_13   CEP4_14  \n",
       "UF_1                            0.009868  0.022239  0.035315  \n",
       "UF_2                            0.021424  0.007369  0.029016  \n",
       "UF_3                            0.002350  0.018033  0.011395  \n",
       "UF_4                            0.010240  0.023383  0.047764  \n",
       "UF_5                            0.023599  0.026219  0.026264  \n",
       "UF_6                            0.000670  0.015740  0.003706  \n",
       "UF_7                            0.017101  0.034493  0.003431  \n",
       "IDADE                           0.002066  0.000616  0.006353  \n",
       "SEXO_1                          0.004715  0.002303  0.003675  \n",
       "NIVEL_RELACIONAMENTO_CREDITO01  0.000372  0.004002  0.005085  \n",
       "NIVEL_RELACIONAMENTO_CREDITO02  0.001918  0.000591  0.001580  \n",
       "BANCO_REST_IRPF_ULTIMA_1        0.007634  0.000321  0.011306  \n",
       "BANCO_REST_IRPF_ULTIMA_2        0.006667  0.002163  0.012610  \n",
       "BANCO_REST_IRPF_ULTIMA_3        0.000145  0.004880  0.004504  \n",
       "BANCO_REST_IRPF_ULTIMA_4        0.001932  0.001854  0.000901  \n",
       "BANCO_REST_IRPF_ULTIMA_5        0.004460  0.000758  0.006276  \n",
       "BANCO_REST_IRPF_ULTIMA_6        0.006814  0.000359  0.012221  \n",
       "BANCO_REST_IRPF_ULTIMA_7        0.006262  0.001432  0.011833  \n",
       "ATIVIDADE_EMAIL                 0.008246  0.001737  0.015123  \n",
       "EXPOSICAO_ENDERECO              0.000534  0.006409  0.019879  \n",
       "EXPOSICAO_EMAIL                 0.006326  0.002026  0.007416  \n",
       "EXPOSICAO_TELEFONE              0.006901  0.001755  0.008774  \n",
       "ATIVIDADE_ENDERECO              0.004260  0.004610  0.017025  \n",
       "ATUALIZACAO_ENDERECO            0.006841  0.005685  0.021115  \n",
       "ATUALIZACAO_EMAIL               0.005740  0.000358  0.011939  \n",
       "EXPOSICAO_CONSUMIDOR_EMAILS     0.007219  0.001482  0.014085  \n",
       "EXPOSICAO_CONSUMIDOR_TELEFONES  0.007721  0.002992  0.015405  \n",
       "ATIVIDADE_TELEFONE              0.012180  0.000529  0.018880  \n",
       "VALOR_PARCELA_BOLSA_FAMILIA     0.000593  0.008237  0.016280  \n",
       "FLAG_BOLSA_FAMILIA_1            0.000170  0.007389  0.018539  \n",
       "...                                  ...       ...       ...  \n",
       "CEP2_6                          0.000501  0.033753  0.008207  \n",
       "CEP2_7                          0.025808  0.002482  0.016561  \n",
       "CEP2_8                          0.018287  0.027417  0.024925  \n",
       "CEP2_9                          0.007514  0.006430  0.058079  \n",
       "CEP3_1                          0.033384  0.017597  0.019042  \n",
       "CEP3_2                          0.006475  0.003271  0.059274  \n",
       "CEP3_3                          0.061374  0.019429  0.040716  \n",
       "CEP3_4                          0.015093  0.002690  0.003043  \n",
       "CEP3_5                          0.019804  0.003867  0.011449  \n",
       "CEP3_6                          0.009546  0.002526  0.058430  \n",
       "CEP3_7                          0.043659  0.022275  0.006181  \n",
       "CEP3_8                          0.005137  0.000335  0.002855  \n",
       "CEP3_9                          0.007158  0.023076  0.001276  \n",
       "CEP3_10                         0.034739  0.034160  0.015346  \n",
       "CEP3_11                         0.011100  0.007912  0.012464  \n",
       "CEP3_12                         0.014722  0.004071  0.009819  \n",
       "CEP4_1                          0.080468  0.042412  0.056045  \n",
       "CEP4_2                          0.064826  0.068966  0.079220  \n",
       "CEP4_3                          0.055201  0.096777  0.092043  \n",
       "CEP4_4                          0.091386  0.093666  0.076223  \n",
       "CEP4_5                          0.081288  0.077429  0.070549  \n",
       "CEP4_6                          0.109380  0.059392  0.105031  \n",
       "CEP4_7                          0.095205  0.093120  0.079717  \n",
       "CEP4_8                          0.037541  0.100988  0.089647  \n",
       "CEP4_9                          0.104018  0.096174  0.081960  \n",
       "CEP4_10                         0.093005  0.059894  0.067307  \n",
       "CEP4_11                         0.065892  0.077590  0.087774  \n",
       "CEP4_12                         1.000000  0.078021  0.064582  \n",
       "CEP4_13                         0.078021  1.000000  0.068267  \n",
       "CEP4_14                         0.064582  0.068267  1.000000  \n",
       "\n",
       "[243 rows x 243 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Zt72Gp2gf7We",
    "outputId": "b461faa1-d8cf-4d94-ccb3-20784271de10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33220</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.217846</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750400</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340086</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074953</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>237182</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.355855</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>335250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.930834</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>149584</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.678045</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>71560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.485231</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>118664</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.654419</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19053</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.358808</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>368546</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132485</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id UF_1 UF_2 UF_3 UF_4 UF_5 UF_6 UF_7     IDADE  SEXO_1     ...       \\\n",
       "0   33220    1    1    1    0    0    0    0  0.217846       0     ...        \n",
       "1  164123    0    0    1    1    0    1    0  0.750400       0     ...        \n",
       "2  340086    1    0    0    0    1    1    0  0.074953       0     ...        \n",
       "3  237182    1    1    1    0    0    0    0  0.355855       0     ...        \n",
       "4  335250    1    0    1    0    0    1    0  0.930834       1     ...        \n",
       "5  149584    1    1    1    0    0    0    0  0.678045       0     ...        \n",
       "6   71560    1    1    0    0    0    0    1  0.485231       1     ...        \n",
       "7  118664    0    1    1    0    1    0    0  0.654419       1     ...        \n",
       "8   19053    1    1    0    1    0    0    0  0.358808       1     ...        \n",
       "9  368546    1    1    1    0    0    0    0  0.132485       1     ...        \n",
       "\n",
       "   CEP4_7  CEP4_8 CEP4_9 CEP4_10 CEP4_11 CEP4_12 CEP4_13 CEP4_14 IND_BOM_1_1  \\\n",
       "0       0       0      1       1       0       0       0       0           0   \n",
       "1       0       1      0       1       1       0       0       0           0   \n",
       "2       0       0      0       0       0       1       1       1           1   \n",
       "3       0       1      1       1       0       0       0       1           1   \n",
       "4       0       1      0       0       0       1       0       0           1   \n",
       "5       1       0      0       1       0       0       1       0           1   \n",
       "6       1       0      1       0       1       0       0       0           1   \n",
       "7       0       0      0       0       0       1       1       1           1   \n",
       "8       0       0      0       0       1       1       0       1           1   \n",
       "9       1       1      1       1       0       0       0       1           1   \n",
       "\n",
       "   IND_BOM_1_2  \n",
       "0            1  \n",
       "1            1  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "5            0  \n",
       "6            0  \n",
       "7            0  \n",
       "8            0  \n",
       "9            0  \n",
       "\n",
       "[10 rows x 246 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "8SWa1sFkf7Wh"
   },
   "outputs": [],
   "source": [
    "corr_matrix = features.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Mmg3lV6df7Wk"
   },
   "outputs": [],
   "source": [
    "values = corr_matrix[corr_matrix > 0.95].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xDl_gqVdf7Wn",
    "outputId": "8e97c2b1-d549-477f-ca37-3d85adc4205a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLAG_BOLSA_FAMILIA_1        2\n",
       "RENDA_VIZINHANCA_1          2\n",
       "RENDA_VIZINHANCA_4          2\n",
       "FLAG_PROGRAMAS_SOCIAIS_1    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[values > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "p4_M6HP1f7Wq",
    "outputId": "e6d2bd55-082c-450c-8f45-ac7d2f30852a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_5</th>\n",
       "      <th>CEP4_6</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RENDA_VIZINHANCA_1</th>\n",
       "      <td>0.039497</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>0.095179</td>\n",
       "      <td>0.120255</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>0.021913</td>\n",
       "      <td>0.094908</td>\n",
       "      <td>0.056833</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014022</td>\n",
       "      <td>0.030272</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.022686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RENDA_VIZINHANCA_4</th>\n",
       "      <td>0.042773</td>\n",
       "      <td>0.123006</td>\n",
       "      <td>0.096118</td>\n",
       "      <td>0.121031</td>\n",
       "      <td>0.041934</td>\n",
       "      <td>0.020677</td>\n",
       "      <td>0.093601</td>\n",
       "      <td>0.053994</td>\n",
       "      <td>0.009825</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014699</td>\n",
       "      <td>0.027470</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>0.020939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        UF_1      UF_2      UF_3      UF_4      UF_5  \\\n",
       "RENDA_VIZINHANCA_1  0.039497  0.126106  0.095179  0.120255  0.040225   \n",
       "RENDA_VIZINHANCA_4  0.042773  0.123006  0.096118  0.121031  0.041934   \n",
       "\n",
       "                        UF_6      UF_7     IDADE    SEXO_1  \\\n",
       "RENDA_VIZINHANCA_1  0.021913  0.094908  0.056833  0.011343   \n",
       "RENDA_VIZINHANCA_4  0.020677  0.093601  0.053994  0.009825   \n",
       "\n",
       "                    NIVEL_RELACIONAMENTO_CREDITO01    ...       CEP4_5  \\\n",
       "RENDA_VIZINHANCA_1                        0.004249    ...     0.014022   \n",
       "RENDA_VIZINHANCA_4                        0.003914    ...     0.014699   \n",
       "\n",
       "                      CEP4_6    CEP4_7    CEP4_8    CEP4_9   CEP4_10  \\\n",
       "RENDA_VIZINHANCA_1  0.030272  0.002249  0.002028  0.003034  0.005432   \n",
       "RENDA_VIZINHANCA_4  0.027470  0.003278  0.000880  0.003880  0.005072   \n",
       "\n",
       "                     CEP4_11   CEP4_12   CEP4_13   CEP4_14  \n",
       "RENDA_VIZINHANCA_1  0.003514  0.008236  0.007406  0.022686  \n",
       "RENDA_VIZINHANCA_4  0.002067  0.006980  0.006323  0.020939  \n",
       "\n",
       "[2 rows x 243 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix[corr_matrix[\"RENDA_VIZINHANCA_1\"] > 0.90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-EcYcC7f7Ws"
   },
   "source": [
    "RENDA_VIZINHANCA_1 e  RENDA_VIZINHANCA_4 possuem alta correlação e FLAG_BOLSA_FAMILIA_1 e FLAG_PROGRAMAS_SOCIAIS_1\n",
    "também. Logo, vou ficar com somente duas das 4.\n",
    "Contudo, este teste é para apenas para variáveis correlacionadas linearmente, existem testes melhores para as variáveis categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "CUw5h-3-f7Wv"
   },
   "outputs": [],
   "source": [
    "features = features.drop([\"RENDA_VIZINHANCA_1\", \"FLAG_BOLSA_FAMILIA_1\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DW2eZPNqf7Ww",
    "outputId": "12e06a68-652f-4862-afec-c71cf7b83125"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194598, 244)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "r7Fy_BfIf7W0",
    "outputId": "378e6199-1661-4c9e-b6f2-53ae48ab021a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194598, 244)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.drop_duplicates(inplace=True)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "pMKX3EYpf7W2"
   },
   "outputs": [],
   "source": [
    "training_data_model = pandas.concat([features, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qDz38AF4f7W4",
    "outputId": "7d52be84-9540-40da-f835-55f9b0f77aca"
   },
   "outputs": [],
   "source": [
    "training_data_model.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5IRkO1O5f7W8",
    "outputId": "5cec10ba-db60-4ef9-d629-a1a906377ee6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    76592\n",
       "0    40167\n",
       "Name: IND_BOM_1_1, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paWFizV2f7W-"
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4WPUJbff7XC"
   },
   "source": [
    "In this module we're trying to build the feature that we see will be more useful in order to learn about\n",
    "the class we need to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NHVg252Vf7XF"
   },
   "source": [
    "# Model Tranining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "VtaX3fzFf7XH"
   },
   "outputs": [],
   "source": [
    "features = training_data.drop([\"IND_BOM_1_1\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DfSOkMvof7XK",
    "outputId": "b53fa1b1-6050-4d99-deee-156cc011dedc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_5</th>\n",
       "      <th>CEP4_6</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264499</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.365567</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37020</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400268</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69476</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333590</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803275</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306057</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.399416</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113343</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285260</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85214</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.782262</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273478</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.580417</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84863</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.911808</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277854</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521636</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "264499     1     1     0     0     0     0     1  0.365567       0   \n",
       "37020      1     0     1     1     0     0     0  0.400268       0   \n",
       "69476      1     0     1     0     1     0     0  0.272141       0   \n",
       "333590     1     1     0     0     1     0     0  0.803275       0   \n",
       "306057     1     0     0     1     0     0     1  0.399416       0   \n",
       "113343     1     1     1     0     0     0     0  0.285260       1   \n",
       "85214      1     1     0     1     0     0     0  0.782262       0   \n",
       "273478     1     1     1     0     0     0     0  0.580417       0   \n",
       "84863      1     1     0     1     0     0     0  0.911808       1   \n",
       "277854     1     1     0     0     0     1     0  0.521636       1   \n",
       "\n",
       "        NIVEL_RELACIONAMENTO_CREDITO01   ...     CEP4_5  CEP4_6  CEP4_7  \\\n",
       "264499                        0.111111   ...          1       0       1   \n",
       "37020                         0.111111   ...          0       1       0   \n",
       "69476                         0.111111   ...          1       0       0   \n",
       "333590                        1.000000   ...          0       1       1   \n",
       "306057                        0.111111   ...          1       1       1   \n",
       "113343                        0.111111   ...          1       1       0   \n",
       "85214                         0.111111   ...          1       1       0   \n",
       "273478                        0.111111   ...          0       1       1   \n",
       "84863                         0.111111   ...          1       0       0   \n",
       "277854                        0.111111   ...          1       0       0   \n",
       "\n",
       "        CEP4_8  CEP4_9  CEP4_10  CEP4_11  CEP4_12  CEP4_13  CEP4_14  \n",
       "264499       0       1        0        0        0        1        0  \n",
       "37020        1       1        0        0        0        1        0  \n",
       "69476        1       1        1        1        0        1        0  \n",
       "333590       1       1        1        0        0        0        0  \n",
       "306057       0       0        0        0        0        0        0  \n",
       "113343       0       1        0        0        0        1        0  \n",
       "85214        0       0        0        0        1        1        1  \n",
       "273478       0       1        1        0        0        1        0  \n",
       "84863        0       1        0        0        1        1        0  \n",
       "277854       1       1        0        0        0        1        1  \n",
       "\n",
       "[10 rows x 243 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "vrTBDGb0f7XO"
   },
   "outputs": [],
   "source": [
    "labels = training_data[\"IND_BOM_1_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260761,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "pt0S5t9yf7XQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "xrXbhsrRf7XT"
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=1/4, \n",
    "#                                                    random_state=42, stratify=labels)\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=1/3, \n",
    "#                                                  random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "xrXbhsrRf7XT"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRECT SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = (test_data.drop(\"IND_BOM_1_1\", axis=1), test_data[\"IND_BOM_1_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = (training_data.drop(\"IND_BOM_1_1\", axis=1), training_data[\"IND_BOM_1_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260761,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_whole = pandas.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389196, 243)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_whole.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_whole = pandas.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389196,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_whole.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if creating different samples from training set, use this paragraph\n",
    "training_data_sample = training_data.sample(frac=0.7)\n",
    "X_train, y_train = (training_data_sample.drop(\"IND_BOM_1_1\", axis=1), training_data_sample[\"IND_BOM_1_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260761, 243)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128435, 243)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create function to plot AUC_ROC given model and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc_roc(model, x_test, y_test):\n",
    "    probs = model.predict_proba(x_test)\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnMarR8Cf7Xx"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "1PYMF-fcf7Xx"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "5iRz5PRVf7X6"
   },
   "outputs": [],
   "source": [
    "def compute_performance_metrics(y, y_pred_class, y_pred_scores=None):\n",
    "    accuracy = accuracy_score(y, y_pred_class)\n",
    "    recall = recall_score(y, y_pred_class)\n",
    "    precision = precision_score(y, y_pred_class)\n",
    "    f1 = f1_score(y, y_pred_class)\n",
    "    performance_metrics = (accuracy, recall, precision, f1)\n",
    "    if y_pred_scores is not None:\n",
    "        auroc = roc_auc_score(y, y_pred_scores)\n",
    "        aupr = average_precision_score(y, y_pred_scores)\n",
    "        performance_metrics = performance_metrics + (auroc, aupr)\n",
    "    return performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "X4UtgNY5f7X6"
   },
   "outputs": [],
   "source": [
    "def print_metrics_summary(accuracy, recall, precision, f1, auroc=None, aupr=None):\n",
    "    print()\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Accuracy:\", value=accuracy))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Recall:\", value=recall))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Precision:\", value=precision))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"F1:\", value=f1))\n",
    "    if auroc is not None:\n",
    "        print(\"{metric:<18}{value:.4f}\".format(metric=\"AUROC:\", value=auroc))\n",
    "    if aupr is not None:\n",
    "        print(\"{metric:<18}{value:.4f}\".format(metric=\"AUPR:\", value=aupr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=20,\n",
    "                              verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_1 = Sequential()\n",
    "classifier_1.add(Dense(16, activation='tanh', input_dim=input_dimension))\n",
    "classifier_1.add(Dense(16, activation='relu', input_dim=input_dimension))\n",
    "classifier_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "classifier_1.compile(optimizer='adam', loss='mean_squared_error', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "senmQCDef7Xc"
   },
   "outputs": [],
   "source": [
    "classifier_2 = Sequential()\n",
    "classifier_2.add(Dense(16, activation='tanh', input_dim=input_dimension))\n",
    "classifier_2.add(Dense(16, activation='tanh', input_dim=input_dimension))\n",
    "classifier_2.add(Dense(8, activation='relu', input_dim=input_dimension/2))\n",
    "classifier_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "classifier_2.compile(optimizer='adam', loss='mean_squared_error', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_3 = Sequential()\n",
    "classifier_3.add(Dense(16, activation='relu', input_dim=input_dimension))\n",
    "classifier_3.add(Dense(8, activation='relu', input_dim=input_dimension))\n",
    "classifier_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "classifier_3.compile(optimizer='adam', loss='mean_squared_error', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z7_JtotLf7Xe"
   },
   "source": [
    "I use as_matrix because Keras expects a Numpy array instead of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Rri7yLInf7Xf",
    "outputId": "7f969378-2d9a-4069-98d5-578e60ec4ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                3904      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 4,193\n",
      "Trainable params: 4,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                3904      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 4,321\n",
      "Trainable params: 4,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 16)                3904      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 4,049\n",
      "Trainable params: 4,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49622 samples, validate on 8757 samples\n",
      "Epoch 1/500\n",
      "49622/49622 [==============================] - 6s 124us/step - loss: 0.2145 - acc: 0.6632 - val_loss: 0.2072 - val_acc: 0.6735\n",
      "Epoch 2/500\n",
      "49622/49622 [==============================] - 7s 134us/step - loss: 0.2083 - acc: 0.6707 - val_loss: 0.2057 - val_acc: 0.6763\n",
      "Epoch 3/500\n",
      "49622/49622 [==============================] - 6s 124us/step - loss: 0.2066 - acc: 0.6737 - val_loss: 0.2047 - val_acc: 0.6788\n",
      "Epoch 4/500\n",
      "49622/49622 [==============================] - 5s 110us/step - loss: 0.2050 - acc: 0.6768 - val_loss: 0.2047 - val_acc: 0.6752\n",
      "Epoch 5/500\n",
      "49622/49622 [==============================] - 5s 105us/step - loss: 0.2039 - acc: 0.6798 - val_loss: 0.2041 - val_acc: 0.6780\n",
      "Epoch 6/500\n",
      "49622/49622 [==============================] - 8s 160us/step - loss: 0.2030 - acc: 0.6832 - val_loss: 0.2039 - val_acc: 0.6753\n",
      "Epoch 7/500\n",
      "49622/49622 [==============================] - 7s 144us/step - loss: 0.2021 - acc: 0.6834 - val_loss: 0.2041 - val_acc: 0.6788\n",
      "Epoch 8/500\n",
      "49622/49622 [==============================] - 9s 188us/step - loss: 0.2016 - acc: 0.6842 - val_loss: 0.2038 - val_acc: 0.6779\n",
      "Epoch 9/500\n",
      "49622/49622 [==============================] - 8s 156us/step - loss: 0.2010 - acc: 0.6860 - val_loss: 0.2041 - val_acc: 0.6782\n",
      "Epoch 10/500\n",
      "49622/49622 [==============================] - 6s 127us/step - loss: 0.1999 - acc: 0.6872 - val_loss: 0.2037 - val_acc: 0.6766\n",
      "Epoch 11/500\n",
      "49622/49622 [==============================] - 6s 124us/step - loss: 0.1994 - acc: 0.6888 - val_loss: 0.2052 - val_acc: 0.6800\n",
      "Epoch 12/500\n",
      "49622/49622 [==============================] - 7s 143us/step - loss: 0.1988 - acc: 0.6892 - val_loss: 0.2045 - val_acc: 0.6749\n",
      "Epoch 13/500\n",
      "49622/49622 [==============================] - 6s 120us/step - loss: 0.1981 - acc: 0.6911 - val_loss: 0.2051 - val_acc: 0.6732\n",
      "Epoch 14/500\n",
      "49622/49622 [==============================] - 7s 150us/step - loss: 0.1976 - acc: 0.6929 - val_loss: 0.2063 - val_acc: 0.6815\n",
      "Epoch 15/500\n",
      "49622/49622 [==============================] - 7s 148us/step - loss: 0.1965 - acc: 0.6957 - val_loss: 0.2054 - val_acc: 0.6741\n",
      "Epoch 16/500\n",
      "49622/49622 [==============================] - 9s 188us/step - loss: 0.1962 - acc: 0.6963 - val_loss: 0.2067 - val_acc: 0.6726\n",
      "Epoch 17/500\n",
      "49622/49622 [==============================] - 7s 140us/step - loss: 0.1956 - acc: 0.6960 - val_loss: 0.2058 - val_acc: 0.6765\n",
      "Epoch 18/500\n",
      "49622/49622 [==============================] - 6s 126us/step - loss: 0.1949 - acc: 0.6996 - val_loss: 0.2062 - val_acc: 0.6736\n",
      "Epoch 19/500\n",
      "49622/49622 [==============================] - 6s 126us/step - loss: 0.1944 - acc: 0.7000 - val_loss: 0.2083 - val_acc: 0.6690\n",
      "Epoch 20/500\n",
      "49622/49622 [==============================] - 7s 140us/step - loss: 0.1941 - acc: 0.7030 - val_loss: 0.2086 - val_acc: 0.6646\n",
      "Epoch 21/500\n",
      "49622/49622 [==============================] - 9s 187us/step - loss: 0.1933 - acc: 0.7033 - val_loss: 0.2081 - val_acc: 0.6662\n",
      "Epoch 22/500\n",
      "49622/49622 [==============================] - 7s 139us/step - loss: 0.1927 - acc: 0.7048 - val_loss: 0.2083 - val_acc: 0.6648\n",
      "Epoch 23/500\n",
      "49622/49622 [==============================] - 7s 141us/step - loss: 0.1926 - acc: 0.7058 - val_loss: 0.2094 - val_acc: 0.6663\n",
      "Epoch 24/500\n",
      "49622/49622 [==============================] - 8s 168us/step - loss: 0.1919 - acc: 0.7067 - val_loss: 0.2087 - val_acc: 0.6679\n",
      "Epoch 25/500\n",
      "49622/49622 [==============================] - 7s 147us/step - loss: 0.1914 - acc: 0.7085 - val_loss: 0.2105 - val_acc: 0.6610\n",
      "Epoch 26/500\n",
      "49622/49622 [==============================] - 6s 128us/step - loss: 0.1908 - acc: 0.7109 - val_loss: 0.2115 - val_acc: 0.6724\n",
      "Epoch 27/500\n",
      "49622/49622 [==============================] - 7s 135us/step - loss: 0.1906 - acc: 0.7087 - val_loss: 0.2111 - val_acc: 0.6598\n",
      "Epoch 28/500\n",
      "49622/49622 [==============================] - 7s 136us/step - loss: 0.1903 - acc: 0.7120 - val_loss: 0.2104 - val_acc: 0.6676\n",
      "Epoch 29/500\n",
      "49622/49622 [==============================] - 9s 187us/step - loss: 0.1898 - acc: 0.7120 - val_loss: 0.2111 - val_acc: 0.6713\n",
      "Epoch 30/500\n",
      "49622/49622 [==============================] - 6s 119us/step - loss: 0.1893 - acc: 0.7103 - val_loss: 0.2105 - val_acc: 0.6674\n"
     ]
    }
   ],
   "source": [
    "model = classifier_1.fit(X_train.as_matrix(), y_train.as_matrix(),epochs=500, callbacks=[early_stopping], validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49622 samples, validate on 8757 samples\n",
      "Epoch 1/500\n",
      "49622/49622 [==============================] - 8s 164us/step - loss: 0.2154 - acc: 0.6602 - val_loss: 0.2080 - val_acc: 0.6726\n",
      "Epoch 2/500\n",
      "49622/49622 [==============================] - 7s 136us/step - loss: 0.2080 - acc: 0.6707 - val_loss: 0.2056 - val_acc: 0.6783\n",
      "Epoch 3/500\n",
      "49622/49622 [==============================] - 8s 167us/step - loss: 0.2059 - acc: 0.6748 - val_loss: 0.2071 - val_acc: 0.6758\n",
      "Epoch 4/500\n",
      "49622/49622 [==============================] - 6s 122us/step - loss: 0.2049 - acc: 0.6765 - val_loss: 0.2038 - val_acc: 0.6763\n",
      "Epoch 5/500\n",
      "49622/49622 [==============================] - 7s 139us/step - loss: 0.2039 - acc: 0.6809 - val_loss: 0.2052 - val_acc: 0.6750\n",
      "Epoch 6/500\n",
      "49622/49622 [==============================] - 7s 132us/step - loss: 0.2030 - acc: 0.6818 - val_loss: 0.2060 - val_acc: 0.6684\n",
      "Epoch 7/500\n",
      "49622/49622 [==============================] - 6s 130us/step - loss: 0.2026 - acc: 0.6838 - val_loss: 0.2033 - val_acc: 0.6775\n",
      "Epoch 8/500\n",
      "49622/49622 [==============================] - 6s 124us/step - loss: 0.2019 - acc: 0.6840 - val_loss: 0.2051 - val_acc: 0.6725\n",
      "Epoch 9/500\n",
      "49622/49622 [==============================] - 6s 115us/step - loss: 0.2015 - acc: 0.6844 - val_loss: 0.2047 - val_acc: 0.6784\n",
      "Epoch 10/500\n",
      "49622/49622 [==============================] - 6s 116us/step - loss: 0.2010 - acc: 0.6859 - val_loss: 0.2064 - val_acc: 0.6696\n",
      "Epoch 11/500\n",
      "49622/49622 [==============================] - 6s 116us/step - loss: 0.2005 - acc: 0.6884 - val_loss: 0.2052 - val_acc: 0.6800\n",
      "Epoch 12/500\n",
      "49622/49622 [==============================] - 6s 113us/step - loss: 0.2001 - acc: 0.6882 - val_loss: 0.2040 - val_acc: 0.6775\n",
      "Epoch 13/500\n",
      "49622/49622 [==============================] - 6s 116us/step - loss: 0.1995 - acc: 0.6899 - val_loss: 0.2064 - val_acc: 0.6699\n",
      "Epoch 14/500\n",
      "49622/49622 [==============================] - 6s 120us/step - loss: 0.1993 - acc: 0.6901 - val_loss: 0.2064 - val_acc: 0.6685\n",
      "Epoch 15/500\n",
      "49622/49622 [==============================] - 6s 116us/step - loss: 0.1987 - acc: 0.6906 - val_loss: 0.2065 - val_acc: 0.6779\n",
      "Epoch 16/500\n",
      "49622/49622 [==============================] - 6s 111us/step - loss: 0.1981 - acc: 0.6927 - val_loss: 0.2055 - val_acc: 0.6789\n",
      "Epoch 17/500\n",
      "49622/49622 [==============================] - 6s 118us/step - loss: 0.1976 - acc: 0.6945 - val_loss: 0.2083 - val_acc: 0.6655\n",
      "Epoch 18/500\n",
      "49622/49622 [==============================] - 6s 117us/step - loss: 0.1974 - acc: 0.6952 - val_loss: 0.2075 - val_acc: 0.6660\n",
      "Epoch 19/500\n",
      "49622/49622 [==============================] - 6s 117us/step - loss: 0.1970 - acc: 0.6960 - val_loss: 0.2061 - val_acc: 0.6775\n",
      "Epoch 20/500\n",
      "49622/49622 [==============================] - 6s 113us/step - loss: 0.1966 - acc: 0.6972 - val_loss: 0.2068 - val_acc: 0.6796\n",
      "Epoch 21/500\n",
      "49622/49622 [==============================] - 6s 115us/step - loss: 0.1964 - acc: 0.6976 - val_loss: 0.2069 - val_acc: 0.6675\n",
      "Epoch 22/500\n",
      "49622/49622 [==============================] - 6s 113us/step - loss: 0.1958 - acc: 0.6978 - val_loss: 0.2067 - val_acc: 0.6765\n",
      "Epoch 23/500\n",
      "49622/49622 [==============================] - 6s 116us/step - loss: 0.1958 - acc: 0.6972 - val_loss: 0.2087 - val_acc: 0.6639\n",
      "Epoch 24/500\n",
      "49622/49622 [==============================] - 6s 118us/step - loss: 0.1954 - acc: 0.7001 - val_loss: 0.2087 - val_acc: 0.6771\n",
      "Epoch 25/500\n",
      "49622/49622 [==============================] - 6s 113us/step - loss: 0.1951 - acc: 0.7002 - val_loss: 0.2088 - val_acc: 0.6701\n",
      "Epoch 26/500\n",
      "49622/49622 [==============================] - 6s 112us/step - loss: 0.1948 - acc: 0.7010 - val_loss: 0.2078 - val_acc: 0.6757\n",
      "Epoch 27/500\n",
      "49622/49622 [==============================] - 6s 111us/step - loss: 0.1946 - acc: 0.7021 - val_loss: 0.2085 - val_acc: 0.6694\n"
     ]
    }
   ],
   "source": [
    "model = classifier_3.fit(X_train.as_matrix(), y_train.as_matrix(),epochs=500, callbacks=[early_stopping], validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "96eZigggf7Xg",
    "outputId": "a59b89bb-a36b-4145-9574-55dd6d273c8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49622 samples, validate on 8757 samples\n",
      "Epoch 1/500\n",
      "49622/49622 [==============================] - 6s 125us/step - loss: 0.2142 - acc: 0.6627 - val_loss: 0.2063 - val_acc: 0.6773\n",
      "Epoch 2/500\n",
      "49622/49622 [==============================] - 6s 114us/step - loss: 0.2075 - acc: 0.6710 - val_loss: 0.2053 - val_acc: 0.6817\n",
      "Epoch 3/500\n",
      "49622/49622 [==============================] - 6s 118us/step - loss: 0.2057 - acc: 0.6737 - val_loss: 0.2077 - val_acc: 0.6815\n",
      "Epoch 4/500\n",
      "49622/49622 [==============================] - 6s 127us/step - loss: 0.2042 - acc: 0.6785 - val_loss: 0.2043 - val_acc: 0.6824\n",
      "Epoch 5/500\n",
      "49622/49622 [==============================] - 8s 156us/step - loss: 0.2034 - acc: 0.6784 - val_loss: 0.2042 - val_acc: 0.6845\n",
      "Epoch 6/500\n",
      "49622/49622 [==============================] - 6s 125us/step - loss: 0.2024 - acc: 0.6815 - val_loss: 0.2042 - val_acc: 0.6759\n",
      "Epoch 7/500\n",
      "49622/49622 [==============================] - 6s 119us/step - loss: 0.2014 - acc: 0.6844 - val_loss: 0.2036 - val_acc: 0.6838\n",
      "Epoch 8/500\n",
      "49622/49622 [==============================] - 6s 116us/step - loss: 0.2008 - acc: 0.6842 - val_loss: 0.2058 - val_acc: 0.6871\n",
      "Epoch 9/500\n",
      "49622/49622 [==============================] - 6s 119us/step - loss: 0.1999 - acc: 0.6870 - val_loss: 0.2035 - val_acc: 0.6831\n",
      "Epoch 10/500\n",
      "49622/49622 [==============================] - 5s 107us/step - loss: 0.1994 - acc: 0.6883 - val_loss: 0.2045 - val_acc: 0.6788\n",
      "Epoch 11/500\n",
      "49622/49622 [==============================] - 5s 100us/step - loss: 0.1984 - acc: 0.6902 - val_loss: 0.2061 - val_acc: 0.6680\n",
      "Epoch 12/500\n",
      "49622/49622 [==============================] - 5s 108us/step - loss: 0.1978 - acc: 0.6911 - val_loss: 0.2059 - val_acc: 0.6732\n",
      "Epoch 13/500\n",
      "49622/49622 [==============================] - 7s 142us/step - loss: 0.1971 - acc: 0.6943 - val_loss: 0.2052 - val_acc: 0.6825\n",
      "Epoch 14/500\n",
      "49622/49622 [==============================] - 9s 187us/step - loss: 0.1969 - acc: 0.6926 - val_loss: 0.2060 - val_acc: 0.6815\n",
      "Epoch 15/500\n",
      "49622/49622 [==============================] - 7s 138us/step - loss: 0.1961 - acc: 0.6958 - val_loss: 0.2055 - val_acc: 0.6733\n",
      "Epoch 16/500\n",
      "49622/49622 [==============================] - 6s 120us/step - loss: 0.1952 - acc: 0.6981 - val_loss: 0.2063 - val_acc: 0.6723\n",
      "Epoch 17/500\n",
      "49622/49622 [==============================] - 6s 119us/step - loss: 0.1947 - acc: 0.6984 - val_loss: 0.2064 - val_acc: 0.6731\n",
      "Epoch 18/500\n",
      "49622/49622 [==============================] - 7s 133us/step - loss: 0.1940 - acc: 0.7009 - val_loss: 0.2081 - val_acc: 0.6623\n",
      "Epoch 19/500\n",
      "49622/49622 [==============================] - 6s 118us/step - loss: 0.1933 - acc: 0.7013 - val_loss: 0.2074 - val_acc: 0.6753\n",
      "Epoch 20/500\n",
      "49622/49622 [==============================] - 6s 114us/step - loss: 0.1929 - acc: 0.7040 - val_loss: 0.2071 - val_acc: 0.6708\n",
      "Epoch 21/500\n",
      "49622/49622 [==============================] - 6s 115us/step - loss: 0.1925 - acc: 0.7044 - val_loss: 0.2101 - val_acc: 0.6622\n",
      "Epoch 22/500\n",
      "49622/49622 [==============================] - 6s 114us/step - loss: 0.1921 - acc: 0.7049 - val_loss: 0.2088 - val_acc: 0.6692\n",
      "Epoch 23/500\n",
      "49622/49622 [==============================] - 6s 118us/step - loss: 0.1916 - acc: 0.7051 - val_loss: 0.2093 - val_acc: 0.6739\n",
      "Epoch 24/500\n",
      "49622/49622 [==============================] - 6s 120us/step - loss: 0.1910 - acc: 0.7074 - val_loss: 0.2108 - val_acc: 0.6686\n",
      "Epoch 25/500\n",
      "49622/49622 [==============================] - 7s 147us/step - loss: 0.1906 - acc: 0.7093 - val_loss: 0.2097 - val_acc: 0.6751\n",
      "Epoch 26/500\n",
      "49622/49622 [==============================] - 7s 146us/step - loss: 0.1901 - acc: 0.7100 - val_loss: 0.2089 - val_acc: 0.6721\n",
      "Epoch 27/500\n",
      "49622/49622 [==============================] - 7s 146us/step - loss: 0.1894 - acc: 0.7115 - val_loss: 0.2102 - val_acc: 0.6693\n",
      "Epoch 28/500\n",
      "49622/49622 [==============================] - 9s 175us/step - loss: 0.1891 - acc: 0.7128 - val_loss: 0.2112 - val_acc: 0.6646\n",
      "Epoch 29/500\n",
      "49622/49622 [==============================] - 12s 246us/step - loss: 0.1889 - acc: 0.7139 - val_loss: 0.2118 - val_acc: 0.6634\n"
     ]
    }
   ],
   "source": [
    "model = classifier_2.fit(X_train.as_matrix(), y_train.as_matrix(),epochs=500, callbacks=[early_stopping], validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(243,))\n",
    "\n",
    "x1 = Dense(16, activation=\"tanh\")(inputs)\n",
    "x1 = Dense(16, activation=\"relu\")(x1)\n",
    "\n",
    "x2 = Dense(16, activation=\"tanh\")(inputs)\n",
    "x2 = Dense(8, activation=\"relu\")(x2)\n",
    "\n",
    "x3 = Dense(16, activation=\"tanh\")(inputs)\n",
    "x3 = Dense(16, activation=\"tanh\")(x3)\n",
    "x3 = Dense(8, activation=\"relu\")(x3)\n",
    "\n",
    "x4 = concatenate([x1,x2,x3])\n",
    "\n",
    "prediction = Dense(1, activation=\"sigmoid\")(x4)\n",
    "\n",
    "voting_classifier = Model(inputs=inputs, outputs= prediction)\n",
    "voting_classifier.compile(optimizer='adam', loss='mean_squared_error', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_voting = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=10,\n",
    "                              verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49622 samples, validate on 8757 samples\n",
      "Epoch 1/500\n",
      "49622/49622 [==============================] - 6s 127us/step - loss: 0.1666 - acc: 0.7577 - val_loss: 0.2292 - val_acc: 0.6459\n",
      "Epoch 2/500\n",
      "49622/49622 [==============================] - 7s 136us/step - loss: 0.1654 - acc: 0.7612 - val_loss: 0.2301 - val_acc: 0.6517\n",
      "Epoch 3/500\n",
      "49622/49622 [==============================] - 7s 140us/step - loss: 0.1639 - acc: 0.7650 - val_loss: 0.2323 - val_acc: 0.6433\n",
      "Epoch 4/500\n",
      "49622/49622 [==============================] - 6s 126us/step - loss: 0.1629 - acc: 0.7669 - val_loss: 0.2308 - val_acc: 0.6599\n",
      "Epoch 5/500\n",
      "49622/49622 [==============================] - 7s 131us/step - loss: 0.1617 - acc: 0.7688 - val_loss: 0.2331 - val_acc: 0.6493\n",
      "Epoch 6/500\n",
      "49622/49622 [==============================] - 7s 136us/step - loss: 0.1604 - acc: 0.7738 - val_loss: 0.2350 - val_acc: 0.6433\n",
      "Epoch 7/500\n",
      "49622/49622 [==============================] - 7s 135us/step - loss: 0.1592 - acc: 0.7733 - val_loss: 0.2365 - val_acc: 0.6426\n",
      "Epoch 8/500\n",
      "49622/49622 [==============================] - 7s 133us/step - loss: 0.1583 - acc: 0.7753 - val_loss: 0.2370 - val_acc: 0.6437\n",
      "Epoch 9/500\n",
      "49622/49622 [==============================] - 6s 129us/step - loss: 0.1569 - acc: 0.7787 - val_loss: 0.2341 - val_acc: 0.6558\n",
      "Epoch 10/500\n",
      "49622/49622 [==============================] - 7s 132us/step - loss: 0.1563 - acc: 0.7801 - val_loss: 0.2376 - val_acc: 0.6571\n",
      "Epoch 11/500\n",
      "49622/49622 [==============================] - 7s 133us/step - loss: 0.1547 - acc: 0.7836 - val_loss: 0.2374 - val_acc: 0.6534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a449f3c9e8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier.fit(X_train.as_matrix(), y_train.as_matrix(),epochs=500, callbacks=[early_stopping_voting], validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "IPdXIjuef7Xk"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier = VotingClassifier([('classifier_1', classifier_1), ('classifier_2', classifier_2), ('classifier_3',classifier_3)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gltINz0wf7Xn"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters to choose\n",
    "number_estimators = [70]\n",
    "max_depth = [15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = GridSearchCV(estimator=RandomForestClassifier(), \n",
    "                          param_grid=dict(\n",
    "                              n_estimators=number_estimators,\n",
    "                              max_depth=max_depth), cv=5, verbose=5, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] max_depth=15, n_estimators=70 ...................................\n",
      "[CV] max_depth=15, n_estimators=70 ...................................\n",
      "[CV]  max_depth=15, n_estimators=70, score=0.6802101509021533, total= 3.6min\n",
      "[CV] max_depth=15, n_estimators=70 ...................................\n",
      "[CV]  max_depth=15, n_estimators=70, score=0.678791248825571, total= 3.8min\n",
      "[CV] max_depth=15, n_estimators=70 ...................................\n",
      "[CV]  max_depth=15, n_estimators=70, score=0.6794178554993097, total= 2.8min\n",
      "[CV] max_depth=15, n_estimators=70 ...................................\n",
      "[CV]  max_depth=15, n_estimators=70, score=0.6795520785396533, total= 2.7min\n",
      "[CV]  max_depth=15, n_estimators=70, score=0.6817318939234147, total= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'n_estimators': [70], 'max_depth': [15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'n_estimators': [70], 'max_depth': [15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=70, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15, 'n_estimators': 70}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fada05ba3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_auc_roc(rf_classifier.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fada0672518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_auc_roc(rf_classifier.best_estimator_, kaggle_x_test, kaggle_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The score of the rf_classifier alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = rf_classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_train_pred = classifier.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = classifier.predict(X_test.as_matrix()).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XXpon-XGf7X9",
    "outputId": "e3724372-f7c7-42b7-ab07-db29750a1d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier.predict_proba(X_test.as_matrix())[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HC--sBLtf7YC",
    "outputId": "5633e246-2e20-4b4a-ee44-0dd2056dc0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6811\n",
      "Recall:           0.9354\n",
      "Precision:        0.6895\n",
      "F1:               0.7938\n",
      "AUROC:            0.6954\n",
      "AUPR:             0.8071\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use grid search to improve our search for parameters using Cross Validation\n",
    "number_estimators = [100, 120, 140]\n",
    "loss_function = [\"deviance\", \"exponential\"]\n",
    "min_samples_leaf = [1, 0.05, 0.5]\n",
    "sub_samples = [0.85, 0.8, 0.7]\n",
    "learning_rates = [0.2, 0.3, 0.35, 0.45]\n",
    "xgboost_classifier = GridSearchCV(estimator=GradientBoostingClassifier(), \n",
    "                          param_grid=dict(\n",
    "                              n_estimators=number_estimators,\n",
    "                              max_features=max_features,\n",
    "                              subsample=sub_samples,\n",
    "                          min_samples_leaf=min_samples_leaf,\n",
    "                          loss=loss_function, learning_rate=learning_rates), verbose=5, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85 \n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85, score=0.6851508841361696, total= 1.1min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85, score=0.6833446462880086, total= 1.2min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8, score=0.6826198502088103, total=  45.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85, score=0.6835214395011447, total=  55.7s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8, score=0.6855995674232924, total=  48.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8, score=0.6838550834685166, total=  41.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7, score=0.6844375927566411, total=  41.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7, score=0.6859677178127265, total=  46.6s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7, score=0.6836710040382425, total=  43.4s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85, score=0.6857606332186699, total= 1.1min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85, score=0.6852429217335282, total= 1.1min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85, score=0.6843613019017706, total=  59.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8, score=0.6850818559381507, total= 1.0min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8, score=0.6863818870008398, total= 1.0min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  6.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8, score=0.6849250451569853, total= 1.1min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7, score=0.68450662095466, total= 1.1min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7, score=0.6852429217335282, total=  52.7s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7, score=0.6830152210678908, total=  51.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85, score=0.6855075298259339, total= 1.2min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85, score=0.6879695355552743, total= 1.1min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85, score=0.6859719969166695, total= 1.2min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8, score=0.6856801003209811, total= 1.4min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8, score=0.6881190966509819, total= 1.2min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8, score=0.6852701940887493, total= 1.2min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7, score=0.6857721379183397, total=  59.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7, score=0.6876704133638591, total= 1.1min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7, score=0.6857073827356505, total=  58.7s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85, score=0.6806870606642813, total=  43.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85, score=0.682884458301216, total=  43.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85, score=0.6815540905900896, total=  47.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8, score=0.6803189102748473, total=  46.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8, score=0.6839083765718296, total=  43.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8, score=0.6801159700410727, total=  41.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7, score=0.6801003209811208, total=  40.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7, score=0.6818835494299421, total=  40.6s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7, score=0.6802310196849941, total=  42.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85, score=0.6836207590800842, total=  47.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85, score=0.68512787473683, total=  53.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85, score=0.6838205685753402, total= 1.1min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8, score=0.6829074677005557, total= 1.2min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8, score=0.6843110410602731, total= 1.0min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8, score=0.6824169629194997, total=  57.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7, score=0.6835402261823955, total=  49.9s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7, score=0.6835977496807446, total=  52.1s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7, score=0.6825435175278133, total=  58.2s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85, score=0.6834711979843766, total= 1.1min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85, score=0.6855190345256037, total= 1.0min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85, score=0.6833373600708705, total= 1.0min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8, score=0.6854845204265942, total=  59.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8, score=0.6861748024067832, total= 1.1min\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8, score=0.6823019132755784, total=  58.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7, score=0.6832180945916407, total=  55.9s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7, score=0.6852084076345187, total=  56.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85, score=0.6550200757009238, total=   9.9s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85, score=0.6550200757009238, total=  10.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7, score=0.6833143501420863, total=  55.7s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85, score=0.6550236427018259, total=  10.9s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8, score=0.6550200757009238, total=  10.4s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8, score=0.6550200757009238, total=  10.4s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8, score=0.6550236427018259, total=  10.6s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7, score=0.6550200757009238, total=  11.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7, score=0.6550200757009238, total=  10.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7, score=0.6550236427018259, total=  10.8s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85, score=0.6550200757009238, total=  11.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85, score=0.6550200757009238, total=  11.6s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85, score=0.6550236427018259, total=  11.7s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8, score=0.6550200757009238, total=  12.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8, score=0.6550200757009238, total=  11.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  68 tasks      | elapsed: 27.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8, score=0.6550236427018259, total=  11.4s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7, score=0.6550200757009238, total=  10.7s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7, score=0.6550200757009238, total=  11.1s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7, score=0.6550236427018259, total=  11.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85, score=0.6550200757009238, total=  11.3s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85, score=0.6550200757009238, total=  11.1s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85, score=0.6550236427018259, total=  11.5s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8, score=0.6550200757009238, total=  11.4s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8, score=0.6550200757009238, total=  11.7s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8, score=0.6550236427018259, total=  11.6s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7, score=0.6550200757009238, total=  12.0s\n",
      "[CV] loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7, score=0.6550200757009238, total=  11.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=deviance, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7, score=0.6550236427018259, total=  12.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85, score=0.6843455551592825, total=  45.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85, score=0.6841844893639052, total=  52.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.85, score=0.6832453203557335, total=  50.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8, score=0.6838393483738107, total=  49.0s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8, score=0.6844836115553203, total= 1.0min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.8, score=0.682014289165775, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7, score=0.6836437684794239, total=  57.0s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7, score=0.68450662095466, total=  56.2s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=100, subsample=0.7, score=0.6830727458898515, total=  57.5s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85, score=0.684633172651028, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85, score=0.6840004141691881, total=  58.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.85, score=0.6839241132548695, total= 1.0min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8, score=0.6842305081625845, total= 1.0min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8, score=0.6867385326906041, total=  50.0s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.8, score=0.6839816380768301, total=  58.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7, score=0.6840234235685277, total=  46.3s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7, score=0.6865889715948965, total=  48.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=120, subsample=0.7, score=0.6840046480056144, total=  49.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85, score=0.685749128519, total=  59.1s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85, score=0.6885907893374443, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.85, score=0.6846029061540054, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8, score=0.6866004762945663, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8, score=0.6861172789084341, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.8, score=0.6860755415961988, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7, score=0.6859907272120661, total=  58.5s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7, score=0.6862668400041417, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=1, n_estimators=140, subsample=0.7, score=0.6846029061540054, total=  58.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85, score=0.6816764648358855, total=  46.2s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85, score=0.6841729846642354, total=  39.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.85, score=0.6824284678838919, total=  46.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8, score=0.6812277815487626, total=  41.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8, score=0.6806065277665927, total=  45.1s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.8, score=0.6794486821063289, total=  41.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7, score=0.6790879074101771, total=  40.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7, score=0.6823552421164045, total=  41.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=100, subsample=0.7, score=0.6802655345781705, total=  39.2s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85, score=0.6835862449810748, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85, score=0.6845756491526789, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.85, score=0.6840046480056144, total= 1.3min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8, score=0.68450662095466, total= 1.2min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8, score=0.6842650222615939, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.8, score=0.6827275969580874, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7, score=0.683137561693952, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7, score=0.6827118878061689, total= 1.0min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=120, subsample=0.7, score=0.6818187047711087, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85, score=0.6841729846642354, total= 1.3min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85, score=0.6865889715948965, total= 1.4min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.85, score=0.6834178948216155, total= 1.4min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8, score=0.6833791603870181, total= 1.3min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8, score=0.6858641755156981, total= 1.3min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.8, score=0.6833373600708705, total= 1.2min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7, score=0.6842650222615939, total= 1.2min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7, score=0.683038230996675, total= 1.1min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.05, n_estimators=140, subsample=0.7, score=0.6858871849150378, total= 1.2min\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85, score=0.6550200757009238, total=  12.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85, score=0.6550200757009238, total=  12.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.85, score=0.6550236427018259, total=  12.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8, score=0.6550200757009238, total=  13.3s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8, score=0.6550200757009238, total=  13.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.8, score=0.6550236427018259, total=  13.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7, score=0.6550200757009238, total=  13.5s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7, score=0.6550200757009238, total=  13.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=100, subsample=0.7, score=0.6550236427018259, total=  13.3s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85, score=0.6550200757009238, total=  13.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85, score=0.6550200757009238, total=  14.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.85, score=0.6550236427018259, total=  15.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8, score=0.6550200757009238, total=  14.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8, score=0.6550200757009238, total=  14.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.8, score=0.6550236427018259, total=  14.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7, score=0.6550200757009238, total=  15.5s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7, score=0.6550200757009238, total=  14.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=120, subsample=0.7, score=0.6550236427018259, total=  14.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85, score=0.6550200757009238, total=  14.9s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85, score=0.6550200757009238, total=  15.8s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.85, score=0.6550236427018259, total=  15.2s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8, score=0.6550200757009238, total=  15.4s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8, score=0.6550200757009238, total=  14.5s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 60.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.8, score=0.6550236427018259, total=  14.6s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7, score=0.6550200757009238, total=  14.7s\n",
      "[CV] loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7 \n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7, score=0.6550200757009238, total=  14.5s\n",
      "[CV]  loss=exponential, max_features=sqrt, min_samples_leaf=0.5, n_estimators=140, subsample=0.7, score=0.6550236427018259, total=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 162 out of 162 | elapsed: 60.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'n_estimators': [100, 120, 140], 'max_features': ['sqrt'], 'subsample': [0.85, 0.8, 0.7], 'min_samples_leaf': [1, 0.05, 0.5], 'loss': ['deviance', 'exponential']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'deviance',\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 140,\n",
       " 'subsample': 0.85}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as I said in the documentation, GridSeach uses a stratified 3-fold cross validation because a Classifier was passed\n",
    "# instead of a recgressor\n",
    "\n",
    "xgboost_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUTjnnCvU/wNNjHi7xhL9FgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fada0666978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_auc_roc(xgboost_classifier.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnCuUJwrnnHOF+n85dDCKC6r8OwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fada0672860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_auc_roc(xgboost_classifier.best_estimator_, kaggle_x_test, kaggle_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score of the single XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = xgboost_classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_train_pred = classifier.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = classifier.predict(X_test.as_matrix()).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XXpon-XGf7X9",
    "outputId": "e3724372-f7c7-42b7-ab07-db29750a1d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier.predict_proba(X_test.as_matrix())[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HC--sBLtf7YC",
    "outputId": "5633e246-2e20-4b4a-ee44-0dd2056dc0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6881\n",
      "Recall:           0.9156\n",
      "Precision:        0.7008\n",
      "F1:               0.7939\n",
      "AUROC:            0.6992\n",
      "AUPR:             0.8053\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble classifiers (Voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ensembling both I must first train those two separated, so I'll get the best parameters of both models\n",
    "in the original dataset and train both in different samples here. (80% of the original dataset each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'deviance',\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 140,\n",
       " 'subsample': 0.85}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters for both classifiers\n",
    "xgboost_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_classifier_voting = GradientBoostingClassifier(loss=\"deviance\", max_features=\"sqrt\", min_samples_leaf=1, n_estimators=140, subsample=0.85, learning_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if creating different samples from training set, use this paragraph\n",
    "training_data_sample = training_data.sample(frac=0.7)\n",
    "X_train, y_train = (training_data_sample.drop(\"IND_BOM_1_1\", axis=1), training_data_sample[\"IND_BOM_1_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=140,\n",
       "              presort='auto', random_state=None, subsample=0.85, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_classifier_voting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15, 'n_estimators': 60}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_voting = RandomForestClassifier(n_estimators=60, max_depth=15, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if creating different samples from training set, use this paragraph\n",
    "training_data_sample = training_data.sample(frac=0.7)\n",
    "X_train, y_train = (training_data_sample.drop(\"IND_BOM_1_1\", axis=1), training_data_sample[\"IND_BOM_1_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=2,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier_voting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest and XGBoost together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I get the best estimator of a previous chosen xgboost classifier\n",
    "classifier = VotingClassifier([('xgboost', xgboost_classifier_voting), ('randomforest', rf_classifier_voting)], voting='soft', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = (training_data.drop(\"IND_BOM_1_1\", axis=1), training_data[\"IND_BOM_1_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgboost', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.3, loss='deviance', max_depth=3,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_l...n_jobs=2,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=2, voting='soft', weights=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fada05e5f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_auc_roc(classifier, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgboost', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.3, loss='deviance', max_depth=3,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_l...n_jobs=2,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=2, voting='soft', weights=None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_whole, y_train_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fadc16854a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_auc_roc(classifier, kaggle_x_test, kaggle_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XXpon-XGf7X9",
    "outputId": "e3724372-f7c7-42b7-ab07-db29750a1d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier.predict_proba(X_test.as_matrix())[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_train_pred = classifier.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = classifier.predict(X_test.as_matrix()).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kB9rJAI6f7X1"
   },
   "source": [
    "é bom prestar atenção se os valores estão próximo, caso contrário, existe uma boa indicação de que houve\n",
    "overfitting e o modelo não consegue generalizar tão bem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7BtRFR1Uf7X3",
    "outputId": "4371cb58-7193-4487-fc91-e5685127acf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square error in train: 0.1\n",
      "Mean Square error in test: 0.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Square error in train: {:0.1f}\".format(mse(y_train, y_train_pred)))\n",
    "print(\"Mean Square error in test: {:0.1f}\".format(mse(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29190,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29190,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29190,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HC--sBLtf7YC",
    "outputId": "5633e246-2e20-4b4a-ee44-0dd2056dc0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6844\n",
      "Recall:           0.9165\n",
      "Precision:        0.6974\n",
      "F1:               0.7921\n",
      "AUROC:            0.7012\n",
      "AUPR:             0.8113\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WTW9B1nRf7YG"
   },
   "source": [
    "# Evaluate for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "lyBq2QWyf7YH"
   },
   "outputs": [],
   "source": [
    "kaggle_test_data = pandas.read_csv(\"real_test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eGiaJwKzf7YJ",
    "outputId": "eff32b6b-7971-43cd-cc05-49562d3d62e6"
   },
   "outputs": [],
   "source": [
    "kaggle_test_data.shape\n",
    "features_kaggle = kaggle_test_data.drop([\"id\"], axis=1)\n",
    "features_kaggle.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ibft8n9Ef7YN"
   },
   "outputs": [],
   "source": [
    "rf_pred_test_class = rf_clf.predict(features_kaggle)\n",
    "rf_pred_test_scores = rf_clf.predict_proba(features_kaggle)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xtuergdcf7YP",
    "outputId": "171f3cf1-2878-4283-a784-de001c38ac10"
   },
   "outputs": [],
   "source": [
    "rf_pred_test_class.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PiHOmQg9f7YS",
    "outputId": "545442e3-9b36-4123-a8f8-730cda6a24fa"
   },
   "outputs": [],
   "source": [
    "rf_pred_test_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yBEXHwduf7YX"
   },
   "source": [
    "Se ligar que na hora que cria o csv, na primeira linha (a linha do header), ele coloca \",0\", tem que substituir para \"id,IND_BOM_1_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "NOE4SMRxf7YY"
   },
   "outputs": [],
   "source": [
    "df = pandas.DataFrame(data=rf_pred_test_class)\n",
    "df.to_csv('test.csv', mode='a', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "jruxoZPlf7Ye"
   },
   "outputs": [],
   "source": [
    "# For in ensemble classifiers\n",
    "classifier = xgboost_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS LOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost - 120 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HC--sBLtf7YC",
    "outputId": "5633e246-2e20-4b4a-ee44-0dd2056dc0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6607\n",
      "Recall:           0.9790\n",
      "Precision:        0.6636\n",
      "F1:               0.7910\n",
      "AUROC:            0.6295\n",
      "AUPR:             0.7507\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6607\n",
      "Recall:           0.9790\n",
      "Precision:        0.6636\n",
      "F1:               0.7910\n",
      "AUROC:            0.6295\n",
      "AUPR:             0.7507\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost - 2nd configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "number_estimators = [30, 60, 120, 200]\n",
    "loss_function = [\"deviance\", \"exponential\"]\n",
    "min_samples_leaf = [1, 0.05]\n",
    "sub_samples = [1.0, 0.8, 0.6]\n",
    "max_features = [\"log2\", \"sqrt\", \"auto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'deviance',\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 0.05,\n",
       " 'n_estimators': 200,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6878\n",
      "Recall:           0.9007\n",
      "Precision:        0.7052\n",
      "F1:               0.7910\n",
      "AUROC:            0.7065\n",
      "AUPR:             0.8131\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Of XBGoost and RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Tuning of the random forest parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgboost', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_l...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6766\n",
      "Recall:           0.8842\n",
      "Precision:        0.7010\n",
      "F1:               0.7820\n",
      "AUROC:            0.6773\n",
      "AUPR:             0.7933\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'deviance',\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 120,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as I said in the documentation, GridSeach uses a stratified 3-fold cross validation because a Classifier was passed\n",
    "# instead of a recgressor\n",
    "\n",
    "xgboost_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': {0: 1, 1: 1},\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 20}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HC--sBLtf7YC",
    "outputId": "5633e246-2e20-4b4a-ee44-0dd2056dc0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6829\n",
      "Recall:           0.9383\n",
      "Precision:        0.6899\n",
      "F1:               0.7952\n",
      "AUROC:            0.7052\n",
      "AUPR:             0.8132\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPs and Ensemble MLPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6664\n",
      "Recall:           0.8560\n",
      "Precision:        0.7013\n",
      "F1:               0.7710\n",
      "AUROC:            0.6650\n",
      "AUPR:             0.7853\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = classifier_1.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = classifier_1.predict(X_test.as_matrix()).ravel()\n",
    "\n",
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier_1.predict_proba(X_test.as_matrix())[:, 0]\n",
    "\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6660\n",
      "Recall:           0.8400\n",
      "Precision:        0.7064\n",
      "F1:               0.7674\n",
      "AUROC:            0.6698\n",
      "AUPR:             0.7878\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = classifier_2.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = classifier_2.predict(X_test.as_matrix()).ravel()\n",
    "\n",
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier_2.predict_proba(X_test.as_matrix())[:, 0]\n",
    "\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6684\n",
      "Recall:           0.8315\n",
      "Precision:        0.7116\n",
      "F1:               0.7669\n",
      "AUROC:            0.6739\n",
      "AUPR:             0.7916\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = classifier_3.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = classifier_3.predict(X_test.as_matrix()).ravel()\n",
    "\n",
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier_3.predict_proba(X_test.as_matrix())[:, 0]\n",
    "\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\danil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance no conjunto de teste:\n",
      "\n",
      "Accuracy:         0.6493\n",
      "Recall:           0.7997\n",
      "Precision:        0.7051\n",
      "F1:               0.7495\n",
      "AUROC:            0.6650\n",
      "AUPR:             0.7853\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = voting_classifier.predict(X_train.as_matrix()).ravel()\n",
    "y_test_pred = voting_classifier.predict(X_test.as_matrix()).ravel()\n",
    "\n",
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = classifier_1.predict_proba(X_test.as_matrix())[:, 0]\n",
    "\n",
    "print('\\nPerformance no conjunto de teste:')\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred.round(), y_test_pred_prob)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking RF and XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify data based on RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add XGBoost to read from new X_train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'deviance',\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 140,\n",
       " 'subsample': 0.85}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_classifier = GradientBoostingClassifier(n_estimators=140, subsample=0.85, max_features=\"sqrt\", min_samples_leaf=1, learning_rate=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XXpon-XGf7X9",
    "outputId": "e3724372-f7c7-42b7-ab07-db29750a1d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = rf_classifier.best_estimator_.predict_proba(X_train_whole.as_matrix())[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [],
   "source": [
    "# add random forest prediction as feature\n",
    "X_train_whole[\"rf_feature\"] = y_test_pred_prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.3, loss='deviance', max_depth=3,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=140,\n",
       "              presort='auto', random_state=None, subsample=0.85, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now it has the rf_feature column on it\n",
    "xgboost_classifier.fit(X_train_whole, y_train_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "kaggle_x_test[\"rf_feature\"] = rf_classifier.best_estimator_.predict_proba(kaggle_x_test.as_matrix())[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.859242\n",
       "1    0.879647\n",
       "2    0.502823\n",
       "3    0.653111\n",
       "4    0.535827\n",
       "5    0.832793\n",
       "6    0.577545\n",
       "7    0.502263\n",
       "8    0.918410\n",
       "9    0.681121\n",
       "Name: rf_feature, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_x_test[\"rf_feature\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzkXlicI551xUniicc85F5YnCOedcVP8PHYXMHTcjbnEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fada8a90278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_auc_roc(xgboost_classifier, kaggle_x_test, kaggle_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking for our test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XXpon-XGf7X9",
    "outputId": "e3724372-f7c7-42b7-ab07-db29750a1d3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# This returns an array for the probabilities of being each class, so it depends what the focus will be\n",
    "# in our case, the focus is at class 1\n",
    "y_test_pred_prob = rf_classifier.best_estimator_.predict_proba(X_train.as_matrix())[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylrT4mitf7Xz",
    "outputId": "c30b5e81-1e7c-4db9-c0ab-88a4805fcd98"
   },
   "outputs": [],
   "source": [
    "# add random forest prediction as feature\n",
    "X_train[\"rf_feature\"] = y_test_pred_prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.3, loss='deviance', max_depth=3,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=140,\n",
       "              presort='auto', random_state=None, subsample=0.85, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now it has the rf_feature column on it\n",
    "xgboost_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbormann/anaconda3/envs/IF702-redes-neurais/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_test[\"rf_feature\"] = rf_classifier.best_estimator_.predict_proba(X_test.as_matrix())[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80781     0.853704\n",
       "96217     0.660023\n",
       "145553    0.625495\n",
       "246883    0.531379\n",
       "192908    0.510707\n",
       "70399     0.731647\n",
       "148944    0.777177\n",
       "68658     0.617032\n",
       "187123    0.662114\n",
       "235113    0.651750\n",
       "Name: rf_feature, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[\"rf_feature\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuaj+H0eSgFY/VBxEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fadc11a0780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_auc_roc(xgboost_classifier, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.12871287128712872, pvalue=0.34994207557716706)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "position = 0\n",
    "class_0 = 0\n",
    "class_1 = 0\n",
    "counting_class_0 = [0] * 101\n",
    "counting_class_1 = [0] * 101\n",
    "grouped_counting_class_0 = [0] * 101\n",
    "grouped_counting_class_1 = [0] * 101\n",
    "percentage_counting_class_0 = [0.0] * 101\n",
    "percentage_counting_class_1 = [0.0] * 101\n",
    "\n",
    "for x in y_test:\n",
    "    score = math.floor(y_test_pred_prob[position]*100)\n",
    "    if x == 0:\n",
    "        class_0 += 1\n",
    "        counting_class_0[score] += 1\n",
    "    else:\n",
    "        class_1 += 1\n",
    "        counting_class_1[score] += 1\n",
    "    position += 1\n",
    "\n",
    "last_value_class_0 = 0\n",
    "last_value_class_1 = 0\n",
    "\n",
    "for x in range(0, 101):\n",
    "    last_value_class_0 += counting_class_0[x]\n",
    "    grouped_counting_class_0[x] = last_value_class_0\n",
    "    percentage_counting_class_0[x] = last_value_class_0/class_0\n",
    "    \n",
    "    last_value_class_1 += counting_class_1[x]\n",
    "    grouped_counting_class_1[x] = last_value_class_1\n",
    "    percentage_counting_class_1[x] = last_value_class_1/class_1\n",
    "\n",
    "#stats.ks_2samp(percentage_counting_class_0, percentage_counting_class_1)\n",
    "stats.ks_2samp(grouped_counting_class_0, grouped_counting_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Kaggle_Submission.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
